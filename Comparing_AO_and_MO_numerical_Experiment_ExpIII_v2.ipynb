{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb6cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "import scipy.integrate\n",
    "import scipy.stats\n",
    "import math\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "############\n",
    "from Helper_Functions import z_expectation_variance,moment_matching_update,product_diff_list,\n",
    "question_extractor,norm_AO_MO_data_generation,batch_design_AO, batch_design_MO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce670c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function calculates the mean and 95% confidence interval (based on t-distribution)\n",
    "#of a set of data.\n",
    "def mean_CI_95(data):\n",
    "    #data: The set of data for which we will calculate the mean and 95% confidence interval.\n",
    "    \n",
    "    data_len = len(data)\n",
    "    t_crit_95 = scipy.stats.t.ppf(q=1-.05/2,df=data_len-1)\n",
    "    data_mean = np.mean(data)\n",
    "    data_sd = np.std(data,ddof=1)\n",
    "    \n",
    "    lower_CI = data_mean - t_crit_95*data_sd/np.sqrt(data_len)\n",
    "    upper_CI = data_mean + t_crit_95*data_sd/np.sqrt(data_len)\n",
    "    \n",
    "    return data_mean, lower_CI, upper_CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03687813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is for conducting an experiment where we compare the batch design using AO, the batch design using MO,\n",
    "#and JMP in a sequential manner.\n",
    "\n",
    "def sequential_AO_MO_experiment(init_mu,init_Sig,true_partworths,gumbel_error_terms,rep_per_partworth,num_questions,AO_MO_batch_size,\n",
    "                               AO_alpha, AO_kappa, AO_gamma, MO_alpha, MO_kappa, MO_gamma, OS_alpha, OS_kappa, noise_par, hitrate_question_list, JMP_questionnaire, Method = 0, t=100):\n",
    "    #init_mu: This is the initial estimate on the partworths\n",
    "    #init_Sig: This is the initial covariance matrix on the partworths\n",
    "    #true_partworths: These are used to make selection in the product selection stage (a list/set of partworths)\n",
    "    #gumbel_error_terms: This is a list of gumbel errors terms used in evaluating the d-error of a design. This \n",
    "    #list should have dimension (true_partworths x num_questions), where each entry is a list with two randomly generated\n",
    "    #gumbel terms. We use the same true partworths and error terms for evaluating the d-error of each randomly generated \n",
    "    #design.\n",
    "    #rep_per_partworth: This is the number of times we want to conduct a questionnaire on each partworth\n",
    "    #num_questions: Length of the questionnaire. Will also be used as the batch size.\n",
    "    #AO_MO_batch_size: The size of the batch we will use for the orthogonal batches using AO and MO.\n",
    "    #AO_alpha,AO_kappa,AO_gamma: These are the parameters that go with average question mean, average question variance, and \n",
    "    #average question orthogonality in the AO model, respectively.\n",
    "    #MO_alpha,MO_kappa,MO_gamma: These are the parameters that go with average question mean, average question variance, and \n",
    "    #maximum question orthogonality in the MO model, respectively.\n",
    "    #OS_alpha and OS_kappa: These are the parameters that go with question mean and question variance in the OS model.\n",
    "    #noise_par: This is a parameter which is used to increase the weight of the individuals' true partworth when making decision\n",
    "    #hitrate_question_list: This is a list of questions which will be used to calculate the hitrate, which is the\n",
    "    #proportion of times that an estimated partworth matches the product selection of a true underlying partworth.\n",
    "    #JMP_questionnaire: This is a dataframe containing the questions coming from a choice design created in JMP.\n",
    "    #                   JMP uses a Bayesian D-optimal design framework to construct the choice design, so we use init_mu\n",
    "    #                   and init_Sig as the prior parameters.\n",
    "    #Method: 0 - Batch Design with AO\n",
    "    #        1 - Batch Design with MO   <------ CAN ADD MORE METHODS IF NEEDED\n",
    "    #        2 - JMP\n",
    "    #        3 - Onestep\n",
    "    #t: time for constructing batch design.\n",
    "    \n",
    "    attr_num = len(init_mu)\n",
    "    \n",
    "    num_true_partworth = len(true_partworths) \n",
    "    \n",
    "    hitrate_total_num_of_questions = len(hitrate_question_list)\n",
    "    \n",
    "    #Set up lists to hold normalized MSE, sqrt determinant, and hitrate. Also save the mu vectors. \n",
    "    \n",
    "    MSE_normalized = [[[] for j in range(num_questions)] for u in range(num_true_partworth)]\n",
    "    \n",
    "    SQRTDET = [[[] for j in range(num_questions)] for u in range(num_true_partworth)]\n",
    "    \n",
    "    HITRATE = [[[] for j in range(num_questions)] for u in range(num_true_partworth)]\n",
    "    \n",
    "    MU = [[[] for j in range(num_questions)] for u in range(num_true_partworth)]\n",
    "    \n",
    "    #Initiate the initial batches for the experiment. Note that we do not need the initial batch in the for loop because\n",
    "    #all true partworths start with the same prior ( N(init_mu, init_Sig) ).\n",
    "    if Method == 0:\n",
    "        batch_AO_init = batch_design_AO(init_mu,init_Sig, AO_MO_batch_size,AO_alpha,AO_kappa,AO_gamma,t_lim = t)[0]\n",
    "    \n",
    "    if Method == 1:\n",
    "        batch_MO_init = batch_design_MO(init_mu,init_Sig, AO_MO_batch_size,MO_alpha,MO_kappa,MO_gamma,t_lim = t)[0]\n",
    "        \n",
    "    for u in range(num_true_partworth):\n",
    "        for i in range(rep_per_partworth):\n",
    "            mu = init_mu\n",
    "            Sig = init_Sig\n",
    "            \n",
    "            for j in range(num_questions):\n",
    "                \n",
    "                #AO batch\n",
    "                if Method == 0:\n",
    "                    if j == 0:\n",
    "                        batch_AO = batch_AO_init\n",
    "                    if (j % AO_MO_batch_size == 0) and (j>0):\n",
    "                        batch_AO = batch_design_AO(mu,Sig,AO_MO_batch_size,AO_alpha,AO_kappa,AO_gamma,t_lim = t)[0]\n",
    "                    [x,y] = batch_AO[j % AO_MO_batch_size]\n",
    "                    \n",
    "                #MO batch\n",
    "                if Method == 1:\n",
    "                    if j == 0:\n",
    "                        batch_MO = batch_MO_init\n",
    "                    if (j % AO_MO_batch_size == 0) and (j>0):\n",
    "                        batch_MO = batch_design_MO(mu,Sig,AO_MO_batch_size,MO_alpha,MO_kappa,MO_gamma,t_lim = t)[0]\n",
    "                    [x,y] = batch_MO[j % AO_MO_batch_size]\n",
    "                    \n",
    "                #JMP \n",
    "                if Method == 2:\n",
    "                    x = np.array(JMP_questionnaire.loc[2*j,'X1':])\n",
    "                    y = np.array(JMP_questionnaire.loc[2*j + 1,'X1':])\n",
    "                \n",
    "                #Onestep\n",
    "                if Method == 3:\n",
    "                    onestep_question = batch_design_AO(mu,Sig,1,OS_alpha,OS_kappa,0,t_lim = t)[0]\n",
    "                    [x,y] = onestep_question[0]\n",
    "                    \n",
    "                #Instantiate gumbel random variables which are used in the product choice selection process. If there is \n",
    "                #only one replication per partworth, we will use a fixed gumbel noise matrix (gumbel_error_terms).\n",
    "                if(rep_per_partworth == 1):\n",
    "                    gum_x = gumbel_error_terms[u][j][0]\n",
    "                    gum_y = gumbel_error_terms[u][j][1]\n",
    "                else:\n",
    "                    gum_x = rng.gumbel(0,1)\n",
    "                    gum_y = rng.gumbel(0,1)\n",
    "                    \n",
    "                #These temp variables will be used in the choice model below in case the user prefers y over x.\n",
    "                x_temp = x\n",
    "                y_temp = y\n",
    "                \n",
    "                #See preference between two products\n",
    "                if (noise_par*np.dot(true_partworths[u],np.array(y)) + gum_y) >= (noise_par*np.dot(true_partworths[u],np.array(x))\n",
    "                                                                               + gum_x):\n",
    "                    x = y_temp\n",
    "                    y = x_temp\n",
    "                    \n",
    "                #Perform moment matching after choice is made.\n",
    "                [mu, Sig] = moment_matching_update(x,y,mu,Sig)\n",
    "                \n",
    "                #add mu to the list of mu vectors\n",
    "                MU[u][j].append(mu)\n",
    "                #Add the normalized MSE between the true partworth and estimator at question j to a list, and add the determinant of\n",
    "                #the covariance matrix at question j into a list. Also add the regular MSE\n",
    "                MSE_normalized[u][j].append(np.square(np.subtract(true_partworths[u]/np.linalg.norm(true_partworths[u],ord = 2),\n",
    "                                                            mu/np.linalg.norm(mu, ord = 2))).mean())\n",
    "                SQRTDET[u][j].append(np.sqrt(np.linalg.det(Sig)))\n",
    "                \n",
    "                #Calculate hitrate for this particular partworth after updating.\n",
    "                hits = 0\n",
    "                for q in hitrate_question_list:\n",
    "                    if np.dot(true_partworths[u],q)*np.dot(mu,q)>=0:\n",
    "                        hits = hits + 1\n",
    "                HITRATE[u][j].append(hits/hitrate_total_num_of_questions)\n",
    "            \n",
    "    return[MSE_normalized,SQRTDET,HITRATE,true_partworths,MU]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176247d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the models batch_AO and batch_MO, and one-step.\n",
    "rng = np.random.default_rng(100) \n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "\n",
    "#signal to noise ratio. \n",
    "#1 - LOW: multiply expectation by 0.25 and covariance by 4.0\n",
    "#2 - REG: multiply expectation by 1.0 and covariance by 1.0\n",
    "#3 - HIGH: multiply expectation by 4.0 and covariance by 0.25\n",
    "snr = int(sys.argv[1])\n",
    "\n",
    "if snr == 1:\n",
    "    init_mu_fit = 0.25*np.array(6*[1.0])\n",
    "    init_Sig_fit = 4.0*np.identity(6)\n",
    "if snr == 2:\n",
    "    init_mu_fit = 1.0*np.array(6*[1.0])\n",
    "    init_Sig_fit = 1.0*np.identity(6)\n",
    "if snr == 3:\n",
    "    init_mu_fit = 4.0*np.array(6*[1.0])\n",
    "    init_Sig_fit = 0.25*np.identity(6)\n",
    "    \n",
    "batch_size_fit = 4\n",
    "    \n",
    "L_fit = [0.5,1.0,2.0]\n",
    "S_fit = [0.5,1.0,2.0]\n",
    "\n",
    "num_random_batches_fit = 1000\n",
    "num_true_partworths_fit = 50\n",
    "\n",
    "#Onestep settings\n",
    "batch_size_OS = 1\n",
    "num_random_batches_OS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e27d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the data in order to estimate the parameters of the AO and MO models\n",
    "average_orthogonality_fit, maximum_orthogonality_fit, average_question_mean_fit, average_question_variance_fit, L_mu_fit, S_Sig_fit, init_sqrt_determinant_fit, average_d_error_fit = norm_AO_MO_data_generation(init_mu_fit, init_Sig_fit, batch_size_fit, L_fit, S_fit, num_random_batches_fit, num_true_partworths_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c058841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the data in order to estimate the parameters of OS model.\n",
    "average_orthogonality_OS, maximum_orthogonality_OS, average_question_mean_OS, average_question_variance_OS, L_mu_OS, S_Sig_OS, init_sqrt_determinant_OS, average_d_error_OS = norm_AO_MO_data_generation(init_mu_fit, init_Sig_fit, batch_size_OS, L_fit, S_fit, num_random_batches_OS, num_true_partworths_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e926b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe of the generated data for fitting the parameters of the AO and MO models\n",
    "df_fit = pd.DataFrame(list(zip(average_orthogonality_fit, maximum_orthogonality_fit, average_question_mean_fit, average_question_variance_fit, L_mu_fit, S_Sig_fit, init_sqrt_determinant_fit, average_d_error_fit)),\n",
    "                  columns =['Avg_Orth', 'Max_Orth', 'Avg_Quest_Mean', 'Avg_Quest_Var', 'L_mu_norm', 'S_Sig_norm', 'Init_Sqrt_Det', 'D_err'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c8fc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fit_OS = pd.DataFrame(list(zip(average_question_mean_OS, average_question_variance_OS, L_mu_OS, S_Sig_OS, init_sqrt_determinant_OS, average_d_error_OS)),\n",
    "                  columns =['Quest_Mean_OS', 'Quest_Var_OS', 'L_mu_norm_OS', 'S_Sig_norm_OS', 'Init_Sqrt_Det_OS', 'D_err_OS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9916b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add some new columns to the dataset. We mean-center the independent variables to attempt to reduce VIF. This will not affect the value of\n",
    "#of the coefficients, except for the intercept.\n",
    "df_fit['log_norm_derr'] = np.log(np.divide(np.array(df_fit['D_err']),np.array(df_fit['Init_Sqrt_Det'])))\n",
    "df_fit['cent_norm_AM'] = np.divide(np.array(df_fit['Avg_Quest_Mean']),np.array(df_fit['L_mu_norm'])) - np.mean(np.divide(np.array(df_fit['Avg_Quest_Mean']),np.array(df_fit['L_mu_norm'])))\n",
    "df_fit['cent_norm_AV'] = np.divide(np.array(df_fit['Avg_Quest_Var']),np.array(df_fit['S_Sig_norm'])) - np.mean(np.divide(np.array(df_fit['Avg_Quest_Var']),np.array(df_fit['S_Sig_norm'])))\n",
    "df_fit['cent_norm_AO'] = np.divide(np.array(df_fit['Avg_Orth']),np.array(df_fit['S_Sig_norm'])) - np.mean(np.divide(np.array(df_fit['Avg_Orth']),np.array(df_fit['S_Sig_norm'])))\n",
    "df_fit['cent_norm_MO'] = np.divide(np.array(df_fit['Max_Orth']),np.array(df_fit['S_Sig_norm'])) - np.mean(np.divide(np.array(df_fit['Max_Orth']),np.array(df_fit['S_Sig_norm'])))\n",
    "\n",
    "df_fit['cent_L_mu_norm'] = df_fit['L_mu_norm'] - np.mean(np.array(df_fit['L_mu_norm']))\n",
    "df_fit['cent_S_Sig_norm'] = df_fit['S_Sig_norm'] - np.mean(np.array(df_fit['S_Sig_norm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b1e085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add some new columns to the OS fit dataset. We mean-center the independent variables to attempt to reduce VIF. This will not affect the value of\n",
    "#of the coefficients, except for the intercept.\n",
    "\n",
    "df_fit_OS['log_norm_derr_OS'] = np.log(np.divide(np.array(df_fit_OS['D_err_OS']),np.array(df_fit_OS['Init_Sqrt_Det_OS'])))\n",
    "df_fit_OS['cent_quest_mean_norm_OS'] = np.divide(np.array(df_fit_OS['Quest_Mean_OS']),np.array(df_fit_OS['L_mu_norm_OS'])) - np.mean(np.divide(np.array(df_fit_OS['Quest_Mean_OS']),np.array(df_fit_OS['L_mu_norm_OS'])))\n",
    "df_fit_OS['cent_quest_var_norm_OS'] = np.divide(np.array(df_fit_OS['Quest_Var_OS']),np.array(df_fit_OS['S_Sig_norm_OS'])) - np.mean(np.divide(np.array(df_fit_OS['Quest_Var_OS']),np.array(df_fit_OS['S_Sig_norm_OS'])))\n",
    "\n",
    "df_fit_OS['cent_L_mu_norm_OS'] = df_fit_OS['L_mu_norm_OS'] - np.mean(np.array(df_fit_OS['L_mu_norm_OS']))\n",
    "df_fit_OS['cent_S_Sig_norm_OS'] = df_fit_OS['S_Sig_norm_OS'] - np.mean(np.array(df_fit_OS['S_Sig_norm_OS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0f4093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save resulting file as a CSV.\n",
    "if snr == 1:\n",
    "    df_fit.to_csv('ThirdseqExpv2_Normalized_AO_MO_Model_Data_mu025_Sig4Ident_batchsize4_L_05_1_2_S_05_1_2_nrb_1000_ntp_50.csv')\n",
    "    df_fit_OS.to_csv('Normalized_OS_Model_Data_mu025_Sig4Ident_batchsize1_L_05_1_2_S_05_1_2_nrb_500_ntp_50_expIIIv2.csv')\n",
    "if snr == 2:\n",
    "    df_fit.to_csv('ThirdseqExpv2_Normalized_AO_MO_Model_Data_mu1_Sig1Ident_batchsize4_L_05_1_2_S_05_1_2_nrb_1000_ntp_50.csv')\n",
    "    df_fit_OS.to_csv('Normalized_OS_Model_Data_mu1_Sig1Ident_batchsize1_L_05_1_2_S_05_1_2_nrb_500_ntp_50_expIIIv2.csv')\n",
    "if snr == 3:\n",
    "    df_fit.to_csv('ThirdseqExpv2_Normalized_AO_MO_Model_Data_mu4_Sig025Ident_batchsize4_L_05_1_2_S_05_1_2_nrb_1000_ntp_50.csv')\n",
    "    df_fit_OS.to_csv('Normalized_OS_Model_Data_mu4_Sig025Ident_batchsize1_L_05_1_2_S_05_1_2_nrb_500_ntp_50_expIIIv2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model with AO\n",
    "model_AO = sm.formula.ols(formula = \"log_norm_derr ~  cent_norm_AM + cent_norm_AV + cent_norm_AO + cent_L_mu_norm + cent_S_Sig_norm\", data = df_fit).fit()\n",
    "parameter_est_AO = model_AO.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec39487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model with MO\n",
    "model_MO = sm.formula.ols(formula = \"log_norm_derr ~  cent_norm_AM + cent_norm_AV + cent_norm_MO + cent_L_mu_norm + cent_S_Sig_norm\", data = df_fit).fit()\n",
    "parameter_est_MO = model_MO.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c8a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model with OS\n",
    "model_OS = sm.formula.ols(formula = \"log_norm_derr_OS ~  cent_quest_mean_norm_OS + cent_quest_var_norm_OS + cent_L_mu_norm_OS + cent_S_Sig_norm_OS\", data = df_fit_OS).fit()\n",
    "parameter_est_OS = model_OS.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50a2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model parameters in txt file\n",
    "if snr == 1:\n",
    "    params_est = np.array([parameter_est_AO[1],parameter_est_AO[2],parameter_est_AO[3],parameter_est_MO[1],parameter_est_MO[2],parameter_est_MO[3], parameter_est_OS[1],parameter_est_OS[2]])\n",
    "    np.savetxt('ThirdseqExpv2_modelparams_lowsnr.txt',params_est)\n",
    "if snr == 2:\n",
    "    params_est = np.array([parameter_est_AO[1],parameter_est_AO[2],parameter_est_AO[3],parameter_est_MO[1],parameter_est_MO[2],parameter_est_MO[3], parameter_est_OS[1],parameter_est_OS[2]])\n",
    "    np.savetxt('ThirdseqExpv2_modelparams_medsnr.txt',params_est)\n",
    "if snr == 3:\n",
    "    params_est = np.array([parameter_est_AO[1],parameter_est_AO[2],parameter_est_AO[3],parameter_est_MO[1],parameter_est_MO[2],parameter_est_MO[3], parameter_est_OS[1],parameter_est_OS[2]])\n",
    "    np.savetxt('ThirdseqExpv2_modelparams_highsnr.txt',params_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c028bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings for experiment\n",
    "rng = np.random.default_rng(100)\n",
    "\n",
    "if snr == 1:\n",
    "    mu_exp = 0.25*np.array(6*[1.0])\n",
    "    Sig_exp = 4.0*np.identity(6)\n",
    "if snr == 2:\n",
    "    mu_exp = 1.0*np.array(6*[1.0])\n",
    "    Sig_exp = 1.0*np.identity(6)\n",
    "if snr == 3:\n",
    "    mu_exp = 4.0*np.array(6*[1.0])\n",
    "    Sig_exp = 0.25*np.identity(6)\n",
    "\n",
    "num_true_partworths_exp = 100\n",
    "true_partworth_exp = []\n",
    "\n",
    "#There will be 100 true partworths\n",
    "for t in range(num_true_partworths_exp):\n",
    "    true_partworth_exp.append(rng.multivariate_normal(mu_exp,Sig_exp))\n",
    "\n",
    "#only one repetition per each partworth    \n",
    "rep_per_partworth_exp = 1\n",
    "num_questions_exp = 16\n",
    "batch_size_exp = 4\n",
    "\n",
    "gumbel_error_terms_exp = [[[np.random.gumbel(0,1) for k in range(2)] for j in range(num_questions_exp)] for i in range(num_true_partworths_exp)]\n",
    "\n",
    "noise_par_exp = 1.0\n",
    "\n",
    "AO_alpha_exp = parameter_est_AO[1]\n",
    "AO_kappa_exp = parameter_est_AO[2]\n",
    "AO_gamma_exp = parameter_est_AO[3]\n",
    "\n",
    "MO_alpha_exp = parameter_est_MO[1]\n",
    "MO_kappa_exp = parameter_est_MO[2]\n",
    "MO_gamma_exp = parameter_est_MO[3]\n",
    "\n",
    "OS_alpha_exp = parameter_est_OS[1]\n",
    "OS_kappa_exp = parameter_est_OS[2]\n",
    "\n",
    "#Create a list of questions for hitrate\n",
    "hitrate_question_list_exp = product_diff_list(6)\n",
    "\n",
    "if snr == 1:\n",
    "    JMP_df = pd.read_csv('JMP_attr_6_exp_1_cov_1_loc_025_scale_4_quest_16.csv')\n",
    "    JMP_df_exp = JMP_df.loc[:,'X1':]\n",
    "if snr == 2:\n",
    "    JMP_df = pd.read_csv('JMP_attr_6_exp_1_cov_1_loc_1_scale_1_quest_16.csv')\n",
    "    JMP_df_exp = JMP_df.loc[:,'X1':]\n",
    "if snr == 3:\n",
    "    JMP_df = pd.read_csv('JMP_attr_6_exp_1_cov_1_loc_4_scale_025_quest_16.csv')\n",
    "    JMP_df_exp = JMP_df.loc[:,'X1':]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbab58ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch_AO\n",
    "#Set up random number seed\n",
    "rng = np.random.default_rng(100) \n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "\n",
    "[Norm_MSE_AO, SQRTDET_AO, HITRATE_AO, true_partworths_AO, MU_AO] = sequential_AO_MO_experiment(mu_exp,Sig_exp,true_partworth_exp, gumbel_error_terms_exp, rep_per_partworth_exp,\n",
    "                                                                                              num_questions_exp, batch_size_exp, AO_alpha_exp, AO_kappa_exp, AO_gamma_exp,\n",
    "                                                                                              MO_alpha_exp, MO_kappa_exp, MO_gamma_exp, OS_alpha_exp, OS_kappa_exp, noise_par_exp, hitrate_question_list_exp,\n",
    "                                                                                              JMP_df_exp, Method = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006d38f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch_MO\n",
    "#Set up random number seed\n",
    "rng = np.random.default_rng(100) \n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "\n",
    "[Norm_MSE_MO, SQRTDET_MO, HITRATE_MO, true_partworths_MO, MU_MO] = sequential_AO_MO_experiment(mu_exp,Sig_exp,true_partworth_exp, gumbel_error_terms_exp, rep_per_partworth_exp,\n",
    "                                                                                              num_questions_exp, batch_size_exp, AO_alpha_exp, AO_kappa_exp, AO_gamma_exp,\n",
    "                                                                                              MO_alpha_exp, MO_kappa_exp, MO_gamma_exp, OS_alpha_exp, OS_kappa_exp, noise_par_exp, hitrate_question_list_exp,\n",
    "                                                                                              JMP_df_exp, Method = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd49e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JMP\n",
    "#Set up random number seed\n",
    "rng = np.random.default_rng(100) \n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "\n",
    "[Norm_MSE_JMP, SQRTDET_JMP, HITRATE_JMP, true_partworths_JMP, MU_JMP] = sequential_AO_MO_experiment(mu_exp,Sig_exp,true_partworth_exp, gumbel_error_terms_exp, rep_per_partworth_exp,\n",
    "                                                                                              num_questions_exp, batch_size_exp, AO_alpha_exp, AO_kappa_exp, AO_gamma_exp,\n",
    "                                                                                              MO_alpha_exp, MO_kappa_exp, MO_gamma_exp, OS_alpha_exp, OS_kappa_exp, noise_par_exp, hitrate_question_list_exp,\n",
    "                                                                                              JMP_df_exp, Method = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad94c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OS\n",
    "#Set up random number seed\n",
    "rng = np.random.default_rng(100) \n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "\n",
    "[Norm_MSE_OS, SQRTDET_OS, HITRATE_OS, true_partworths_OS, MU_OS] = sequential_AO_MO_experiment(mu_exp,Sig_exp,true_partworth_exp, gumbel_error_terms_exp, rep_per_partworth_exp,\n",
    "                                                                                              num_questions_exp, batch_size_exp, AO_alpha_exp, AO_kappa_exp, AO_gamma_exp,\n",
    "                                                                                              MO_alpha_exp, MO_kappa_exp, MO_gamma_exp, OS_alpha_exp, OS_kappa_exp, noise_par_exp, hitrate_question_list_exp,\n",
    "                                                                                              JMP_df_exp, Method = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180cd658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct the columns of the dataframe. This is for the case where there are 100 true partworths.\n",
    "\n",
    "data_collection = [[Norm_MSE_AO, SQRTDET_AO, HITRATE_AO, true_partworths_AO, MU_AO],[Norm_MSE_MO, SQRTDET_MO, HITRATE_MO, true_partworths_MO, MU_MO],\n",
    "                  [Norm_MSE_JMP, SQRTDET_JMP, HITRATE_JMP, true_partworths_JMP, MU_JMP],[Norm_MSE_OS, SQRTDET_OS, HITRATE_OS, true_partworths_OS, MU_OS]]\n",
    "\n",
    "method_range = 4\n",
    "\n",
    "Norm_MSE_col = []\n",
    "SQRTDET_col = []\n",
    "HITRATE_col = []\n",
    "partworthID_col = []\n",
    "Method_col = []\n",
    "\n",
    "rep_col = []\n",
    "quest_col = []\n",
    "\n",
    "method_types = ['AO','MO','JMP','OS']\n",
    "\n",
    "#Columns here are the entries in the ith component of the true partworth and estimator mu. There are 6 attributes.\n",
    "true_partworths_col = [[] for i in range(6)]\n",
    "MU_col = [[] for i in range(6)]\n",
    "\n",
    "#Construct the Norm_MSE, SQRTDET, and HITRATE columns\n",
    "#Methods are 0=Batch_AO, 1=Batch_MO, 2=JMP, 3=OS\n",
    "for Meth in range(method_range):\n",
    "    for part in range(100):\n",
    "        for r in range(rep_per_partworth_exp):\n",
    "            for q in range(num_questions_exp):\n",
    "                Norm_MSE_col.append(data_collection[Meth][0][part][q][r])\n",
    "                SQRTDET_col.append(data_collection[Meth][1][part][q][r])\n",
    "                \n",
    "                Method_col.append(Meth)\n",
    "                partworthID_col.append(part)\n",
    "                \n",
    "                rep_col.append(r + 1)\n",
    "                quest_col.append(q + 1)\n",
    "                \n",
    "                HITRATE_col.append(data_collection[Meth][2][part][q][r])\n",
    "                \n",
    "                for i in range(6):\n",
    "                    true_partworths_col[i].append(data_collection[Meth][3][part][i])\n",
    "                    MU_col[i].append(data_collection[Meth][4][part][q][r][i])\n",
    "                    \n",
    "#Data for the mu vector and true partworths\n",
    "df_columns_data = [Method_col,partworthID_col,rep_col,quest_col,Norm_MSE_col,SQRTDET_col,HITRATE_col]\n",
    "\n",
    "for i in range(6):\n",
    "    df_columns_data.append(MU_col[i])\n",
    "\n",
    "for i in range(6):\n",
    "    df_columns_data.append(true_partworths_col[i])\n",
    "    \n",
    "df_columns_data = np.array(df_columns_data).T\n",
    "\n",
    "#Make column names\n",
    "df_columns_names = ['Method', 'PartworthID','Rep','Question','Norm_MSE','SQRTDet','HITRATE']\n",
    "\n",
    "for i in range(6):\n",
    "    df_columns_names.append('Mu_' + str(i+1))\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    df_columns_names.append('True_' + str(i+1))\n",
    "    \n",
    "#Make dataframe. The number of columns is 7 + 2*attributes. The number of rows is method_range*100*1*num_questions\n",
    "#100 comes from the 100 true_partworths that we use.\n",
    "df_data = pd.DataFrame(data = df_columns_data, index = range(1,method_range*100*rep_per_partworth_exp*num_questions_exp + 1),\n",
    "                      columns = df_columns_names)\n",
    "\n",
    "#Here we add a column for normalized D-error, and it's log transformation.\n",
    "df_data[\"Normalized_SQRTDet\"] = df_data[\"SQRTDet\"]/(np.sqrt(np.linalg.det(Sig_exp)))\n",
    "df_data[\"Log_Normalized_SQRTDet\"] = np.log(df_data[\"Normalized_SQRTDet\"])\n",
    "\n",
    "if snr == 1:\n",
    "    df_data.to_csv('ThirdseqExpv2_sequential_data_AO_MO_JMP_OS_attr_'+str(6)+ '_exp_'+str(1)+'_cov_'+str(1) +\n",
    "               '_loc_' + str(25) +'_scale_'+ str(4) + '_quest_'+ str(num_questions_exp)+'_batch_'+str(batch_size_exp)+'.csv',\n",
    "               index=True,header=True)\n",
    "if snr == 2:\n",
    "    df_data.to_csv('ThirdseqExpv2_sequential_data_AO_MO_JMP_OS_attr_'+str(6)+ '_exp_'+str(1)+'_cov_'+str(1) +\n",
    "               '_loc_' + str(1) +'_scale_'+ str(1) + '_quest_'+ str(num_questions_exp)+'_batch_'+str(batch_size_exp)+'.csv',\n",
    "               index=True,header=True)\n",
    "if snr == 3:\n",
    "    df_data.to_csv('ThirdseqExpv2_sequential_data_AO_MO_JMP_OS_attr_'+str(6)+ '_exp_'+str(1)+'_cov_'+str(1) +\n",
    "               '_loc_' + str(4) +'_scale_'+ str(25) + '_quest_'+ str(num_questions_exp)+'_batch_'+str(batch_size_exp)+'.csv',\n",
    "               index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0093473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determinant, 100 partworths\n",
    "#fig = plt.figure()\n",
    "#sns.lineplot(data = df_data, x = 'Question',y = 'SQRTDet', hue = 'Method', palette = 'deep').set(\n",
    "    #title='Square Root of Determinant')\n",
    "#plt.legend(labels=[\"AO\",\"MO\",\"JMP\",\"OS\"])\n",
    "#if snr == 1:\n",
    "    #fig.savefig('ThirdseqExpv2_Det_AO_MO_JMP_OS_attr_'+str(6)+'_exp_'+str(1)+'_cov_'+str(1)+'_loc_'+str(25)+'_scale_'+str(4)+'_quest_'+ str(num_questions_exp)+'_batch_'+str(batch_size_exp)+'.jpg',bbox_inches='tight')\n",
    "#if snr == 2:\n",
    "    #fig.savefig('ThirdseqExpv2_Det_AO_MO_JMP_OS_attr_'+str(6)+'_exp_'+str(1)+'_cov_'+str(1)+'_loc_'+str(1)+'_scale_'+str(1)+'_quest_'+ str(num_questions_exp)+'_batch_'+str(batch_size_exp)+'.jpg',bbox_inches='tight')\n",
    "#if snr == 3:\n",
    "    #fig.savefig('ThirdseqExpv2_Det_AO_MO_JMP_OS_attr_'+str(6)+'_exp_'+str(1)+'_cov_'+str(1)+'_loc_'+str(4)+'_scale_'+str(25)+'_quest_'+ str(num_questions_exp)+'_batch_'+str(batch_size_exp)+'.jpg',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d4a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized MSE, 100 partworths\n",
    "#fig = plt.figure()\n",
    "#sns.lineplot(data = df_data, x = 'Question',y = 'Norm_MSE', hue = 'Method', palette = 'deep').set(\n",
    "    #title='Normalized MSE')\n",
    "#plt.legend(labels=[\"AO\",\"MO\",\"JMP\",\"OS\"])\n",
    "#if snr == 1:\n",
    "    #fig.savefig('ThirdseqExpv2_Normmse_AO_MO_JMP_OS_attr_'+str(6)+'_exp_'+str(1)+'_cov_'+str(1)+'_loc_'+str(25)+'_scale_'+ str(4) +'_quest_'+ str(num_questions_exp)+'_batch_'+str(batch_size_exp)+'.jpg',bbox_inches='tight')\n",
    "#if snr == 2:\n",
    "    #fig.savefig('ThirdseqExpv2_Normmse_AO_MO_JMP_OS_attr_'+str(6)+'_exp_'+str(1)+'_cov_'+str(1)+'_loc_'+str(1)+'_scale_'+ str(1) +'_quest_'+ str(num_questions_exp)+'_batch_'+str(batch_size_exp)+'.jpg',bbox_inches='tight')\n",
    "#if snr == 3:\n",
    "    #fig.savefig('ThirdseqExpv2_Normmse_AO_MO_JMP_OS_attr_'+str(6)+'_exp_'+str(1)+'_cov_'+str(1)+'_loc_'+str(4)+'_scale_'+ str(25) +'_quest_'+ str(num_questions_exp)+'_batch_'+str(batch_size_exp)+'.jpg',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798aac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log normalized D-error, 100 partworths\n",
    "if snr == 1:\n",
    "    #Determinant of loc=25 scale=4, using log_norm d-err\n",
    "    fig = plt.figure()\n",
    "    sns.lineplot(data = df_data, x = 'Question',y = 'Log_Normalized_SQRTDet', hue = 'Method', style = 'Method', palette = 'deep').set(\n",
    "        title='Logarithm of Normalized D-error: Low SNR')\n",
    "    plt.legend(labels=[\"MIP-AC\",\"MIP-MC\",\"JMP\",\"OS\"])\n",
    "    plt.xlabel(\"Question\")\n",
    "    plt.ylabel(\"Log Norm D-Err\")\n",
    "    fig.savefig('ThirdseqExpv2_Det_AO_MO_JMP_OS_attr_'+str(6)+'_exp_'+str(1)+'_cov_'+str(1)+'_loc_'+str(25)+'_scale_'+str(4)+'_quest_'+ str(16)+'_batch_'+str(4)+'_LogNorm.png',bbox_inches='tight')\n",
    "if snr == 2:\n",
    "    #Determinant of loc=1 scale=1, using log_norm d-err\n",
    "    fig = plt.figure()\n",
    "    sns.lineplot(data = df_data, x = 'Question',y = 'Log_Normalized_SQRTDet', hue = 'Method', style = 'Method', palette = 'deep').set(\n",
    "        title='Logarithm of Normalized D-error: Medium SNR')\n",
    "    plt.legend(labels=[\"MIP-AC\",\"MIP-MC\",\"JMP\",\"OS\"])\n",
    "    plt.xlabel(\"Question\")\n",
    "    plt.ylabel(\"Log Norm D-Err\")\n",
    "    fig.savefig('ThirdseqExpv2_Det_AO_MO_JMP_OS_attr_'+str(6)+'_exp_'+str(1)+'_cov_'+str(1)+'_loc_'+str(1)+'_scale_'+str(1)+'_quest_'+ str(16)+'_batch_'+str(4)+'_LogNorm.png',bbox_inches='tight')\n",
    "if snr == 3:\n",
    "    #Determinant of loc=4 scale=25, using log_norm d-err\n",
    "    fig = plt.figure()\n",
    "    sns.lineplot(data = df_data, x = 'Question',y = 'Log_Normalized_SQRTDet', hue = 'Method', style = 'Method', palette = 'deep').set(\n",
    "        title='Logarithm of Normalized D-Error: High SNR')\n",
    "    plt.legend(labels=[\"MIP-AC\",\"MIP-MC\",\"JMP\",\"OS\"])\n",
    "    plt.xlabel(\"Question\")\n",
    "    plt.ylabel(\"Log Norm D-Err\")\n",
    "    fig.savefig('ThirdseqExpv2_Det_AO_MO_JMP_OS_attr_'+str(6)+'_exp_'+str(1)+'_cov_'+str(1)+'_loc_'+str(4)+'_scale_'+str(25)+'_quest_'+ str(16)+'_batch_'+str(4)+'_LogNorm.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81cefbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized MSE, 100 partworths\n",
    "if snr == 1:\n",
    "    #Norm MSE of loc=0.25 and scale=4\n",
    "    fig = plt.figure()\n",
    "    sns.lineplot(data = df_data, x = 'Question',y = 'Norm_MSE', hue = 'Method', style = 'Method', palette = 'deep').set(\n",
    "        title='Normalized MSE: Low SNR')\n",
    "    plt.legend(labels=[\"MIP-AC\",\"MIP-MC\",\"JMP\",\"OS\"])\n",
    "    plt.xlabel(\"Question\")\n",
    "    plt.ylabel(\"Norm MSE\")\n",
    "    fig.savefig('ThirdseqExpv2_Normmse_MIPAC_MIPMC_JMP_OS_attr_'+str(6)+'_exp_'+str(1)+'_cov_'+str(1)+'_loc_'+str(25)+'_scale_'+ str(4) +'_quest_'+ str(16)+'_batch_'+str(4)+'.png',bbox_inches='tight')\n",
    "if snr == 2:\n",
    "    #Norm MSE of loc=1 and scale=1\n",
    "    fig = plt.figure()\n",
    "    sns.lineplot(data = df_data, x = 'Question',y = 'Norm_MSE', hue = 'Method', style = 'Method', palette = 'deep').set(\n",
    "        title='Normalized MSE: Medium SNR')\n",
    "    plt.legend(labels=[\"MIP-AC\",\"MIP-MC\",\"JMP\",\"OS\"])\n",
    "    plt.xlabel(\"Question\")\n",
    "    plt.ylabel(\"Norm MSE\")\n",
    "    fig.savefig('ThirdseqExpv2_Normmse_MIPAC_MIPMC_JMP_OS_attr_'+str(6)+'_exp_'+str(1)+'_cov_'+str(1)+'_loc_'+str(1)+'_scale_'+ str(1) +'_quest_'+ str(16)+'_batch_'+str(4)+'.png',bbox_inches='tight')\n",
    "if snr == 3:\n",
    "    #Norm MSE of loc=4 and scale=0.25\n",
    "    fig = plt.figure()\n",
    "    sns.lineplot(data = df_data, x = 'Question',y = 'Norm_MSE', hue = 'Method', style = 'Method', palette = 'deep').set(\n",
    "        title='Normalized MSE: High SNR')\n",
    "    plt.legend(labels=[\"MIP-AC\",\"MIP-MC\",\"JMP\",\"OS\"])\n",
    "    plt.xlabel(\"Question\")\n",
    "    plt.ylabel(\"Norm MSE\")\n",
    "    fig.savefig('ThirdseqExpv2_Normmse_MIPAC_MIPMC_JMP_OS_attr_'+str(6)+'_exp_'+str(1)+'_cov_'+str(1)+'_loc_'+str(4)+'_scale_'+ str(25) +'_quest_'+ str(16)+'_batch_'+str(4)+'.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dab49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect data from the last question, partition with respect to the \n",
    "#method type\n",
    "df_data_AO_lastquest = df_data[(df_data['Question'] == 16) & (df_data['Method'] == 0)]\n",
    "df_data_MO_lastquest = df_data[(df_data['Question'] == 16) & (df_data['Method'] == 1)]\n",
    "df_data_JMP_lastquest = df_data[(df_data['Question'] == 16) & (df_data['Method'] == 2)]\n",
    "df_data_OS_lastquest = df_data[(df_data['Question'] == 16) & (df_data['Method'] == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af6ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute means and 95% confidence intervals of the Log Normalized D-error for the last question for each method\n",
    "AO_lastquest_mean_CI = mean_CI_95(df_data_AO_lastquest['Log_Normalized_SQRTDet'])\n",
    "MO_lastquest_mean_CI = mean_CI_95(df_data_MO_lastquest['Log_Normalized_SQRTDet'])\n",
    "JMP_lastquest_mean_CI = mean_CI_95(df_data_JMP_lastquest['Log_Normalized_SQRTDet'])\n",
    "OS_lastquest_mean_CI = mean_CI_95(df_data_OS_lastquest['Log_Normalized_SQRTDet'])\n",
    "\n",
    "mean_CI_info = {'AO' : AO_lastquest_mean_CI, 'MO' : MO_lastquest_mean_CI, 'JMP' : JMP_lastquest_mean_CI,\n",
    "                'OS' : OS_lastquest_mean_CI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcffeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save mean and CI information to a CSV\n",
    "if snr == 1:\n",
    "    # open file for writing, \"w\" is writing\n",
    "    w = csv.writer(open(\"low_snr_mean_CI_lastquest.csv\", \"w\"))\n",
    "    # loop over dictionary keys and values\n",
    "    for key, val in mean_CI_info.items():\n",
    "        # write every key and value to file\n",
    "        w.writerow([key,val[0],val[1],val[2]])\n",
    "if snr == 2:\n",
    "    # open file for writing, \"w\" is writing\n",
    "    w = csv.writer(open(\"med_snr_mean_CI_lastquest.csv\", \"w\"))\n",
    "    # loop over dictionary keys and values\n",
    "    for key, val in mean_CI_info.items():\n",
    "        # write every key and value to file\n",
    "        w.writerow([key,val[0],val[1],val[2]])\n",
    "if snr == 3:\n",
    "    # open file for writing, \"w\" is writing\n",
    "    w = csv.writer(open(\"high_snr_mean_CI_lastquest.csv\", \"w\"))\n",
    "    # loop over dictionary keys and values\n",
    "    for key, val in mean_CI_info.items():\n",
    "        # write every key and value to file\n",
    "        w.writerow([key,val[0],val[1],val[2]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
