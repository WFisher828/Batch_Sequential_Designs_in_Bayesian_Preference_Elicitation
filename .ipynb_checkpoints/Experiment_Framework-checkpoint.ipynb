{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e2cb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This module \"Experiment_Framework\" has functions which are used in conducting numerical experiments. \n",
    "#These functions include:\n",
    "#1. product_diff_list\n",
    "#2. question_extractor\n",
    "#3. enum_two_step\n",
    "#4. enum_two_step_opt_worst\n",
    "#5. quantile_test_enum_data\n",
    "#6. MSE_det_test \n",
    "#7. new_mse_det_experiment\n",
    "\n",
    "# (IGNORE) 6,7,8 can be consolidated (AND HAVE BEEN). MAKE A FUNCTION TO PLOT DATA FROM MSE_det_test, THIS WILL REPLACE WHAT \n",
    "# MSE_test_2 and det_test_2 did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b22183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gurobipy as gp # Feb 27 2023\n",
    "from gurobipy import GRB # Feb 27 2023\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "import sklearn.datasets\n",
    "import scipy.integrate #Feb27 2023\n",
    "import math # Feb 27 2023\n",
    "\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\wsfishe\\Desktop\\PreferenceElicitationCode')\n",
    "from Questionnaire_Procedure import moment_matching_update, g_opt, two_stage_g_opt,two_step_g_acq, g_opt_multi_lvl, multlvl_two_step_g_acq #Feb 27, 2023 was \" * \"\n",
    "from Baseline_Functions_Definitions import g_fun_linear_regression\n",
    "from Batch_Design_and_Rollout import batch_design_delta_penalty, question_selection_prob, rollout, monte_carlo_rollout,rollout_with_batch_design_acquisition, coordinate_exchange_acq\n",
    "\n",
    "#From Questionnaire_Procedure we are importing:\n",
    "\n",
    "#PACKAGES:\n",
    "# gurobipy\n",
    "# numpy\n",
    "# scipy.integrate\n",
    "# math\n",
    "\n",
    "#FUNCTIONS:\n",
    "# z_expectation_variance (originally from Baseline_Functions_Definitions)\n",
    "# g_fun (originally from Baseline_Functions_Definitions)\n",
    "# moment_matching_update\n",
    "# g_opt\n",
    "# two_stage_g_opt\n",
    "# two_step_g_acq\n",
    "\n",
    "#!!NO LONGER USING!!\n",
    "#VARIABLES:\n",
    "#mu_log_coeff = 0.03596804494858049\n",
    "#Sig_log_coeff = -0.020785433813507195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0cab8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS WILL NEED TO BE MOVED!!!\n",
    "#This is used to instantiate the coefficient values for optimization when there are 6 attributes.\n",
    "#mu_log_coeff_6,Sig_log_coeff_6 = g_fun_linear_regression(0,12.70,0.1,42.0,24,84)\n",
    "#print(mu_log_coeff_6,Sig_log_coeff_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f9d633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVE!!!\n",
    "#print(mu_log_coeff_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9673b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS MAY BE REMOVED!!!\n",
    "#This is used to instantiate the coefficient values for optimization when there are 12 attributes.\n",
    "#mu_log_coeff_12,Sig_log_coeff_12 = g_fun_linear_regression(0, 24.50, 0.1, 156.0, 49, 312)\n",
    "#print(mu_log_coeff_12,Sig_log_coeff_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f71f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS MAY BE REMOVED!!!\n",
    "#This is used to instantiate the linear approximation coefficient values for optimization in the\n",
    "#multi-level case when there are 6 attributes and 3 levels per attribute. \n",
    "#mu_log_coeff_6_mult_3, Sig_log_coeff_6_mult_3 = g_fun_linear_regression(0.0, 36.0, 0.1, 2*4.0*42.0, 72, 2*2*4*42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42c7610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVE!!!\n",
    "#print(mu_log_coeff_6_mult_3,Sig_log_coeff_6_mult_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ebe9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a set that has all the differences between binary products\n",
    "\n",
    "def product_diff_list(n):\n",
    "    #n: the number of attributes of the products\n",
    "    \n",
    "    #Example of itertools.product:\n",
    "    #itertools.product(range(2), repeat = 3) --> 000 001 010 011 100 101 110 111\n",
    "    p_d_l = list(itertools.product([-1.0,0.0,1.0],repeat = n))\n",
    "    \n",
    "    #Return the index of the tuple with all 0s.\n",
    "    zero_index = p_d_l.index(tuple([0]*n))\n",
    "\n",
    "    #Note that at this point, product_diff_list contains some redundant information. Due to\n",
    "    #the symmetry of the one-step and two-step acquisition function in terms of question mean, question pairs such as \n",
    "    #(-1,-1,-1,...,-1) and (1,1,1,...,1) (i.e. negative multiples) will evaluate as the same under the one-step and two-step\n",
    "    #acquisition functions. Due to the structure of product_diff_list, we can remove every question pair before and including\n",
    "    #the question pair with all zero entries in order to remove this redundant information.\n",
    "    for i in range(0,zero_index + 1):\n",
    "        p_d_l.pop(0)\n",
    "    \n",
    "    p_d_l = [np.array(a) for a in p_d_l]\n",
    "    return p_d_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a32cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a set that has all the differences between quantitative multi-level products. For simplicity, we assume that\n",
    "#the number of levels are the same among all attributes\n",
    "\n",
    "def multlvl_product_diff_list(n,num_lvl):\n",
    "    #n: the number of attributes of the products\n",
    "    #num_lvl: this is a integer declaring the number of levels for each attribute. For example, n=3, num_lvl=4 denotes\n",
    "    #three attributes with 4 quantitative levels each. Each attribute in this case\n",
    "    #would be encode with levels 0, 1, 2, and 3.\n",
    "    \n",
    "    ml_p_d_l = list(itertools.product(range(-(num_lvl-1),num_lvl), repeat = n))\n",
    "    \n",
    "    #Return the index of the tuple with all 0s.\n",
    "    zero_index = ml_p_d_l.index(tuple([0]*n))\n",
    "    \n",
    "    #Note that at this point, product_diff_list contains some redundant information. Due to\n",
    "    #the symmetry of the one-step and two-step acquisition function in terms of question mean, question pairs such as \n",
    "    #(-1,-1,-1,...,-1) and (1,1,1,...,1) (i.e. negative multiples) will evaluate as the same under the one-step and two-step\n",
    "    #acquisition functions. Due to the structure of product_diff_list, we can remove every question pair before and including\n",
    "    #the question pair with all zero entries in order to remove this redundant information.\n",
    "    for i in range(0,zero_index + 1):\n",
    "        ml_p_d_l.pop(0)\n",
    "    \n",
    "    ml_p_d_l = [np.array(a) for a in ml_p_d_l]\n",
    "\n",
    "    return ml_p_d_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8160507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS MAY BE MOVED!!!\n",
    "#Example8: product_diff_list\n",
    "#ex8_n = 3\n",
    "#print(product_diff_list(ex8_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ba2442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS MAY BE MOVED!!!\n",
    "#Example8a: multlvl_product_diff_list\n",
    "#ex8a_n = 3\n",
    "#ex8a_num_lvl = 3\n",
    "#print(multlvl_product_diff_list(ex8a_n,ex8a_num_lvl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35339114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a trinary vector of 0, 1, and -1, find two binary products whose difference is the trinary vector.\n",
    "def question_extractor(prod):\n",
    "    #prod: This is a trinary vector of 0, 1, and -1 that represents the difference between two products, which\n",
    "    #are represented by binary vectors.\n",
    "    \n",
    "    x = [0]*len(prod)\n",
    "    y = [0]*len(prod)\n",
    "    for i in range(0,len(prod)):\n",
    "        if prod[i] == 1.0:\n",
    "            x[i] = 1.0\n",
    "            y[i] = 0.0\n",
    "        if prod[i] == 0.0:\n",
    "            x[i] = 0.0\n",
    "            y[i] = 0.0\n",
    "        if prod[i] == -1.0:\n",
    "            x[i] = 0.0\n",
    "            y[i] = 1.0\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bf00a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a vector d with entries coming from -(m-1), -(m-2),...,0,...,m-2,m-1, find two vectors x and y with entries\n",
    "#in 0,1,...,m-2,m-1 whose difference is d.\n",
    "def multlvl_question_extractor(prod,num_lvl):\n",
    "    #prod: This is a vector with entries coming from -(m-1), -(m-2),...,0,...,m-2,m-1 \n",
    "    #that represents the difference between two products, where the two products have attributes with entrie coming from\n",
    "    #0,1,...,m-2,m-1\n",
    "    #num_lvl: This is the number of levels in each attribute of the product.\n",
    "    \n",
    "    n = len(prod)\n",
    "    \n",
    "    x = [0]*n\n",
    "    y = [0]*n\n",
    "    for i in range(n):\n",
    "        for j in range(-(num_lvl - 1),num_lvl):\n",
    "            if prod[i]==j and j<0:\n",
    "                x[i] = 0\n",
    "                y[i] = j\n",
    "            if prod[i]==j and j==0:\n",
    "                x[i] = 0\n",
    "                y[i] = 0\n",
    "            if prod[i]==j and j>0:\n",
    "                x[i] = j\n",
    "                y[i] = 0\n",
    "    \n",
    "    return x,y          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d856cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function which returns a list of all the enumerated two-step acquisition values of a given product set. We use the exact\n",
    "#two-step g function. We return the prod_diff_set in case there was sampling done and we have interest in the sampled\n",
    "#question pairs. We also return a list of all the first stage and two second stage questions.\n",
    "def enum_two_step(mu_vec, Sig_mat, mu_log_coeff, Sig_log_coeff, prod_diff_set, prod_samp_num = 0):\n",
    "    #mu_vec: expectation of prior on beta\n",
    "    #Sig_mat: covariance matrix of prior on beta\n",
    "    #mu_log_coeff and Sig_log_coeff: coefficients that are used in the optimization prblem.\n",
    "    #prod_diff_set: set of question pairs we are enumerating over. This should be created by using product_diff_list.\n",
    "    #prod_samp_num: Should be a positive integer. Used in obtaining a random sample of product pairs if needed.\n",
    "    \n",
    "    #Sample a number of product pairs from the product pairs list, if needed in the case where\n",
    "    #there are a large number of attributes. Will possibly need a seed for random.sample()\n",
    "    if prod_samp_num>0:\n",
    "        prod_diff_set = random.sample(prod_diff_set,prod_samp_num)\n",
    "    \n",
    "    #define a list to store enumerated two-step values, along with a list to save the first stage and two second stage\n",
    "    #questions.\n",
    "    prod_diff_len = len(prod_diff_set)\n",
    "    two_step_g_val = [0]*prod_diff_len\n",
    "    first_stage_second_stage_questions = [0]*prod_diff_len\n",
    "    \n",
    "    #calculate two-step values for all question pairs\n",
    "    for i in range(0, prod_diff_len):\n",
    "        x_0,y_0 = question_extractor(prod_diff_set[i])\n",
    "        two_step = two_step_g_acq(mu_vec,Sig_mat,mu_log_coeff,Sig_log_coeff,x_0,y_0)\n",
    "        two_step_g_val[i] = two_step[0]\n",
    "        first_stage_second_stage_questions[i] = [x_0,y_0,two_step[1],two_step[2],two_step[3],two_step[4]]\n",
    "        \n",
    "    return two_step_g_val,prod_diff_set,first_stage_second_stage_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d5f63c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function which returns a list of all the enumerated two-step acquisition values of a given product set in the\n",
    "#multi-level attribute setting. We use the exact\n",
    "#two-step g function. We return the prod_diff_set in case there was sampling done and we have interest in the sampled\n",
    "#question pairs. We also return a list of all the first stage and two second stage questions.\n",
    "\n",
    "def multlvl_enum_two_step(mu_vec, Sig_mat, mu_log_coeff, Sig_log_coeff, multlvl_prod_diff_set, num_lvl, prod_samp_num = 0):\n",
    "    #mu_vec: expectation of prior on beta\n",
    "    #Sig_mat: covariance matrix of prior on beta\n",
    "    #mu_log_coeff and Sig_log_coeff: coefficients that are used in the optimization prblem.\n",
    "    #multlvl_prod_diff_set: set of question pairs we are enumerating over. This should be created by using multlvl_product_diff_list.\n",
    "    #num_lvl: This is the number of levels in each attribute of the product.\n",
    "    #prod_samp_num: Should be a positive integer. Used in obtaining a random sample of product pairs if needed.\n",
    "    \n",
    "    #Sample a number of product pairs from the product pairs list, if needed in the case where\n",
    "    #there are a large number of attributes. Will possibly need a seed for random.sample()\n",
    "    if prod_samp_num>0:\n",
    "        multlvl_prod_diff_set = random.sample(multlvl_prod_diff_set,prod_samp_num)\n",
    "        \n",
    "    #define a list to store enumerated two-step values, along with a list to save the first stage and two second stage\n",
    "    #questions.\n",
    "    multlvl_prod_diff_len = len(multlvl_prod_diff_set)\n",
    "    multlvl_two_step_g_val = [0]*multlvl_prod_diff_len\n",
    "    first_stage_second_stage_questions = [0]*multlvl_prod_diff_len\n",
    "    \n",
    "    #calculate two-step values for all question pairs\n",
    "    n = len(mu_vec)\n",
    "    for i in range(0, multlvl_prod_diff_len):\n",
    "        x_0,y_0 = multlvl_question_extractor(multlvl_prod_diff_set[i],num_lvl)\n",
    "        multlvl_two_step = multlvl_two_step_g_acq(mu_vec,Sig_mat,mu_log_coeff,Sig_log_coeff,x_0,y_0,[num_lvl]*n)\n",
    "        multlvl_two_step_g_val[i] = multlvl_two_step[0]\n",
    "        first_stage_second_stage_questions[i] = [x_0,y_0,multlvl_two_step[1],multlvl_two_step[2],multlvl_two_step[3],multlvl_two_step[4]]\n",
    "        \n",
    "    return multlvl_two_step_g_val,multlvl_prod_diff_set,first_stage_second_stage_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37a71fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEEDS TO BE MOVED!!!\n",
    "#Ex1\n",
    "#mu_vec_1 = np.array([1.0]*6)\n",
    "#Sig_mat_1 = np.identity(6)\n",
    "#prod_1 = product_diff_list(6)\n",
    "#print(enum_two_step(mu_vec_1,Sig_mat_1,mu_log_coeff_6,Sig_log_coeff_6,prod_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb6bccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Ex1a\n",
    "#mu_vec_1a = np.array([1.0,1.0,1.0,1.0])\n",
    "#Sig_mat_1a = np.identity(4)\n",
    "#prod_1a = multlvl_product_diff_list(4,4)\n",
    "#num_lvl_1a = 4\n",
    "#print(multlvl_enum_two_step(mu_vec_1a,Sig_mat_1a,mu_log_coeff_12,Sig_log_coeff_12,prod_1a,num_lvl_1a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "878f6eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function which returns the best performing solution and their two-step acquisition values, along with the corresponding\n",
    "#first stage and two second stage questions.\n",
    "#We use the exact two-step g function. Used for experimenting and gaining insight into two-step acquisition.\n",
    "#NOTE: THIS CAN BE USED FOR MULTILEVEL CASE.\n",
    "\n",
    "def enum_two_step_opt(two_step_values,first_second_stage_question):\n",
    "    #two_step_values: A list of two_step values. This should come from the function enum_two_step\n",
    "    \n",
    "    \n",
    "    #Find min index of the two-step enumeration. Use these values to return the optimal two-step value,\n",
    "    #along with their corresponding questions.\n",
    "    two_step_array = np.array(two_step_values)\n",
    "    min_index = np.argmin(two_step_array)\n",
    "    max_index = np.argmax(two_step_array)\n",
    "    opt_x0 = first_second_stage_question[min_index][0]\n",
    "    opt_y0 = first_second_stage_question[min_index][1]\n",
    "    opt_x10 = first_second_stage_question[min_index][2]\n",
    "    opt_y10 = first_second_stage_question[min_index][3]\n",
    "    opt_x11 = first_second_stage_question[min_index][4]\n",
    "    opt_y11 = first_second_stage_question[min_index][5]\n",
    "    opt_val = two_step_values[min_index]\n",
    "\n",
    "    return [opt_val,opt_x0,opt_y0,opt_x10,opt_y10,opt_x11,opt_y11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "402164b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Solve the two-step problem via enumeration for 6 attributes and look at the structure of the optimal solution,\n",
    "#in particular look at the relationship between the first stage and the two second stage solutions. \n",
    "\n",
    "#rng = np.random.default_rng(100) \n",
    "#np.random.seed(100)\n",
    "#random.seed(100)\n",
    "\n",
    "#attribute numbers for enumeration\n",
    "#attr_enum = 6\n",
    "\n",
    "#Prior Parameters\n",
    "#mu_vec_enum = np.array([-0.25,0.5,-0.75,1.0,-1.25,1.5]) #np.array([1.0]*attr_enum)#rng.uniform(low = -1.0, high = 1.0, size = attr_enum)\n",
    "#Sig_mat_enum = 1.25*np.array([[1.0,-0.5,0.25,-0.125,0.0625,-0.03125],\n",
    "                      #[-0.5,1.0,-0.5,0.25,-0.125,0.0625],\n",
    "                     #[0.25,-0.5,1.0,-0.5,0.25,-0.125],\n",
    "                     #[-0.125,0.25,-0.5,1.0,-0.5,0.25],\n",
    "                     #[0.0625,-0.125,0.25,-0.5,1.0,-0.5],\n",
    "                     #[-0.03125,0.0625,-0.125,0.25,-0.5,1.0]])#np.identity(attr_enum)#sklearn.datasets.make_spd_matrix(attr_enum)\n",
    "\n",
    "#List of question pairs we will enumerate on\n",
    "#prod_list_enum = product_diff_list(attr_enum)\n",
    "#print(len(prod_list_enum))\n",
    "\n",
    "#Do the enumeration procedure\n",
    "#start_time_twostep = time.perf_counter()\n",
    "#enumerated_solution_list = enum_two_step(mu_vec_enum,Sig_mat_enum,mu_log_coeff_6,Sig_log_coeff_6,prod_list_enum)\n",
    "#print(time.perf_counter() - start_time_twostep, \"seconds\")\n",
    "\n",
    "#Save the two-step g values and the corresponding first stage and 2 second stage questions\n",
    "#opt_sol_questions = enum_two_step_opt(enumerated_solution_list[0],enumerated_solution_list[2])\n",
    "#print(opt_sol_questions)\n",
    "\n",
    "#Print prior parameters\n",
    "#print(mu_vec_enum)\n",
    "#print(Sig_mat_enum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d878306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS WILL NEED TO BE MOVED!!!\n",
    "#Create a matrix to save values measuring the inner product under \n",
    "#Sig_mat_enum of the 3 question pairs from above.\n",
    "#ortho_meas_matr = np.zeros((3,3))\n",
    "#q_0 = np.array(opt_sol_questions[1]) - np.array(opt_sol_questions[2])\n",
    "#q_10 = np.array(opt_sol_questions[3]) - np.array(opt_sol_questions[4])\n",
    "#q_11 = np.array(opt_sol_questions[5]) - np.array(opt_sol_questions[6])\n",
    "#question_list = [q_0,q_10,q_11]\n",
    "#print(opt_sol_questions)\n",
    "#print(question_list)\n",
    "#for i in range(3):\n",
    "    #for j in range(3):\n",
    "        #ortho_meas_matr[i,j] = np.dot(question_list[i],np.dot(Sig_mat_enum,question_list[j]))\n",
    "#print(ortho_meas_matr)\n",
    "\n",
    "#Look at the optimal solution from the approximate two-step method. Can be used to compare with the true\n",
    "#optimal solution.\n",
    "#two_step_apprx_opt = two_stage_g_opt(mu_vec_enum,Sig_mat_enum,mu_log_coeff_6,Sig_log_coeff_6,0.01)\n",
    "#print(two_step_apprx_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79025362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVE!!!\n",
    "#print(two_step_g_acq(mu_vec_enum,Sig_mat_enum,mu_log_coeff_6,Sig_log_coeff_6,two_step_apprx_opt[2],two_step_apprx_opt[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3c768c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is used to get the quantile of our two-step approximate solution value relative to the optimal solution value\n",
    "#as well as the one-step solution value relative to the optimal solution value. Also returns\n",
    "#a dataframe containing all of the enumeration data from each replication\n",
    "\n",
    "def quantile_test_enum_data(attr_num,prod_diff_list,rep_num,scale,location,mu_log_coeff,Sig_log_coeff,epsilon_0 = 0.1):\n",
    "    #attr_num: the number of attributes the products have.\n",
    "    \n",
    "    #prod_diff_list: A list of product pairs we will enumerate over for each replication. \n",
    "    #Products should have same number of attributes as attr_num.\n",
    "    \n",
    "    #rep_num: the number of replications we wish to make\n",
    "    \n",
    "    #scale: A parameter to increase/decrease the determinant of the random covariance matrix\n",
    "    \n",
    "    #location: A parameter to increase/decrease the magnitude of the partworth estimator.\n",
    "    \n",
    "    #mu_log_coeff and Sig_log_coeff: linear coefficients that are used in the optimization problem\n",
    "    \n",
    "    #epsilon_0: A parameter that is used in the two-step optimization problem with orthogonality constraints. \n",
    "    #It sets the degree of orthogonality, and we want it to be small.\n",
    "    \n",
    "    \n",
    "    #create two lists to store quantile data for one-step and two-step\n",
    "    quant_val_one_step = [0.0]*rep_num\n",
    "    quant_val_two_step = [0.0]*rep_num\n",
    "    \n",
    "    one_step_sol_val_list = [0.0]*rep_num\n",
    "    two_step_sol_val_list = [0.0]*rep_num\n",
    "    \n",
    "    enum_df = pd.DataFrame()\n",
    "    \n",
    "    #Collect quantile data\n",
    "    for i in range(0, rep_num):\n",
    "        #prior parameters\n",
    "        mu_0_rand = location*rng.uniform(low = -1.0, high = 1.0, size = attr_num) #use rng, this is Unif(-1.0,1.0)\n",
    "        Sig_0_rand = scale*sklearn.datasets.make_spd_matrix(attr_num) #NEED SEED FOR THIS\n",
    "        \n",
    "        #Solve the two-step(with orthgonality constraint) and one-step optimization problems\n",
    "        [w_0,z_0,w_1,z_1] = two_stage_g_opt(mu_0_rand,Sig_0_rand,mu_log_coeff,Sig_log_coeff,epsilon_0)\n",
    "        [x_0, y_0] = g_opt(mu_0_rand,Sig_0_rand,mu_log_coeff,Sig_log_coeff)[1:]\n",
    "        \n",
    "        #Save the two-step acquisition function values of the one-step and two-step solutions\n",
    "        one_step_sol_val = two_step_g_acq(mu_0_rand, Sig_0_rand,mu_log_coeff,Sig_log_coeff, x_0, y_0)[0]\n",
    "        two_step_appr_sol_val_0 = two_step_g_acq(mu_0_rand, Sig_0_rand,mu_log_coeff,Sig_log_coeff, w_0,z_0)[0]\n",
    "        two_step_appr_sol_val_1 = two_step_g_acq(mu_0_rand, Sig_0_rand,mu_log_coeff,Sig_log_coeff, w_1,z_1)[0]\n",
    "        two_step_appr_sol_val = min(two_step_appr_sol_val_0,two_step_appr_sol_val_1)\n",
    "        \n",
    "        one_step_sol_val_list[i] = one_step_sol_val\n",
    "        two_step_sol_val_list[i] = two_step_appr_sol_val\n",
    "        \n",
    "        #Create a list storing all of the enumerated values of all question pairs evaluated\n",
    "        #under two-step acquisition function. Return a dataframe containing enumeration if needed.\n",
    "        enum_data = enum_two_step(mu_0_rand,Sig_0_rand,mu_log_coeff,Sig_log_coeff,prod_diff_list)[0]\n",
    "        enum_df['Trial: %s'%(str(i))] = enum_data\n",
    "        \n",
    "        #Calculate the quantile values of one-step and two-step. The best performing solution will have a quant\n",
    "        #value of 1.0 and the worst performing solution will have a quant value of 0.\n",
    "        enum_data_len = len(enum_data)\n",
    "        one_step_quantile = [1 for x in enum_data if x >= one_step_sol_val]\n",
    "        two_step_quantile = [1 for x in enum_data if x >= two_step_appr_sol_val]\n",
    "        quant_val_one_step[i] = sum(one_step_quantile)/enum_data_len\n",
    "        quant_val_two_step[i] = sum(two_step_quantile)/enum_data_len\n",
    "     \n",
    "    return [quant_val_one_step, quant_val_two_step, enum_df, one_step_sol_val_list, two_step_sol_val_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b945a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Create Quantile Data with Two Boxplots for one-step vs two-step. \n",
    "#rng = np.random.default_rng(100) \n",
    "#np.random.seed(100)\n",
    "#random.seed(100)\n",
    "#These are the parameters we will use\n",
    "#attr_num_quant = 6\n",
    "#prod_diff_list_quant = product_diff_list(attr_num_quant) # TAKE A SAMPLE IF attr_num_quant IS LARGE\n",
    "#sample_size = 3**6\n",
    "#prod_diff_list_quant = random.sample(prod_diff_list_quant,sample_size)\n",
    "#rep_num_quant = 100\n",
    "#scale_quant = 1.0\n",
    "#location_quant = 8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "138b268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Create Quantile Data with Two Boxplots for one-step vs two-step, as well as enumeration data.\n",
    "#quant_data = quantile_test_enum_data(attr_num_quant,prod_diff_list_quant,rep_num_quant,scale_quant,location_quant,\n",
    "                                    #mu_log_coeff_6,Sig_log_coeff_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fbdc2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Create Quantile Data with Two Boxplots for one-step vs two-step\n",
    "\n",
    "#Place quant_data into a dataframe and convert to csv\n",
    "#zipped_quant = list(zip(quant_data[0], quant_data[1]))\n",
    "#df_quantile = pd.DataFrame(zipped_quant,columns = ['one-step','two-step'])\n",
    "#df_quantile.to_csv(r'C:\\Users\\wsfishe\\Desktop\\quantile_Aug5_%s_%s_%s_%s.csv'%(str(attr_num_quant),str(rep_num_quant),\n",
    "                                                                             #str(scale_quant),str(location_quant)),index=False,header=True)\n",
    "\n",
    "#quant_data[2].to_csv(r'C:\\Users\\wsfishe\\Desktop\\enum_data_Aug5_%s_%s_%s_%s.csv'%(str(attr_num_quant),str(rep_num_quant),\n",
    "                                                                             #str(scale_quant),str(location_quant)),index=False,header=True)\n",
    "\n",
    "#zipped_solval = list(zip(quant_data[3], quant_data[4]))\n",
    "#df_solval = pd.DataFrame(zipped_solval,columns = ['one-step','two-step'])\n",
    "#df_solval.to_csv(r'C:\\Users\\wsfishe\\Desktop\\quantile_solval_July11_%s_%s_%s_%s.csv'%(str(attr_num_quant),str(rep_num_quant),\n",
    "                                                                             #str(scale_quant),str(location_quant)),index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57fd8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Plot boxplot of quantile information\n",
    "#labels = ['one-step', 'two_step']\n",
    "#plt.boxplot([quant_data[0],quant_data[1]], vert=True, patch_artist=True, labels=labels) \n",
    "#plt.ylabel(\"Percentile of Solution\")\n",
    "#plt.title(\"Quantiles of Approximate Solutions: n=%s, scale = %s,Location = %s, Replication = %s\"%(str(attr_num_quant),\n",
    "                                                                                                  #str(scale_quant),\n",
    "                                                                                              #str(location_quant),\n",
    "                                                                                                  #str(rep_num_quant)))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c300d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#February 27, 2023. This function is used to check the one-step optimal solution's quantile as ranked against\n",
    "#all of the two-step feasible solutions (two-step) function values. We enumerate all of the possible solution's two-step\n",
    "#acquisition value, and see where the one-step optimal solution lies within this list.\n",
    "def one_step_sol_two_step_quantile(attr_num,prod_diff_list,rep_num,scale,location,mu_log_coeff,Sig_log_coeff):\n",
    "    #attr_num: the number of attributes the products have.\n",
    "    \n",
    "    #prod_diff_list: A list of product pairs we will enumerate over for each replication. \n",
    "    #Products should have same number of attributes as attr_num.\n",
    "    \n",
    "    #rep_num: the number of replications we wish to make\n",
    "    \n",
    "    #scale: A parameter to increase/decrease the determinant of the random covariance matrix\n",
    "    \n",
    "    #location: A parameter to increase/decrease the magnitude of the partworth estimator.\n",
    "    \n",
    "    #mu_log_coeff and Sig_log_coeff: linear coefficients that are used in the optimization problem\n",
    "    \n",
    "    #create lists to store quantile data for one-step under two-step solution\n",
    "    quant_val_one_step = [0.0]*rep_num\n",
    "    one_step_sol_val_list = [0.0]*rep_num\n",
    "    \n",
    "    enum_df = pd.DataFrame()\n",
    "    \n",
    "    #Collect quantile data\n",
    "    for i in range(0, rep_num):\n",
    "        #prior parameters\n",
    "        mu_0_rand = location*rng.uniform(low = -1.0, high = 1.0, size = attr_num) #use rng, this is Unif(-1.0,1.0)\n",
    "        print(mu_0_rand)\n",
    "        Sig_0_rand = scale*sklearn.datasets.make_spd_matrix(attr_num) #NEED SEED FOR THIS\n",
    "        \n",
    "        #Solve the one-step optimization problem's optimal solution\n",
    "        [x_0, y_0] = g_opt(mu_0_rand,Sig_0_rand,mu_log_coeff,Sig_log_coeff)[1:]\n",
    "        \n",
    "        #Save the two-step acquisition function values of the one-step solution\n",
    "        one_step_sol_val = two_step_g_acq(mu_0_rand, Sig_0_rand,mu_log_coeff,Sig_log_coeff, x_0, y_0)[0]\n",
    "        \n",
    "        one_step_sol_val_list[i] = one_step_sol_val\n",
    "        \n",
    "        #Create a list storing all of the enumerated values of all question pairs evaluated\n",
    "        #under two-step acquisition function. Return a dataframe containing enumeration if needed.\n",
    "        enum_data = enum_two_step(mu_0_rand,Sig_0_rand,mu_log_coeff,Sig_log_coeff,prod_diff_list)[0]\n",
    "        enum_df['Trial: %s'%(str(i))] = enum_data\n",
    "        \n",
    "        #Calculate the quantile values of one-step and two-step. The best performing solution will have a quant\n",
    "        #value of 1.0 and the worst performing solution will have a quant value of 0.\n",
    "        enum_data_len = len(enum_data)\n",
    "        one_step_quantile = [1 for x in enum_data if x >= one_step_sol_val]\n",
    "        quant_val_one_step[i] = sum(one_step_quantile)/enum_data_len\n",
    "        print('iteration: ' +str(i))\n",
    "     \n",
    "    return [quant_val_one_step, enum_df, one_step_sol_val_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fbc23d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Create Quantile Data with Boxplot for one-step performance in terms of two-step acquisition value.\n",
    "#rng = np.random.default_rng(100) \n",
    "#np.random.seed(100)\n",
    "#random.seed(100)\n",
    "#These are the parameters we will use\n",
    "#attr_num_OS_quant = 6\n",
    "#prod_diff_list_OS_quant = product_diff_list(attr_num_OS_quant) # TAKE A SAMPLE IF attr_num_OS_quant IS LARGE\n",
    "#sample_size = 3**6\n",
    "#prod_diff_list_onestep_quant = random.sample(prod_diff_list_OS_quant,sample_size)\n",
    "#rep_num_OS_quant = 100\n",
    "#scale_OS_quant = 4.0\n",
    "#location_OS_quant = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa75f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Create Quantile Data with one Boxplot for one-step, as well as enumeration data of two-step function.\n",
    "#quant_data_OS = one_step_sol_two_step_quantile(attr_num_OS_quant,prod_diff_list_OS_quant,rep_num_OS_quant,scale_OS_quant,location_OS_quant,\n",
    "                                    #mu_log_coeff_6,Sig_log_coeff_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61b117e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#labels_OS = ['one-step']\n",
    "#plt.boxplot(quant_data_OS[0], vert=True, patch_artist=True, labels=labels_OS)\n",
    "#plt.ylabel(\"Percentile of Solution\")\n",
    "\n",
    "#plt.title(\"Quantiles of One-Step Solutions (Two-Step Value): n=%s, scale = %s,Location = %s, Replication = %s\"%(str(attr_num_OS_quant),\n",
    "                                                                                                  #str(scale_OS_quant),\n",
    "                                                                                              #str(location_OS_quant),\n",
    "                                                                                                  #str(rep_num_OS_quant)))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c7f56ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#March 15, 2023. This function is used to check the one-step optimal solution's quantile as ranked against\n",
    "#all of the two-step feasible solutions (two-step) function values in the multi-level setting. We enumerate all of the possible solution's two-step\n",
    "#acquisition value, and see where the one-step optimal solution lies within this list.\n",
    "\n",
    "def multlvl_one_step_sol_two_step_quantile(attr_num,multlvl_prod_diff_list,rep_num,scale,location,mu_log_coeff,Sig_log_coeff, num_lvl):\n",
    "    #attr_num: the number of attributes the products have.\n",
    "    \n",
    "    #multlvl_prod_diff_list: A list of product pairs we will enumerate over for each replication. \n",
    "    #Products should have same number of attributes as attr_num. We assume each attribute has same number of levels.\n",
    "    \n",
    "    #rep_num: the number of replications we wish to make\n",
    "    \n",
    "    #scale: A parameter to increase/decrease the determinant of the random covariance matrix\n",
    "    \n",
    "    #location: A parameter to increase/decrease the magnitude of the partworth estimator.\n",
    "    \n",
    "    #mu_log_coeff and Sig_log_coeff: linear coefficients that are used in the optimization problem\n",
    "    \n",
    "    #num_lvl: This is the number of levels in each attribute of the product.\n",
    "    \n",
    "    quant_val_one_step = [0.0]*rep_num\n",
    "    one_step_sol_val_list = [0.0]*rep_num\n",
    "    \n",
    "    enum_df = pd.DataFrame()\n",
    "    \n",
    "    #Collect quantile data\n",
    "    for i in range(0, rep_num):\n",
    "        #prior parameters\n",
    "        mu_0_rand = location*rng.uniform(low = -1.0, high = 1.0, size = attr_num) #use rng, this is Unif(-1.0,1.0)\n",
    "        print(mu_0_rand)\n",
    "        Sig_0_rand = scale*sklearn.datasets.make_spd_matrix(attr_num) #NEED SEED FOR THIS\n",
    "        \n",
    "        #Solve the one-step optimization problem's optimal solution\n",
    "        [x_0, y_0] = g_opt_multi_lvl(mu_0_rand,Sig_0_rand,mu_log_coeff,Sig_log_coeff,[num_lvl]*attr_num)[1:3]\n",
    "        \n",
    "        #Save the two-step acquisition function values of the one-step solution\n",
    "        one_step_sol_val = multlvl_two_step_g_acq(mu_0_rand, Sig_0_rand,mu_log_coeff,Sig_log_coeff, x_0, y_0,[num_lvl]*attr_num)[0]\n",
    "        \n",
    "        one_step_sol_val_list[i] = one_step_sol_val\n",
    "        \n",
    "        #Create a list storing all of the enumerated values of all question pairs evaluated\n",
    "        #under two-step acquisition function. Return a dataframe containing enumeration if needed.\n",
    "        enum_data = multlvl_enum_two_step(mu_0_rand,Sig_0_rand,mu_log_coeff,Sig_log_coeff,multlvl_prod_diff_list,num_lvl)[0]\n",
    "        enum_df['Trial: %s'%(str(i))] = enum_data\n",
    "        \n",
    "        #Calculate the quantile values of one-step and two-step. The best performing solution will have a quant\n",
    "        #value of 1.0 and the worst performing solution will have a quant value of 0.\n",
    "        enum_data_len = len(enum_data)\n",
    "        one_step_quantile = [1 for x in enum_data if x >= one_step_sol_val]\n",
    "        quant_val_one_step[i] = sum(one_step_quantile)/enum_data_len\n",
    "        print('iteration: ' +str(i))\n",
    "        \n",
    "    return [quant_val_one_step, enum_df, one_step_sol_val_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c437cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Create Quantile Data with Boxplot for one-step performance in terms of two-step acquisition value.\n",
    "#rng = np.random.default_rng(10000) \n",
    "#np.random.seed(10000)\n",
    "#random.seed(10000)\n",
    "#These are the parameters we will use\n",
    "#attr_num_multlvl_OS_quant = 6\n",
    "#num_lvl_OS_quant = 3\n",
    "#prod_diff_list_multlvl_OS_quant = multlvl_product_diff_list(attr_num_multlvl_OS_quant,num_lvl_OS_quant) # TAKE A SAMPLE IF attr_num_OS_quant IS LARGE\n",
    "#sample_size = 3**6\n",
    "#prod_diff_list_onestep_quant = random.sample(prod_diff_list_OS_quant,sample_size)\n",
    "#rep_num_OS_quant = 30\n",
    "#scale_OS_quant = 2.0\n",
    "#location_OS_quant = 1.0\n",
    "#print(len(prod_diff_list_multlvl_OS_quant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6312e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Create Quantile Data with one Boxplot for one-step, as well as enumeration data of two-step function.\n",
    "#multlvl_quant_data_OS = multlvl_one_step_sol_two_step_quantile(attr_num_multlvl_OS_quant,prod_diff_list_multlvl_OS_quant,rep_num_OS_quant,scale_OS_quant,location_OS_quant,\n",
    "                                    #mu_log_coeff_6_mult_3,Sig_log_coeff_6_mult_3,num_lvl_OS_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d57331c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#labels_OS = ['one-step']\n",
    "#plt.boxplot(multlvl_quant_data_OS[0], vert=True, patch_artist=True, labels=labels_OS)\n",
    "#plt.ylabel(\"Percentile of Solution\")\n",
    "\n",
    "#plt.title(\"Quantiles of One-Step Solutions (Two-Step Value,Multi-Level): n=%s, scale = %s,Location = %s, Replication = %s, #levels = %s \"%(str(attr_num_multlvl_OS_quant),\n",
    "                                                                                                  #str(scale_OS_quant),\n",
    "                                                                                              #str(location_OS_quant),\n",
    "                                                                                                  #str(rep_num_OS_quant), str(num_lvl_OS_quant)))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fd3f896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to generate an nxn matrix M(r) such that M_ij = r^|i-j| for 0<r<1. This matrix is called a \n",
    "#Kac-Murdock-Szego matrix.\n",
    "def KMS_Matrix(n,r):\n",
    "    #n: this is the number of rows and columns of the matrix\n",
    "    #r: this is the coefficient given above that determines the value of the matrice's entries \n",
    "    \n",
    "    \n",
    "    M = np.zeros([n,n])\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            M[i,j] = r**abs(i-j)\n",
    "        \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c959fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#print(1.25*KMS_Matrix(6,-0.5))\n",
    "#print(np.linalg.det(1.25*KMS_Matrix(12,-0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b224ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to compare one-step and two-step in a sequential fashion. We start the experiment with\n",
    "#some prior information (expectation and covariance matrix), and sample a number of individuals\n",
    "#(partworth vectors) from this prior. We then run the two questionnaires (one-step and two-step) on all of the individuals,\n",
    "#recording the MSE between the estimator and their true partworth vector after each question, and we also record their MSE\n",
    "#and determinant information before starting the questionnaire.\n",
    "def MSE_det_test(attr_num,mu_scale,Sig_scale,num_rep,num_beta,noise_par,mu_log_coeff,Sig_log_coeff, use_max_min_mse_beta = True,\n",
    "                 rand_samp_par = True, epsilon_0 = 0.1,question_num=16,r=0.5,t = 100):\n",
    "    #attr_num: number of attributes the products should have.\n",
    "    \n",
    "    #mu_scale: used to create the expectation of the normal distribution we sample true partworth vectors from.\n",
    "    \n",
    "    #Sig_Scale: used to create the covariance matrix of the normal distribution we sample true partworth vectors from.\n",
    "    \n",
    "    #num_rep: The number of times we run the sequential experiment on ONE individual partworth vector.\n",
    "    \n",
    "    #num_beta: The number of individuals (partworth vectors) we sample for our experiment.\n",
    "    \n",
    "    #noise_par: This is a parameter which is used to increase the weight of the individuals' true partworth when making decision\n",
    "    #between x and y. The higher this weight is, the less effect the gumbel random variable has on user choice.\n",
    "    \n",
    "    #mu_log_coeff and Sig_log_coeff: linear coefficients that are used in the optimization problem\n",
    "    \n",
    "    #use_approx_two_step: Determines whether we use the approximate two-step method or the true two-step method via enumeration\n",
    "    \n",
    "    #use_max_min_mse_beta: Determines if we only experiment using the two betas with max and min MSE compared to the\n",
    "    #intial prior expectation.\n",
    "    \n",
    "    #rand_samp_par: This boolean parameter decides whether we use randomly generated expectation and \n",
    "    #covariance matrix or if we use\n",
    "    #constant vector and diagonal covariance matrix for the sampling of true partworth vectors.\n",
    "    \n",
    "    #epsilon_0: This is used in the two-step optimization problem to set the degree of orthogonality between\n",
    "    #the first-stage and second-stage question pairs\n",
    "    \n",
    "    #question_num: number of questions in the questionnaire.\n",
    "    \n",
    "    #r: coefficient for the KMS matrix, which acts as the prior covariance matrix.\n",
    "    \n",
    "    #t: this is the time limit on the approximate two-step method.\n",
    "    \n",
    "    \n",
    "    #Use rng to generate random. SHOULD rng BE INSIDE THE FUNCTION?\n",
    "    #rng = np.random.default_rng(0)\n",
    "    \n",
    "    #Decide whether we use randomly generated prior.\n",
    "    if rand_samp_par:\n",
    "        pop_prior_mu = mu_scale*rng.uniform(size = attr_num)\n",
    "        pop_prior_Sig = Sig_scale*sklearn.datasets.make_spd_matrix(attr_num)\n",
    "    else:\n",
    "        pop_prior_mu = np.array(attr_num*[mu_scale])\n",
    "        pop_prior_Sig = Sig_scale*np.identity(attr_num)\n",
    "    \n",
    "    #Used to store partworth vectors\n",
    "    true_betas = []\n",
    "\n",
    "    #Sample from prior distribution to get partworths\n",
    "    for i in range(0,num_beta):\n",
    "        true_betas.append(rng.multivariate_normal(pop_prior_mu,pop_prior_Sig))\n",
    "    \n",
    "    #Start the experiment\n",
    "    mu_start = pop_prior_mu #rng.uniform(low = -0.1, high = 0.1, size = attr_num)#mu_scale*np.array(attr_num*[0.01])\n",
    "    Sig_start = pop_prior_Sig #Sig_scale*KMS_Matrix(attr_num,r)\n",
    "    \n",
    "    #If use_max_min_mse_beta is true, then we only use the betas with the smallest and largest MSE from the experiment.\n",
    "    #MSE(true_beta/||true_beta||, initial_est/||initial_est||)\n",
    "    if use_max_min_mse_beta:\n",
    "        init_mse_values = num_beta*[0.0]\n",
    "        for i in range(0,num_beta):\n",
    "            init_mse_values[i] =  np.square(np.subtract(true_betas[i]/np.linalg.norm(true_betas[i],ord = 2),\n",
    "                                                            mu_start/np.linalg.norm(mu_start, ord = 2))).mean()\n",
    "        init_mse_max_index = np.argmax(np.array(init_mse_values))\n",
    "        init_mse_min_index = np.argmin(np.array(init_mse_values))\n",
    "        true_betas = [true_betas[init_mse_min_index],true_betas[init_mse_max_index]]\n",
    "    \n",
    "    beta_len = len(true_betas)\n",
    "    \n",
    "    #These will be used to store MSE and covariance matrix determinant values after each question is asked.\n",
    "    one_step_det = [[[] for j in range(beta_len)] for i in range(question_num + 1)]\n",
    "    one_step_mse = [[[] for j in range(beta_len)] for i in range(question_num + 1)]\n",
    "    \n",
    "    true_two_step_det = [[[] for j in range(beta_len)] for i in range(question_num + 1)]\n",
    "    true_two_step_mse = [[[] for j in range(beta_len)] for i in range(question_num + 1)]\n",
    "    \n",
    "    appr_two_step_det = [[[] for j in range(beta_len)] for i in range(question_num + 1)]\n",
    "    appr_two_step_mse = [[[] for j in range(beta_len)] for i in range(question_num + 1)]\n",
    "    \n",
    "    \n",
    "    for b in range(0,beta_len):\n",
    "        for i in range(0,num_rep):\n",
    "            #Start each individual with the same prior information for both one-step and two-step methods. Store\n",
    "            #starting determinant value and MSE\n",
    "            one_step_mu = mu_start\n",
    "            one_step_Sig = Sig_start\n",
    "            true_two_step_mu = mu_start\n",
    "            true_two_step_Sig = Sig_start\n",
    "            appr_two_step_mu = mu_start\n",
    "            appr_two_step_Sig = Sig_start\n",
    "            #redundant\n",
    "            one_step_det[0][b].append(np.linalg.det(Sig_start))\n",
    "            true_two_step_det[0][b].append(np.linalg.det(Sig_start))\n",
    "            appr_two_step_det[0][b].append(np.linalg.det(Sig_start))\n",
    "\n",
    "            one_step_mse[0][b].append(np.square(np.subtract(true_betas[b]/np.linalg.norm(true_betas[b],ord = 2),\n",
    "                                                            one_step_mu/np.linalg.norm(one_step_mu, ord = 2))).mean())\n",
    "            true_two_step_mse[0][b].append(np.square(np.subtract(true_betas[b]/np.linalg.norm(true_betas[b],ord = 2),\n",
    "                                                            true_two_step_mu/np.linalg.norm(true_two_step_mu, ord = 2))).mean())\n",
    "            appr_two_step_mse[0][b].append(np.square(np.subtract(true_betas[b]/np.linalg.norm(true_betas[b],ord = 2),\n",
    "                                                            appr_two_step_mu/np.linalg.norm(appr_two_step_mu, ord = 2))).mean())\n",
    "            for j in range(1,question_num + 1):\n",
    "                #get questions for one step\n",
    "                [one_step_x,one_step_y] = g_opt(one_step_mu,one_step_Sig,mu_log_coeff,Sig_log_coeff)[1:]\n",
    "                \n",
    "                #get questions for approx two step\n",
    "                [w_0,z_0,w_1,z_1] = two_stage_g_opt(appr_two_step_mu,appr_two_step_Sig,mu_log_coeff,Sig_log_coeff,epsilon_0,t_lim=t)\n",
    "                two_step_appr_sol_val_0 = two_step_g_acq(appr_two_step_mu, appr_two_step_Sig,mu_log_coeff,Sig_log_coeff, w_0,z_0)\n",
    "                two_step_appr_sol_val_1 = two_step_g_acq(appr_two_step_mu, appr_two_step_Sig,mu_log_coeff,Sig_log_coeff, w_1,z_1)\n",
    "                if two_step_appr_sol_val_0 < two_step_appr_sol_val_1:\n",
    "                    appr_two_step_x = w_0\n",
    "                    appr_two_step_y = z_0\n",
    "                else:\n",
    "                    appr_two_step_x = w_1\n",
    "                    appr_two_step_y = z_1\n",
    "            \n",
    "                #List of question pairs we will enumerate on for true two-step\n",
    "                prod_list_enum_two_step = product_diff_list(attr_num)\n",
    "\n",
    "                #Do the enumeration procedure\n",
    "                enumerated_solution_list_two_step = enum_two_step(true_two_step_mu,true_two_step_Sig,mu_log_coeff,\n",
    "                                                             Sig_log_coeff,prod_list_enum_two_step)\n",
    "                    \n",
    "                opt_sol_questions_two_step = enum_two_step_opt(enumerated_solution_list_two_step[0],\n",
    "                                                          enumerated_solution_list_two_step[2])\n",
    "                    \n",
    "                #get the first stage products for true two-step\n",
    "                true_two_step_x = np.array(opt_sol_questions_two_step[1])\n",
    "                true_two_step_y = np.array(opt_sol_questions_two_step[2])\n",
    "                    \n",
    "\n",
    "                gum_x = rng.gumbel(0,1,1)\n",
    "                gum_y = rng.gumbel(0,1,1)\n",
    "\n",
    "                #These temp variables will be used in the choice model below in case the user prefers y over x.\n",
    "                one_step_x_temp = one_step_x\n",
    "                one_step_y_temp = one_step_y\n",
    "                true_two_step_x_temp = true_two_step_x\n",
    "                true_two_step_y_temp = true_two_step_y\n",
    "                appr_two_step_x_temp = appr_two_step_x\n",
    "                appr_two_step_y_temp = appr_two_step_y\n",
    "\n",
    "                #See preference between two products\n",
    "                #set signal to noise ratio\n",
    "                if (noise_par*np.dot(true_betas[b],np.array(one_step_y)) + gum_y) >= (noise_par*np.dot(true_betas[b],np.array(one_step_x))\n",
    "                                                                               + gum_x):\n",
    "                    one_step_x = one_step_y_temp\n",
    "                    one_step_y = one_step_x_temp\n",
    "                if (noise_par*np.dot(true_betas[b],np.array(true_two_step_y)) + gum_y) >= (noise_par*np.dot(true_betas[b],np.array(true_two_step_x))\n",
    "                                                                               + gum_x):\n",
    "                    true_two_step_x = true_two_step_y_temp\n",
    "                    true_two_step_y = true_two_step_x_temp\n",
    "                if (noise_par*np.dot(true_betas[b],np.array(appr_two_step_y)) + gum_y) >= (noise_par*np.dot(true_betas[b],np.array(appr_two_step_x))\n",
    "                                                                               + gum_x):\n",
    "                    appr_two_step_x = appr_two_step_y_temp\n",
    "                    appr_two_step_y = appr_two_step_x_temp\n",
    "            \n",
    "\n",
    "                #Perform moment matching after choice is made.\n",
    "                [one_step_mu, one_step_Sig] = moment_matching_update(one_step_x,one_step_y,one_step_mu,one_step_Sig)\n",
    "                [true_two_step_mu, true_two_step_Sig] = moment_matching_update(true_two_step_x,true_two_step_y,true_two_step_mu,true_two_step_Sig)\n",
    "                [appr_two_step_mu, appr_two_step_Sig] = moment_matching_update(appr_two_step_x,appr_two_step_y,appr_two_step_mu,appr_two_step_Sig)\n",
    "\n",
    "\n",
    "                #Compute determinant and MSE after question j, save information in a list corresponding to question j.\n",
    "                #This list will hold all of the MSE and determinant information for all individuals for question j.\n",
    "                one_step_det[j][b].append(np.linalg.det(one_step_Sig))\n",
    "                true_two_step_det[j][b].append(np.linalg.det(true_two_step_Sig))\n",
    "                appr_two_step_det[j][b].append(np.linalg.det(appr_two_step_Sig))\n",
    "                \n",
    "                one_step_mse[j][b].append(np.square(np.subtract(true_betas[b]/np.linalg.norm(true_betas[b],ord = 2),\n",
    "                                                            one_step_mu/np.linalg.norm(one_step_mu, ord = 2))).mean())\n",
    "                true_two_step_mse[j][b].append(np.square(np.subtract(true_betas[b]/np.linalg.norm(true_betas[b],ord = 2),\n",
    "                                                            true_two_step_mu/np.linalg.norm(true_two_step_mu, ord = 2))).mean())\n",
    "                appr_two_step_mse[j][b].append(np.square(np.subtract(true_betas[b]/np.linalg.norm(true_betas[b],ord = 2),\n",
    "                                                            appr_two_step_mu/np.linalg.norm(appr_two_step_mu, ord = 2))).mean())\n",
    "            \n",
    "    return [one_step_det,one_step_mse,true_two_step_det,true_two_step_mse,appr_two_step_det,appr_two_step_mse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7bfa832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Set up parameters for MSE_det_test\n",
    "#rng = np.random.default_rng(100) \n",
    "#np.random.seed(100)\n",
    "#random.seed(100)\n",
    "#attr_num_test = 6\n",
    "#mu_scale_test = 0.5 \n",
    "#Sig_scale_test = 1.0\n",
    "#num_rep_test = 50 #100\n",
    "#num_beta_test = 100\n",
    "#noise_par_test = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35cea35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Gather MSE and determinant information for two betas (max and min MSE) \n",
    "#MSE_det_info = MSE_det_test(attr_num_test,mu_scale_test,Sig_scale_test,num_rep_test,num_beta_test,noise_par_test,mu_log_coeff_6,\n",
    "                           #Sig_log_coeff_6,use_max_min_mse_beta = True,rand_samp_par = False, question_num = 16,t=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5c81755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#print(MSE_det_info[1])\n",
    "#print(MSE_det_info[5])\n",
    "#print(MSE_det_info[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3402dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Place data in a csv\n",
    "#zipped_MSE_det = list(zip(MSE_det_info[0], MSE_det_info[1],MSE_det_info[2],MSE_det_info[3]))\n",
    "#df_MSE_det = pd.DataFrame(zipped_MSE_det,columns = ['one-step det','one-step MSE','two-step det', 'two-step MSE'])\n",
    "#df_MSE_det.to_csv(r'C:\\Users\\wsfishe\\Desktop\\MSE_det_test_July13_%s_%s_%s_%s_%s_Truetwostep.csv'%(str(attr_num_test),str(num_rep_test),str(num_beta_test),\n",
    "                                                                             #str(Sig_scale_test),str(mu_scale_test)),index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "441e2eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#format data to use in sns.lineplot. Use this when there are multiple betas but only one replication for each\n",
    "#beta. Plot MSE\n",
    "#question_num_test = 4\n",
    "#x_axis_one_mse = []\n",
    "#for i in range(question_num_test + 1):\n",
    "    #for j in range (0,num_beta_test):\n",
    "        #x_axis_one_mse.append(i)\n",
    "\n",
    "#y_axis_one_mse = []\n",
    "    \n",
    "#for j in range(question_num_test + 1):\n",
    "    #for k in MSE_det_info[1][j]:\n",
    "        #y_axis_one_mse.append(k)\n",
    "        \n",
    "#x_axis_two_mse = []\n",
    "#for i in range(question_num_test + 1):\n",
    "    #for j in range (0,num_beta_test):\n",
    "        #x_axis_two_mse.append(i)\n",
    "\n",
    "#y_axis_two_mse = []\n",
    "    \n",
    "#for j in range(question_num_test + 1):\n",
    "    #for k in MSE_det_info[3][j]:\n",
    "        #y_axis_two_mse.append(k)\n",
    "    \n",
    "#fig = sns.lineplot(x = x_axis_one_mse, y = y_axis_one_mse).set(title='MSE Sequential Comparison:July12')\n",
    "#sns.lineplot(x = x_axis_two_mse, y = y_axis_two_mse).set( xlabel = \"Question Number\", ylabel = \"MSE After Normalizing\")\n",
    "#plt.legend(labels=[\"One-Step\",\"Two-Step\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4d56edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#format data to use in sns.lineplot. Use this when there are max and min betas but having multiple replications each\n",
    "#. Plot MSE (MAX)\n",
    "\n",
    "#question_num_max_min = 2\n",
    "\n",
    "#max_x_axis_one_mse = []\n",
    "#for i in range(question_num_max_min + 1):\n",
    "    #for j in range(0,num_rep_test):\n",
    "        #max_x_axis_one_mse.append(i)\n",
    "\n",
    "#max_y_axis_one_mse = []\n",
    "    \n",
    "#for i in range(question_num_max_min + 1):\n",
    "    #for j in MSE_det_info[1][i][1]:\n",
    "        #max_y_axis_one_mse.append(j)\n",
    "        \n",
    "#max_x_axis_true_two_mse = []\n",
    "#for i in range(question_num_max_min + 1):\n",
    "    #for j in range(0,num_rep_test):\n",
    "        #max_x_axis_true_two_mse.append(i)\n",
    "\n",
    "#max_y_axis_true_two_mse = []\n",
    "    \n",
    "#for i in range(question_num_max_min + 1):\n",
    "    #for j in MSE_det_info[3][i][1]:\n",
    "        #max_y_axis_true_two_mse.append(j)\n",
    "        \n",
    "#max_x_axis_appr_two_mse = []\n",
    "#for i in range(question_num_max_min + 1):\n",
    "    #for j in range(0,num_rep_test):\n",
    "        #max_x_axis_appr_two_mse.append(i)\n",
    "\n",
    "#max_y_axis_appr_two_mse = []\n",
    "    \n",
    "#for i in range(question_num_max_min + 1):\n",
    "    #for j in MSE_det_info[5][i][1]:\n",
    "        #max_y_axis_appr_two_mse.append(j)\n",
    "        \n",
    "#fig = sns.lineplot(x = max_x_axis_one_mse, y = max_y_axis_one_mse).set(title='MSE Sequential Comparison: Baseline Partworth with Max MSE')\n",
    "#sns.lineplot(x = max_x_axis_true_two_mse, y = max_y_axis_true_two_mse).set( xlabel = \"Question Number\", ylabel = \"MSE After Normalizing\")\n",
    "#sns.lineplot(x = max_x_axis_appr_two_mse, y = max_y_axis_appr_two_mse)\n",
    "#plt.legend(labels=[\"One-Step\",\"True Two-Step\",\"Approximate Two-Step\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "327c7abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#format data to use in sns.lineplot. Use this when there are max and min betas but having multiple replications each\n",
    "#. Plot MSE (MIN)\n",
    "\n",
    "#question_num_max_min = 16\n",
    "\n",
    "#min_x_axis_one_mse = []\n",
    "#for i in range(question_num_max_min + 1):\n",
    "    #for j in range(0,num_rep_test):\n",
    "        #min_x_axis_one_mse.append(i)\n",
    "\n",
    "#min_y_axis_one_mse = []\n",
    "    \n",
    "#for i in range(question_num_max_min + 1):\n",
    "    #for j in MSE_det_info[1][i][0]:\n",
    "        #min_y_axis_one_mse.append(j)\n",
    "        \n",
    "#min_x_axis_two_mse = []\n",
    "#for i in range(question_num_max_min + 1):\n",
    "    #for j in range(0,num_rep_test):\n",
    "        #min_x_axis_two_mse.append(i)\n",
    "\n",
    "#min_y_axis_two_mse = []\n",
    "    \n",
    "#for i in range(question_num_max_min + 1):\n",
    "    #for j in MSE_det_info[3][i][0]:\n",
    "        #min_y_axis_two_mse.append(j)\n",
    "        \n",
    "#fig = sns.lineplot(x = min_x_axis_one_mse, y = min_y_axis_one_mse).set(title='MSE Sequential Comparison: Baseline Partworth with Min MSE')\n",
    "#sns.lineplot(x = min_x_axis_two_mse, y = min_y_axis_two_mse).set( xlabel = \"Question Number\", ylabel = \"MSE After Normalizing\")\n",
    "#plt.legend(labels=[\"One-Step\",\"True Two-Step\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a9f79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#format data to use in sns.lineplot. Use this when there are multiple betas but only one replication for each\n",
    "#beta.Plot determinant\n",
    "#question_num_test = 4\n",
    "#x_axis_one_det = []\n",
    "#for i in range(question_num_test + 1):\n",
    "    #for j in range (0,num_beta_test):\n",
    "        #x_axis_one_det.append(i)\n",
    "\n",
    "#y_axis_one_det = []\n",
    "    \n",
    "#for j in range(question_num_test + 1):\n",
    "    #for k in MSE_det_info[0][j]:\n",
    "        #y_axis_one_det.append(k)\n",
    "        \n",
    "#x_axis_two_det = []\n",
    "#for i in range(question_num_test + 1):\n",
    "    #for j in range (0,num_beta_test):\n",
    "        #x_axis_two_det.append(i)\n",
    "\n",
    "#y_axis_two_det = []\n",
    "    \n",
    "#for j in range(question_num_test + 1):\n",
    "    #for k in MSE_det_info[2][j]:\n",
    "        #y_axis_two_det.append(k)\n",
    "\n",
    "#print(len(x_axis_one_det))\n",
    "#print(len(y_axis_one_det))\n",
    "#fig = sns.lineplot(x = x_axis_one_det, y = y_axis_one_det).set(title='Determinant Sequential Comparison: KMS Prior')\n",
    "#sns.lineplot(x = x_axis_two_det, y = y_axis_two_det).set( xlabel = \"Question Number\", ylabel = \"Determinant\")\n",
    "#plt.legend(labels=[\"One-Step\",\"Two-Step\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b33f9eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#format data to use in sns.lineplot. Use this when there are max and min betas but having multiple replications each\n",
    "#. Plot DET (MAX)\n",
    "\n",
    "#question_num_max_min = 1\n",
    "\n",
    "#max_x_axis_one_det = []\n",
    "#for i in range(0,question_num_max_min + 1):\n",
    "    #for j in range(0,num_rep_test):\n",
    "        #max_x_axis_one_det.append(i)\n",
    "\n",
    "#max_y_axis_one_det = []\n",
    "    \n",
    "#for i in range(0,question_num_max_min + 1):\n",
    "    #for j in MSE_det_info[0][i][1]:\n",
    "        #max_y_axis_one_det.append(j)\n",
    "        \n",
    "#max_x_axis_true_two_det = []\n",
    "#for i in range(0,question_num_max_min + 1):\n",
    "    #for j in range(0,num_rep_test):\n",
    "        #max_x_axis_true_two_det.append(i)\n",
    "\n",
    "#max_y_axis_true_two_det = []\n",
    "    \n",
    "#for i in range(0,question_num_max_min + 1):\n",
    "    #for j in MSE_det_info[2][i][1]:\n",
    "        #max_y_axis_true_two_det.append(j)\n",
    "        \n",
    "#max_x_axis_appr_two_det = []\n",
    "#for i in range(0,question_num_max_min + 1):\n",
    "    #for j in range(0,num_rep_test):\n",
    "        #max_x_axis_appr_two_det.append(i)\n",
    "\n",
    "#max_y_axis_appr_two_det = []\n",
    "    \n",
    "#for i in range(0,question_num_max_min + 1):\n",
    "    #for j in MSE_det_info[4][i][1]:\n",
    "        #max_y_axis_appr_two_det.append(j)\n",
    "        \n",
    "#fig = sns.lineplot(x = max_x_axis_one_det, y = max_y_axis_one_det).set(title='Determinant Sequential Comparison: Baseline Partworth with Max MSE')\n",
    "#sns.lineplot(x = max_x_axis_true_two_det, y = max_y_axis_true_two_det).set( xlabel = \"Question Number\", ylabel = \"Determinant\")\n",
    "#sns.lineplot(x = max_x_axis_appr_two_det, y = max_y_axis_appr_two_det)\n",
    "#plt.legend(labels=[\"One-Step\",\"True Two-Step\",\"Approximate Two-Step\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9471940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#format data to use in sns.lineplot. Use this when there are max and min betas but having multiple replications each\n",
    "#. Plot DET (MIN)\n",
    "\n",
    "#question_num_max_min = 16\n",
    "\n",
    "#min_x_axis_one_det = []\n",
    "#for i in range(8,question_num_max_min + 1):\n",
    "    #for j in range(0,num_rep_test):\n",
    "        #min_x_axis_one_det.append(i)\n",
    "\n",
    "#min_y_axis_one_det = []\n",
    "    \n",
    "#for i in range(8,question_num_max_min + 1):\n",
    "    #for j in MSE_det_info[0][i][0]:\n",
    "        #min_y_axis_one_det.append(j)\n",
    "        \n",
    "#min_x_axis_two_det = []\n",
    "#for i in range(8,question_num_max_min + 1):\n",
    "    #for j in range(0,num_rep_test):\n",
    "        #min_x_axis_two_det.append(i)\n",
    "\n",
    "#min_y_axis_two_det = []\n",
    "    \n",
    "#for i in range(8,question_num_max_min + 1):\n",
    "    #for j in MSE_det_info[2][i][0]:\n",
    "        #min_y_axis_two_det.append(j)\n",
    "        \n",
    "#fig = sns.lineplot(x = min_x_axis_one_det, y = min_y_axis_one_det).set(title='Determinant Sequential Comparison: Baseline Partworth with Min MSE')\n",
    "#sns.lineplot(x = min_x_axis_two_det, y = min_y_axis_two_det).set( xlabel = \"Question Number\", ylabel = \"Determinant\")\n",
    "#plt.legend(labels=[\"One-Step\",\"True Two-Step\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59dec756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOVE IT!!!\n",
    "#from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "062a0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Look at the determinant values after question 4\n",
    "#one_step_det_q4 = MSE_det_info[0][4]\n",
    "#two_step_det_q4 = MSE_det_info[2][4]\n",
    "#Do a paired t-test between the two sets of determinant data for question 4\n",
    "#tStat_detq4, pValue_detq4 =  stats.ttest_rel(one_step_det_q4, two_step_det_q4)\n",
    "#print(\"P-Value:{0} T-Statistic:{1}\".format(pValue_detq4,tStat_detq4)) #print the P-Value and the T-Statistic\n",
    "#Print out the average\n",
    "#print(\"One-Step Determinant Average: \" +str(sum(one_step_det_q4)/len(one_step_det_q4)))\n",
    "#print(\"Approximate Two-Step Determinant Average: \" +str(sum(two_step_det_q4)/len(two_step_det_q4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4bd07efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Look at the determinant values after question 3\n",
    "#one_step_det_q3 = MSE_det_info[0][3]\n",
    "#two_step_det_q3 = MSE_det_info[2][3]\n",
    "#Do a paired t-test between the two sets of determinant data for question 3\n",
    "#tStat_detq3, pValue_detq3 =  stats.ttest_rel(one_step_det_q3, two_step_det_q3)\n",
    "#print(\"P-Value:{0} T-Statistic:{1}\".format(pValue_detq3,tStat_detq3)) #print the P-Value and the T-Statistic\n",
    "#Print out the average\n",
    "#print(\"One-Step Determinant Average: \" + str(sum(one_step_det_q3)/len(one_step_det_q3)))\n",
    "#print(\"Approximate Two-Step Determinant Average: \" + str(sum(two_step_det_q3)/len(two_step_det_q3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24d37cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Look at the determinant values after question 2\n",
    "#one_step_det_q2 = MSE_det_info[0][2]\n",
    "#two_step_det_q2 = MSE_det_info[2][2]\n",
    "#Do a paired t-test between the two sets of determinant data for question 2\n",
    "#tStat_detq2, pValue_detq2 =  stats.ttest_rel(one_step_det_q2, two_step_det_q2)\n",
    "#print(\"P-Value:{0} T-Statistic:{1}\".format(pValue_detq2,tStat_detq2)) #print the P-Value and the T-Statistic\n",
    "#Print out the average\n",
    "#print(\"One-Step Determinant Average: \"+ str(sum(one_step_det_q2)/len(one_step_det_q2)))\n",
    "#print(\"Approximate Two-Step Determinant Average: \" + str(sum(two_step_det_q2)/len(two_step_det_q2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6bc228bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Look at the determinant values after question 1\n",
    "#one_step_det_q1 = MSE_det_info[0][1]\n",
    "#two_step_det_q1 = MSE_det_info[2][1]\n",
    "\n",
    "#Do a paired t-test between the two sets of determinant data for question 1\n",
    "#tStat_detq1, pValue_detq1 =  stats.ttest_rel(one_step_det_q1, two_step_det_q1)\n",
    "#print(\"P-Value:{0} T-Statistic:{1}\".format(pValue_detq1,tStat_detq1)) #print the P-Value and the T-Statistic\n",
    "#Print out the average\n",
    "#print(\"One-Step Determinant Average: \" + str(sum(one_step_det_q1)/len(one_step_det_q1)))\n",
    "#print(\"Approximate Two-Step Determinant Average: \" + str(sum(two_step_det_q1)/len(two_step_det_q1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "74602e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#This is used to reformat the MSE and determinant data in a nicer format and save it as a csv.\n",
    "#df_MSE_det_reformatted = pd.DataFrame()\n",
    "#questions_and_start = 17\n",
    "#max_or_min = ['MIN','MAX']\n",
    "#for i in range(2):\n",
    "#for j in range(questions_and_start):\n",
    "        #df_MSE_det_reformatted['Question %s, Baseline Partworth %s, One-Step Det' %(str(j),max_or_min[1])] = MSE_det_info[0][j][1]\n",
    "        #df_MSE_det_reformatted['Question %s, Baseline Partworth %s, One-Step MSE' %(str(j),max_or_min[1])] = MSE_det_info[1][j][1]\n",
    "        #df_MSE_det_reformatted['Question %s, Baseline Partworth %s, True Two-Step Det' %(str(j),max_or_min[1])] = MSE_det_info[2][j][1]\n",
    "        #df_MSE_det_reformatted['Question %s, Baseline Partworth %s, True Two-Step MSE' %(str(j),max_or_min[1])] = MSE_det_info[3][j][1]\n",
    "        #df_MSE_det_reformatted['Question %s, Baseline Partworth %s, Appr Two-Step Det' %(str(j),max_or_min[1])] = MSE_det_info[4][j][1]\n",
    "        #df_MSE_det_reformatted['Question %s, Baseline Partworth %s, Appr Two-Step MSE' %(str(j),max_or_min[1])] = MSE_det_info[5][j][1]\n",
    "\n",
    "\n",
    "#df_MSE_det_reformatted.to_csv(r'C:\\Users\\wsfishe\\Desktop\\MSE_det_test_reformat_July29_%s_%s_%s_%s.csv'%(str(attr_num_test),str(num_rep_test),\n",
    "                                                                             #str(Sig_scale_test),str(mu_scale_test)),index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "01f4694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Look at the 16th question in terms of Normalized MSE for Max MSE case\n",
    "\n",
    "#one_step_MSE_maxcase_q16 = MSE_det_info[1][16][1]\n",
    "#two_step_MSE_maxcase_q16 = MSE_det_info[3][16][1]\n",
    "#Do a paired t-test between the two sets of MSE data for question 16 in the Max MSE case\n",
    "#tStat_MSEq16maxcase, pValue_MSEq16maxcase =  stats.ttest_rel(one_step_MSE_maxcase_q16 , two_step_MSE_maxcase_q16)\n",
    "#print(\"P-Value:{0} T-Statistic:{1}\".format(pValue_MSEq16maxcase,tStat_MSEq16maxcase)) #print the P-Value and the T-Statistic\n",
    "#Print out the average\n",
    "#print(\"Max Case One-Step MSE Average: \" + str(sum(one_step_MSE_maxcase_q16)/len(one_step_MSE_maxcase_q16)))\n",
    "#print(\"Max Case True Two-Step MSE Average: \" + str(sum(two_step_MSE_maxcase_q16)/len(two_step_MSE_maxcase_q16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "28c00979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Look at the 12th question in terms of Normalized MSE for Max MSE case\n",
    "\n",
    "#one_step_MSE_maxcase_q12 = MSE_det_info[1][12][1]\n",
    "#two_step_MSE_maxcase_q12 = MSE_det_info[3][12][1]\n",
    "#Do a paired t-test between the two sets of MSE data for question 16 in the Max MSE case\n",
    "#tStat_MSEq12maxcase, pValue_MSEq12maxcase =  stats.ttest_rel(one_step_MSE_maxcase_q12 , two_step_MSE_maxcase_q12)\n",
    "#print(\"P-Value:{0} T-Statistic:{1}\".format(pValue_MSEq12maxcase,tStat_MSEq12maxcase)) #print the P-Value and the T-Statistic\n",
    "#Print out the average\n",
    "#print(\"Max Case One-Step MSE Average: \" + str(sum(one_step_MSE_maxcase_q12)/len(one_step_MSE_maxcase_q12)))\n",
    "#print(\"Max Case True Two-Step MSE Average: \" + str(sum(two_step_MSE_maxcase_q12)/len(two_step_MSE_maxcase_q12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38c9cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!THIS FUNCTION IS A REWRITE OF MSE_det_test!!!#\n",
    "#This function is used to compare different methods in a sequential fashion using normalized MSE, determinant, \n",
    "#hitrate, and MSE as a measurement \n",
    "#of quality. In this function, we only use one acquisition method at a time (compare with MSE_det_test).\n",
    "\n",
    "def new_sequential_experiment(init_mu, init_Sig, true_partworths, rep_per_partworth, num_questions,look_ahead_horizon, mu_log_coeff,\n",
    "                                   Sig_log_coeff,noise_par, question_list, Method = 0,\n",
    "                                   batch_size = 0, MC_budget = 0, include_one_step = False,penalty = 100,rel_gap = 0.0001):\n",
    "    #init_mu: This is the initial estimate on the partworths\n",
    "    #init_Sig: This is the initial covariance matrix on the partworths\n",
    "    #true_partworths: These are used to make selection in the product selection stage (a list/set of partworths)\n",
    "    #rep_per_partworth: This is the number of times we want to conduct a questionnaire on each partworth\n",
    "    #num_questions: Length of the questionnaire\n",
    "    #look_ahead_horizon: This is the number of stages that we look ahead in a rollout method.\n",
    "    #mu_log_coeff; Sig_log_coeff: These are the coefficients in the optimization model for the linearized objective function\n",
    "    #noise_par: This is a parameter which is used to increase the weight of the individuals' true partworth when making decision\n",
    "    #hitrate_question_list: This is a list of questions which will be used to calculate the hitrate, which is the\n",
    "    #proportion of times that an estimated partworth matches the product selection of a true underlying partworth.\n",
    "    #between x and y. The higher this weight is, the less effect the gumbel random variable has on user choice.\n",
    "    #Method: 0 - One step look ahead\n",
    "    #        1 - Rollout with batch design   <------ CAN ADD MORE METHODS IF NEEDED\n",
    "    #        2 - Two step look ahead via enumeration\n",
    "    #        3 - Rollout using coordinate exchange\n",
    "    #batch_size: Used to select batch size if we use rollout\n",
    "    #        OPTIONS:\n",
    "    #        batch_size = n (n is a non-negative integer): This will make it so that the batch size is constant and equal to n for every rollout iteration\n",
    "    #        batch_size = -1: This will make it so that the batch size is equal to the look-ahead horizon\n",
    "    #MC_budget: Used to select Monte Carlo budget if we use rollout.\n",
    "    #include_one_step: This determines whether we want to include the one-step optimal question within our batch. This can\n",
    "    #help ensure that rollout performs at least as well as one-step look ahead. Default value is False.\n",
    "    #penalty_term: This is used to set the penalty level for orthogonality in the orthogonal batch design optimization problem. A higher penalty\n",
    "    #term will lead to a more Sigma_orthogonal design, while a lower penalty term will lead to less Sigma_orthogonality in the design\n",
    "    #rel_gap: This is used in rollout with coordinate exchange. This value measures the improvement of a question's rollout\n",
    "    #value over the current question's rollout value. If the improvement is greater than the relative gap, we update the current\n",
    "    #question\n",
    "    \n",
    "    \n",
    "    #Construct lists for storing normalized MSE, determinant, hitrate, and MSE information. \n",
    "    #For each of the baseline partworths, we create a list holding\n",
    "    #(num_questions) lists, where each of the (num_questions) lists holds the MSE and determinant values for all replications\n",
    "    #after the first, second,...,nth question\n",
    "    \n",
    "    num_true_partworth = len(true_partworths) \n",
    "    \n",
    "    hitrate_total_num_of_questions = len(question_list)\n",
    "    \n",
    "    \n",
    "    #Construct the expected preferred product selection for each true partworth. This will be used when we calculate the probability\n",
    "    #of correct selection\n",
    "    x_trueselection = [[] for u in range(num_true_partworth)]\n",
    "    attributes_num = len(init_mu)\n",
    "    for u in range(num_true_partworth):\n",
    "        x_trueselection[u] = np.array([1.0 if partworth_component>=0.0 else 0.0 for partworth_component in \n",
    "                                           true_partworths[u]])\n",
    "    \n",
    "    #Set up lists to hold normalized MSE, determinant, MSE, and hitrate information. For now, we will only calculate hitrate at the end\n",
    "    #of the questionnaire.  Also save the mu vectors. \n",
    "    \n",
    "    MSE_normalized = [[[] for j in range(num_questions)] for u in range(num_true_partworth)]\n",
    "    \n",
    "    DET = [[[] for j in range(num_questions)] for u in range(num_true_partworth)]\n",
    "    \n",
    "    HITRATE = [[] for u in range(num_true_partworth)]\n",
    "    \n",
    "    MSE = [[[] for j in range(num_questions)] for u in range(num_true_partworth)]\n",
    "    \n",
    "    PROB_CORRECT_SEL = []\n",
    "    \n",
    "    MU = [[[] for j in range(num_questions)] for u in range(num_true_partworth)]\n",
    "    \n",
    "    for u in range(num_true_partworth):\n",
    "        #create a variable which will store the number of correct selections.\n",
    "        correct_sel = 0\n",
    "        print('true_partworth:' + str(true_partworths[u]))\n",
    "        for i in range(rep_per_partworth):\n",
    "            #Instantiate mu and Sig with the initial parameters init_mu and init_Sig. These act as prior parameters for all\n",
    "            #the partworths\n",
    "            mu = init_mu\n",
    "            Sig = init_Sig\n",
    "            print('init_mu: ' + str(init_mu))\n",
    "            print('init_Sig: ' + str(init_Sig))\n",
    "            #print('replication:'+ str(i))\n",
    "            for j in range(num_questions):\n",
    "                if Method == 0:\n",
    "                    #get optimal question for one step\n",
    "                    [x,y] = g_opt(mu,Sig,mu_log_coeff,Sig_log_coeff)[1:]\n",
    "                    \n",
    "                if Method == 1:\n",
    "                    #get optimal question for rollout over batch design\n",
    "                    #Use a rollout length equal to look_ahead_horizon - 1, until we are within look_ahead_horizon of the\n",
    "                    #budget\n",
    "                    \n",
    "                    if j < num_questions - look_ahead_horizon:\n",
    "                        rollout_len = look_ahead_horizon - 1\n",
    "                    else:\n",
    "                        rollout_len = num_questions - j - 1\n",
    "                    \n",
    "                    if batch_size == -1:\n",
    "                        #When batch_size is -1, we use the rollout length + 1 as the batch size.\n",
    "                        [x,y] = rollout_with_batch_design_acquisition(mu,Sig,mu_log_coeff,Sig_log_coeff,rollout_len+1,\n",
    "                                                                 rollout_len,MC_budget,include_one_step,penalty_term = penalty)\n",
    "                    else:\n",
    "                        [x,y] = rollout_with_batch_design_acquisition(mu,Sig,mu_log_coeff,Sig_log_coeff,batch_size,\n",
    "                                                                 rollout_len,MC_budget,include_one_step,penalty_term = penalty)\n",
    "\n",
    "                    \n",
    "                if Method == 2:\n",
    "                    #Do the enumeration procedure for two-step look ahead\n",
    "                    if j < num_questions-1:\n",
    "                        enumerated_solution_list_two_step = enum_two_step(mu,Sig,mu_log_coeff,\n",
    "                                                             Sig_log_coeff,question_list)\n",
    "                        opt_sol_questions_two_step = enum_two_step_opt(enumerated_solution_list_two_step[0],\n",
    "                                                          enumerated_solution_list_two_step[2])\n",
    "                    \n",
    "                        #get the first stage products for true two-step\n",
    "                        x = np.array(opt_sol_questions_two_step[1])\n",
    "                        y = np.array(opt_sol_questions_two_step[2])\n",
    "                    #Use one-step for the last question.\n",
    "                    else:\n",
    "                        [x,y] = g_opt(mu,Sig,mu_log_coeff,Sig_log_coeff)[1:]\n",
    "                    \n",
    "                if Method == 3:\n",
    "                    #Do rollout with coordinate exchange\n",
    "                    if j < num_questions - look_ahead_horizon:\n",
    "                        rollout_len = look_ahead_horizon - 1\n",
    "                    else:\n",
    "                        rollout_len = num_questions - j - 1\n",
    "                        \n",
    "                    [x,y] = coordinate_exchange_acq(mu,Sig,mu_log_coeff,Sig_log_coeff,batch_size,rollout_len,\n",
    "                                                   MC_budget,rel_gap,include_batch = False,include_one_step = True)\n",
    "                    \n",
    "                #Instantiate gumbel random variables which are used in the product choice selection process.\n",
    "                gum_x = rng.gumbel(0,1,1)\n",
    "                gum_y = rng.gumbel(0,1,1)\n",
    "                    \n",
    "                #These temp variables will be used in the choice model below in case the user prefers y over x.\n",
    "                x_temp = x\n",
    "                y_temp = y\n",
    "                    \n",
    "                #See preference between two products\n",
    "                #set signal to noise ratio\n",
    "                if (noise_par*np.dot(true_partworths[u],np.array(y)) + gum_y) >= (noise_par*np.dot(true_partworths[u],np.array(x))\n",
    "                                                                               + gum_x):\n",
    "                    x = y_temp\n",
    "                    y = x_temp\n",
    "                \n",
    "                #Perform moment matching after choice is made.\n",
    "                print('Sig before:' + str(Sig))\n",
    "                print('mu before: ' + str(mu))\n",
    "                [mu, Sig] = moment_matching_update(x,y,mu,Sig)\n",
    "                print('Sig after:' + str(Sig))\n",
    "                print('mu after: ' + str(mu))\n",
    "                \n",
    "                #add mu to the list of mu vectors\n",
    "                MU[u][j].append(mu)\n",
    "                #Add the normalized MSE between the true partworth and estimator at question j to a list, and add the determinant of\n",
    "                #the covariance matrix at question j into a list. Also add the regular MSE\n",
    "                MSE_normalized[u][j].append(np.square(np.subtract(true_partworths[u]/np.linalg.norm(true_partworths[u],ord = 2),\n",
    "                                                            mu/np.linalg.norm(mu, ord = 2))).mean())\n",
    "                DET[u][j].append(np.linalg.det(Sig))\n",
    "                \n",
    "                MSE[u][j].append(np.square(np.subtract(true_partworths[u],\n",
    "                                                            mu)).mean())\n",
    "                \n",
    "            #Calculate hitrate for this replication. Given a set of questions of length K, we compare how well the final \n",
    "            #estimator performs in terms of correctly selecting the preferred profile for each question. The estimator\n",
    "            #makes a correct selection if its selection matches that of the true partworth (selection is absent of gumble noise)\n",
    "            hits = 0\n",
    "            for q in question_list:\n",
    "                if np.dot(true_partworths[u],q)*np.dot(mu,q)>=0:\n",
    "                    hits = hits + 1\n",
    "            HITRATE[u].append(hits/hitrate_total_num_of_questions)\n",
    "            \n",
    "            #Calculate whether we have correct selection in this replication for estimator mu\n",
    "            x_mu = np.array([1.0 if mu_component>=0.0 else 0.0 for mu_component in \n",
    "                                           mu])\n",
    "            print('x_mu: ' + str(x_mu))\n",
    "            print('x_true_selection: ' + str(x_trueselection[u]))\n",
    "            if np.dot(x_trueselection[u]-x_mu,x_trueselection[u]-x_mu) == 0.0:\n",
    "                correct_sel = correct_sel + 1\n",
    "        \n",
    "        #Calculate the probability of correct selection for the current true partworth\n",
    "        PROB_CORRECT_SEL.append(correct_sel/rep_per_partworth)\n",
    "                \n",
    "        \n",
    "    return[MSE_normalized,DET,HITRATE,MSE,PROB_CORRECT_SEL,true_partworths,MU]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de89db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEEDS TO BE MOVED!!!\n",
    "# 09/13/2022 Set up parameters for new_mse_det_experiment\n",
    "\n",
    "#Set up random number seed\n",
    "#rng = np.random.default_rng(100) \n",
    "#np.random.seed(100)\n",
    "#random.seed(100)\n",
    "\n",
    "#declare initial parameters mu and Sig, as well as the number of partworths to sample from N(mu,Sig).\n",
    "#num_attr_nmde = 6\n",
    "#samp_num_partworths = 100\n",
    "#mu_initial = np.array([1.0,1.0,1.0,1.0,1.0,1.0])#np.array(num_attr_nmde*[0.1])\n",
    "#Sig_initial = np.identity(num_attr_nmde)#KMS_Matrix(num_attr_nmde,0.5)#np.diag([4.0,0.1,0.1,0.1,0.1,4.0])\n",
    "\n",
    "#partworths_nmde = []\n",
    "\n",
    "#for i in range(0,samp_num_partworths):\n",
    "        #partworths_nmde.append(rng.multivariate_normal(mu_initial,Sig_initial))\n",
    "\n",
    "#Use only the two partworths with the max and min MSE compared to the initial mu\n",
    "#init_mse_values = samp_num_partworths*[0.0]\n",
    "#for i in range(0,samp_num_partworths):\n",
    "    #init_mse_values[i] =  np.square(np.subtract(partworths_nmde[i]/np.linalg.norm(partworths_nmde[i],ord = 2),\n",
    "                                                            #mu_initial/np.linalg.norm(mu_initial, ord = 2))).mean()\n",
    "#init_mse_max_index = np.argmax(np.array(init_mse_values))\n",
    "#init_mse_min_index = np.argmin(np.array(init_mse_values))\n",
    "#partworths_nmde = [partworths_nmde[init_mse_min_index],partworths_nmde[init_mse_max_index]]\n",
    "\n",
    "#Declare number of repetitions per partworth and the number of questions in the questionnaire.\n",
    "#rep_per_partworth_nmde = 1\n",
    "#num_questions_nmde = 4\n",
    "#look_ahead_hor_nmde = 4\n",
    "#noise_par_nmde = 1.0\n",
    "\n",
    "#Construct the list of questions for the hitrate procedure.\n",
    "#nmde_question_list = product_diff_list(num_attr_nmde)\n",
    "\n",
    "#Here we decide to use rollout\n",
    "#Method_nmde = 1\n",
    "#batch_size_nmde = 4\n",
    "#MC_budget_nmde = 40\n",
    "#print(Sig_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d0d0eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEEDS TO BE MOVED!!!\n",
    "#Set up random number seed\n",
    "#rng = np.random.default_rng(100) \n",
    "#np.random.seed(100)\n",
    "#random.seed(100)\n",
    "\n",
    "#[Norm_MSE_roll,DET_roll,HITRATE_roll,MSE_roll,Prob_sel_roll] = new_sequential_experiment(mu_initial,Sig_initial,partworths_nmde,rep_per_partworth_nmde,num_questions_nmde,\n",
    "                                           #look_ahead_hor_nmde,mu_log_coeff_6,Sig_log_coeff_6,noise_par_nmde,nmde_question_list,Method = 3,\n",
    "                                            #batch_size = batch_size_nmde,MC_budget=MC_budget_nmde, include_one_step = True,penalty = 1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eb6c561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEEDS TO BE MOVED!!!\n",
    "#Set up random number seed\n",
    "#rng = np.random.default_rng(100) \n",
    "#np.random.seed(100)\n",
    "#random.seed(100)\n",
    "\n",
    "#[Norm_MSE_onestep,DET_onestep,HITRATE_onestep,MSE_onestep,Prob_sel_onestep] = new_mse_det_hitrate_experiment(mu_initial,Sig_initial,partworths_nmde,rep_per_partworth_nmde,num_questions_nmde,\n",
    "                                           #mu_log_coeff_6,Sig_log_coeff_6,noise_par_nmde,nmde_question_list,Method = 0,\n",
    "                                            #batch_size = 0,MC_budget = 0,penalty = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ef78e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOVE IT!!!\n",
    "#print(MSE_roll)\n",
    "#print(DET_onestep)\n",
    "#print(DET_roll)\n",
    "#print(Prob_sel_roll)\n",
    "#print(Prob_sel_onestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80fb178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Plotting MSE data for Max MSE case. Comparing one-step and rollout\n",
    "#x_axis_one_step_max_mse = []\n",
    "\n",
    "#for i in range(1,num_questions_nmde+1):\n",
    "    #for j in range (0,rep_per_partworth_nmde):\n",
    "        #x_axis_one_step_max_mse.append(i)\n",
    "        \n",
    "#y_axis_one_step_max_mse = []\n",
    "\n",
    "#for i in range(0,num_questions_nmde):\n",
    "    #for mse_data in MSE_onestep[1][i]:\n",
    "        #y_axis_one_step_max_mse.append(mse_data)\n",
    "        \n",
    "#x_axis_rollout_max_mse = []\n",
    "\n",
    "#for i in range(1,num_questions_nmde+1):\n",
    "    #for j in range (0,rep_per_partworth_nmde):\n",
    "        #x_axis_rollout_max_mse.append(i)\n",
    "        \n",
    "#y_axis_rollout_max_mse = []\n",
    "\n",
    "#for i in range(0,num_questions_nmde):\n",
    "    #for mse_data in MSE_roll[1][i]:\n",
    "        #y_axis_rollout_max_mse.append(mse_data)\n",
    "        \n",
    "#fig = sns.lineplot(x = x_axis_one_step_max_mse, y = y_axis_one_step_max_mse).set(title='(Max)MSE Sequential Comparison: One-step vs Rollout')\n",
    "#sns.lineplot(x = x_axis_rollout_max_mse, y = y_axis_rollout_max_mse).set( xlabel = \"Question Number\", ylabel = \"MSE After Normalizing\")\n",
    "#plt.legend(labels=[\"One-Step\",\"Rollout\"])\n",
    "#plt.xticks([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0d5d1422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Plotting MSE data for Min MSE case. Comparing one-step and rollout\n",
    "#x_axis_one_step_min_mse = []\n",
    "\n",
    "#for i in range(1,num_questions_nmde+1):\n",
    "    #for j in range (0,rep_per_partworth_nmde):\n",
    "        #x_axis_one_step_min_mse.append(i)\n",
    "        \n",
    "#y_axis_one_step_min_mse = []\n",
    "\n",
    "#for i in range(0,num_questions_nmde):\n",
    "    #for mse_data in MSE_onestep[0][i]:\n",
    "        #y_axis_one_step_min_mse.append(mse_data)\n",
    "        \n",
    "#x_axis_rollout_min_mse = []\n",
    "\n",
    "#for i in range(1,num_questions_nmde+1):\n",
    "    #for j in range (0,rep_per_partworth_nmde):\n",
    "        #x_axis_rollout_min_mse.append(i)\n",
    "        \n",
    "#y_axis_rollout_min_mse = []\n",
    "\n",
    "#for i in range(0,num_questions_nmde):\n",
    "    #for mse_data in MSE_roll[0][i]:\n",
    "        #y_axis_rollout_min_mse.append(mse_data)\n",
    "        \n",
    "#fig = sns.lineplot(x = x_axis_one_step_min_mse, y = y_axis_one_step_min_mse).set(title='(Min)MSE Sequential Comparison: One-step vs Rollout')\n",
    "#sns.lineplot(x = x_axis_rollout_min_mse, y = y_axis_rollout_min_mse).set( xlabel = \"Question Number\", ylabel = \"MSE After Normalizing\")\n",
    "#plt.legend(labels=[\"One-Step\",\"Rollout\"])\n",
    "#plt.xticks([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e2a5b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Plotting determinant data for Max MSE case. Comparing one-step and rollout\n",
    "#x_axis_one_step_max_det = []\n",
    "\n",
    "#for i in range(1,num_questions_nmde+1):\n",
    "    #for j in range (0,rep_per_partworth_nmde):\n",
    "        #x_axis_one_step_max_det.append(i)\n",
    "        \n",
    "#y_axis_one_step_max_det = []\n",
    "\n",
    "#for i in range(0,num_questions_nmde):\n",
    "    #for det_data in DET_onestep[1][i]:\n",
    "        #y_axis_one_step_max_det.append(det_data)\n",
    "        \n",
    "#x_axis_rollout_max_det = []\n",
    "\n",
    "#for i in range(1,num_questions_nmde+1):\n",
    "    #for j in range (0,rep_per_partworth_nmde):\n",
    "        #x_axis_rollout_max_det.append(i)\n",
    "        \n",
    "#y_axis_rollout_max_det = []\n",
    "\n",
    "#for i in range(0,num_questions_nmde):\n",
    "    #for det_data in DET_roll[1][i]:\n",
    "        #y_axis_rollout_max_det.append(det_data)\n",
    "        \n",
    "#fig = sns.lineplot(x = x_axis_one_step_max_det, y = y_axis_one_step_max_det).set(title='(Max)Determinant Sequential Comparison: One-step vs Rollout')\n",
    "#sns.lineplot(x = x_axis_rollout_max_det, y = y_axis_rollout_max_det).set( xlabel = \"Question Number\", ylabel = \"Determinant\")\n",
    "#plt.legend(labels=[\"One-Step\",\"Rollout\"])\n",
    "#plt.xticks([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b74fe426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Plotting determinant data for Max MSE case. Comparing one-step and rollout\n",
    "#x_axis_one_step_min_det = []\n",
    "\n",
    "#for i in range(1,num_questions_nmde+1):\n",
    "    #for j in range (0,rep_per_partworth_nmde):\n",
    "        #x_axis_one_step_min_det.append(i)\n",
    "        \n",
    "#y_axis_one_step_min_det = []\n",
    "\n",
    "#for i in range(0,num_questions_nmde):\n",
    "    #for det_data in DET_onestep[0][i]:\n",
    "        #y_axis_one_step_min_det.append(det_data)\n",
    "        \n",
    "#x_axis_rollout_min_det = []\n",
    "\n",
    "#for i in range(1,num_questions_nmde+1):\n",
    "    #for j in range (0,rep_per_partworth_nmde):\n",
    "        #x_axis_rollout_min_det.append(i)\n",
    "        \n",
    "#y_axis_rollout_min_det = []\n",
    "\n",
    "#for i in range(0,num_questions_nmde):\n",
    "    #for det_data in DET_roll[0][i]:\n",
    "        #y_axis_rollout_min_det.append(det_data)\n",
    "        \n",
    "#fig = sns.lineplot(x = x_axis_one_step_min_det, y = y_axis_one_step_min_det).set(title='(Min)Determinant Sequential Comparison: One-step vs Rollout')\n",
    "#sns.lineplot(x = x_axis_rollout_min_det, y = y_axis_rollout_min_det).set( xlabel = \"Question Number\", ylabel = \"Determinant\")\n",
    "#plt.legend(labels=[\"One-Step\",\"Rollout\"])\n",
    "#plt.xticks([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7f015321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Getting HITRATE Results\n",
    "#Plot boxplot of HITRATE for MAX MSE case\n",
    "#labels_hitrate_max = ['one-step', 'rollout']\n",
    "#plt.boxplot([HITRATE_onestep[1],HITRATE_roll[1]], vert=False, patch_artist=True, labels=labels_hitrate_max) \n",
    "#plt.ylabel(\"Hitrate\")\n",
    "#plt.title(\"Hitrate of One-Step and Rollout (MAX MSE): n=6, rep = 50\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "056702a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS NEEDS TO BE MOVED!!!\n",
    "#Getting HITRATE Results\n",
    "#Plot boxplot of HITRATE for MAX MSE case\n",
    "#labels_hitrate_min = ['one-step', 'rollout']\n",
    "#plt.boxplot([HITRATE_onestep[0],HITRATE_roll[0]], vert=False, patch_artist=True, labels=labels_hitrate_min) \n",
    "#plt.ylabel(\"Hitrate\")\n",
    "#plt.title(\"Hitrate of One-Step and Rollout (MIN MSE): n=6, rep = 50\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5689f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This needs to be moved!\n",
    "#df_MSE_det_09272022 = pd.DataFrame()\n",
    "#questions_09272022 = 4\n",
    "#max_or_min_09272022 = ['MIN','MAX']\n",
    "#for i in range(2):\n",
    "#for j in range(questions_09272022):\n",
    "        #df_MSE_det_09272022['Question %s, Baseline Partworth %s, Rollout MSE' %(str(j),max_or_min_09272022[1])] = MSE_roll[1][j]\n",
    "        #df_MSE_det_09272022['Question %s, Baseline Partworth %s, Rollout DET' %(str(j),max_or_min_09272022[1])] = DET_roll[1][j]\n",
    "\n",
    "#df_MSE_det_09272022.to_csv(r'C:\\Users\\wsfishe\\Desktop\\MSE_det_Max_rep=50_quest=4_Rollout_10052022.csv',index=False,header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
