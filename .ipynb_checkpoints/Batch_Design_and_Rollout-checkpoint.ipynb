{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a6c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This module 'Batch_Design_and_Rollout' includes functions to construct a batch design as well as\n",
    "#doing the rollout method.\n",
    "\n",
    "#Functions in this module include:\n",
    "\n",
    "#orthogonal_constraint_feas\n",
    "#batch_design_delta_penalty #THIS WILL BE PREFERRED OVER batch_design_delta_refine\n",
    "#batch_design_AO #!!!!THIS WAS ADDED ON JUNE 20, 2023!!!!\n",
    "#batch_design_delta_refine\n",
    "#question_selection_prob\n",
    "#rollout\n",
    "#monte_carlo_rollout\n",
    "#rollout_with_batch_design_acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58732179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import scipy.integrate\n",
    "import scipy.stats #import bernoulli\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\wsfishe\\Desktop\\PreferenceElicitationCode')\n",
    "from Baseline_Functions_Definitions import z_expectation_variance, g_fun, g_fun_linear_regression\n",
    "from Questionnaire_Procedure import moment_matching_update, g_opt, two_step_g_acq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e49a2b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS WILL NEED TO BE MOVED!!!\n",
    "#mu_log_coeff_6,Sig_log_coeff_6 = g_fun_linear_regression(0,12.70,0.1,42.0,24,84)\n",
    "#print(mu_log_coeff_6,Sig_log_coeff_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1354cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS WILL NEED TO BE MOVED!!!\n",
    "#This is used to instantiate the coefficient values for optimization when there are 12 attributes.\n",
    "#mu_log_coeff_12,Sig_log_coeff_12 = g_fun_linear_regression(0, 24.50, 0.1, 156.0, 49, 312)\n",
    "#print(mu_log_coeff_12,Sig_log_coeff_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d46b11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to check the feasibility of the orthogonality constraints used in the batch design for a given \n",
    "#tolerance delta. That is, it checks the feasibility of -delta <= q_i * Sig * q_j <= delta for i not equal to j\n",
    "def orthogonal_constraint_feas(mu,Sig,delta,batch_size,t_lim=30):\n",
    "    #mu: expectation of prior on beta\n",
    "    #Sig: Covariance matrix of prior on beta\n",
    "    #delta: This is a parameter in the batch-design model that is used to control the level of orthogonality of \n",
    "    #the various questions in the batch design.\n",
    "    #batch_size: the number of questions we want to return in our batch design. This should be less or equal to the number\n",
    "    #of attributes\n",
    "    #t_lim: a time limit on the running time of the optimization procedure. Not sure if t=100 is sufficient at the moment.\n",
    "    \n",
    "    #This is the number of attributes for the products\n",
    "    n = len(Sig[0])\n",
    "    \n",
    "    m = gp.Model(\"mip1\")\n",
    "    m.setParam('Timelimit',t_lim)\n",
    "    \n",
    "    #Set up the x_i and y_i, i = 1,...,batchsize\n",
    "    X = m.addMVar((batch_size,n),vtype = GRB.BINARY)\n",
    "    Y = m.addMVar((batch_size,n),vtype = GRB.BINARY)\n",
    "    \n",
    "    #Set up the objective function. We use an objective function of 0 just to check the feasibility of the orthogonality\n",
    "    #constraints\n",
    "    m.setObjective(0,GRB.MINIMIZE)\n",
    "    \n",
    "    #Set up the constraints that force the products in question i to be different\n",
    "    for i in range(batch_size):\n",
    "        m.addConstr(X[i]@X[i] - X[i]@Y[i] - Y[i]@X[i] + Y[i]@Y[i] >= 1)\n",
    "        m.addConstr(mu@X[i] - mu@Y[i] >= 0)\n",
    "    \n",
    "    #Set up the Sigma-orthogonality constraint for all questions i and j, i not equal to j.\n",
    "    for i in range(batch_size):\n",
    "        for j in range(i+1,batch_size):\n",
    "            m.addConstr(X[i]@Sig@X[j] - X[i]@Sig@Y[j] - Y[i]@Sig@X[j] + Y[i]@Sig@Y[j] - delta <= 0)\n",
    "            m.addConstr(X[i]@Sig@X[j] - X[i]@Sig@Y[j] - Y[i]@Sig@X[j] + Y[i]@Sig@Y[j] + delta >= 0)\n",
    "            \n",
    "    m.optimize()\n",
    "    \n",
    "    feasibility = True\n",
    "    \n",
    "    #If the time limit was exceeded for finding a feasible solution, we assume the problem is infeasible.\n",
    "    if m.Status == GRB.TIME_LIMIT:\n",
    "        feasibility = False\n",
    "        \n",
    "    return feasibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3e6ed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function constructs a batch design of size k <= (number of attributes) where we enforce mutual \n",
    "#Sigma-orthogonality between the k questions. The orthogonality condition makes it so that the D-error minimization\n",
    "#can be written as a product of g (one-step lookahead) functions. For this function, delta is considered as a continuous\n",
    "#variable and is penalized in the objective function.\n",
    "\n",
    "def batch_design_delta_penalty(mu,Sig,batch_size,mu_log_coeff,Sig_log_coeff,M=100,t_lim=100):\n",
    "    #mu: expectation of prior on beta\n",
    "    #Sig: Covariance matrix of prior on beta\n",
    "    #batch_size: the number of questions we want to return in our batch design. This should be less or equal to the number\n",
    "    #of attributes\n",
    "    #mu_log_coeff: the estimated coefficient c_1 that goes with m in the linear model log(g) = c_1*m + c_2*v\n",
    "    #Sig_log_coeff: the estimated coefficient c_2 that goes with v in the linear model log(g) = c_1m + c_2*v\n",
    "    #M: this is a parameter which will be used as a constant to penalize the orthogonality constraint term delta.\n",
    "    #t_lim: a time limit on the running time of the optimization procedure. Not sure if t=100 is sufficient at the moment.\n",
    "    \n",
    "    #This is the number of attributes for the products\n",
    "    n = len(Sig[0])\n",
    "    \n",
    "    #These are terms corresponding to the linear and quadratic terms in the objective function.\n",
    "    mu_s = mu_log_coeff*mu\n",
    "    Sig_s = Sig_log_coeff*Sig\n",
    "    \n",
    "    m = gp.Model(\"mip1\")\n",
    "    m.setParam('Timelimit',t_lim)\n",
    "    #m.params.NonConvex = 2\n",
    "    \n",
    "    #Set up the x_i and y_i, i = 1,...,batchsize\n",
    "    X = m.addMVar((batch_size,n),vtype = GRB.BINARY)\n",
    "    Y = m.addMVar((batch_size,n),vtype = GRB.BINARY)\n",
    "    delta = m.addVar(lb=0.0, vtype = GRB.CONTINUOUS)\n",
    "    \n",
    "    #Set up the objective function, which is the sum of (batch_size) linearized g functions.\n",
    "    m.setObjective(sum([mu_s@X[i] - mu_s@Y[i] + X[i]@Sig_s@X[i] -X[i]@(2.0*Sig_s)@Y[i] + \n",
    "                   Y[i]@Sig_s@Y[i]  for i in range(batch_size)]) + M*delta,GRB.MINIMIZE)\n",
    "    \n",
    "    #Set up the constraints that force the products in question i to be different, as well as forcing the symmetry\n",
    "    #exploitation condition.\n",
    "    for i in range(batch_size):\n",
    "        m.addConstr(X[i]@X[i] - X[i]@Y[i] - Y[i]@X[i] + Y[i]@Y[i] >= 1)\n",
    "        m.addConstr(mu@X[i] - mu@Y[i] >= 0)\n",
    "    \n",
    "    #Set up the Sigma-orthogonality constraint for all questions i and j, i not equal to j.\n",
    "    for i in range(batch_size):\n",
    "        for j in range(i+1,batch_size):\n",
    "            m.addConstr(X[i]@Sig@X[j] - X[i]@Sig@Y[j] - Y[i]@Sig@X[j] + Y[i]@Sig@Y[j] - delta <= 0)\n",
    "            m.addConstr(X[i]@Sig@X[j] - X[i]@Sig@Y[j] - Y[i]@Sig@X[j] + Y[i]@Sig@Y[j] + delta >= 0)\n",
    "    \n",
    "    m.optimize()\n",
    "    \n",
    "    #This will be the list of products\n",
    "    Q = [ [] for i in range(batch_size)]\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        Q[i].append(X[i].X)\n",
    "        Q[i].append(Y[i].X)\n",
    "        \n",
    "    return[Q,delta.X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "117a13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function constructs a batch design based off of average question mean, average question variance, and average\n",
    "#question orthogonality. For the average question orthogonality, we take the absolute value of the summands rather than\n",
    "#the square. We also normalize mu and Sig in the objective so that we do not need to keep on refitting the parameters \n",
    "#that go with question mean, question variance, and question orthogonality.\n",
    "\n",
    "def batch_design_AO(mu,Sig,batch_size,quest_mean_log_coeff,quest_var_log_coeff,quest_orth_log_coeff,t_lim = 100):\n",
    "    #mu: expectation of prior on beta\n",
    "    #Sig: Covariance matrix of prior on beta\n",
    "    #batch_size: the number of questions we want to return in our batch design. This should be less or equal to the number\n",
    "    #of attributes\n",
    "    #quest_mean_log_coeff: this is a fitting parameter that goes with the average question mean and is obtained \n",
    "    #by fitting a linear model log (D-err/Init_det) ~ AM/||l*mu|| + AV/||s*Sig|| + AO/||s*Sig|| + ||l*mu|| + ||s*Sig|| and using the fitted parameter that goes with\n",
    "    #AM/||l*mu||\n",
    "    #quest_var_log_coeff: this is a fitting parameter that goes with the average question variance and is obtained \n",
    "    #by fitting a linear model log (D-err/Init_det) ~ AM/||l*mu|| + AV/||s*Sig|| + AO/||s*Sig|| + ||l*mu|| + ||s*Sig|| and using the fitted parameter that goes with\n",
    "    #AV/||s*Sig||\n",
    "    #quest_orth_log_coeff: this is a fitting parameter that goes with the average question orthogonality and is obtained \n",
    "    #by fitting a linear model log (D-err/Init_det) ~ AM/||l*mu|| + AV/||s*Sig|| + AO/||s*Sig|| + ||l*mu|| + ||s*Sig|| and using the fitted parameter that goes with\n",
    "    #AO/||s*Sig||\n",
    "    #(l,s) are scaling parameters for mu and Sig that divide the space into different signal-to-noise ratio regions.\n",
    "    #t_lim: this is the max amount of time we want to take to construct the batch\n",
    "    \n",
    "    #Make sure that quest_orth_log_coeff is greater or equal to zero. Otherwise, we will\n",
    "    #have an unbounded optimization problem. In most situations, the fitting procedure\n",
    "    #will result in a positive value for quest_orth_log_coeff, but very rarely the fitting\n",
    "    #procedure will give a statistically non-significant but negative value for\n",
    "    #quest_orth_log_coeff that makes the optimization problem bounded. When the quest_orth_log_coeff\n",
    "    #is less than 0, we decide to set it equal to 0. This will result in a bounded optimization problem,\n",
    "    #but the quality of the solution in terms of D-error may not be sufficient because we are no\n",
    "    #longer controlling orthogonality in the objective function.\n",
    "    if quest_orth_log_coeff<0.0:\n",
    "        quest_orth_log_coeff = 0.0\n",
    "    \n",
    "    #This is the number of attributes for the products\n",
    "    n = len(Sig[0])\n",
    "    \n",
    "    m = gp.Model(\"mip1\")\n",
    "    m.setParam('Timelimit',t_lim)\n",
    "    \n",
    "    #calculate 2-norms of mu and Sigma\n",
    "    mu_2norm = np.linalg.norm(mu,2)\n",
    "    Sig_2norm = np.linalg.norm(Sig,2)\n",
    "    \n",
    "    #List of tuples for delta variable\n",
    "    delta_tuples = []\n",
    "    for i in range(batch_size):\n",
    "        for j in range(i+1,batch_size):\n",
    "            delta_tuples.append((i,j))\n",
    "    \n",
    "    #Set up the x_i and y_i, i = 1,...,batchsize\n",
    "    X = m.addMVar((batch_size,n),vtype = GRB.BINARY)\n",
    "    Y = m.addMVar((batch_size,n),vtype = GRB.BINARY)\n",
    "    Delta = m.addVars(delta_tuples, lb=0.0, vtype = GRB.CONTINUOUS)\n",
    "    \n",
    "    #Set up the objective function.\n",
    "    m.setObjective((quest_mean_log_coeff/(batch_size*mu_2norm))*sum([mu@X[i] - mu@Y[i] for i in range(batch_size)]) + \n",
    "                   (quest_var_log_coeff/(batch_size*Sig_2norm))*sum([X[i]@Sig@X[i] - X[i]@(2.0*Sig)@Y[i] + \n",
    "                   Y[i]@Sig@Y[i] for i in range(batch_size)]) + \n",
    "                   (quest_orth_log_coeff/(batch_size*(batch_size-1)*Sig_2norm/2))*sum([Delta[i,j] for i in range(batch_size) for j in range(i+1,batch_size)]),GRB.MINIMIZE)\n",
    "    \n",
    "    #Set up the constraints that force the products in question i to be different, as well as forcing the symmetry\n",
    "    #exploitation condition.\n",
    "    for i in range(batch_size):\n",
    "        m.addConstr(X[i]@X[i] - X[i]@Y[i] - Y[i]@X[i] + Y[i]@Y[i] >= 1)\n",
    "        m.addConstr(mu@X[i] - mu@Y[i] >= 0)\n",
    "        \n",
    "    #Set up the Sigma-orthogonality constraint for all questions i and j, i not equal to j. Also add constraints\n",
    "    #to make sure that questions within a batch are different, including with respect to switching order of products in\n",
    "    #the questions.\n",
    "    for i in range(batch_size):\n",
    "        for j in range(i+1,batch_size):\n",
    "            m.addConstr(X[i]@Sig@X[j] - X[i]@Sig@Y[j] - Y[i]@Sig@X[j] + Y[i]@Sig@Y[j] - Delta[i,j] <= 0)\n",
    "            m.addConstr(X[i]@Sig@X[j] - X[i]@Sig@Y[j] - Y[i]@Sig@X[j] + Y[i]@Sig@Y[j] + Delta[i,j] >= 0)\n",
    "            m.addConstr(X[i]@X[i] - X[i]@Y[i] - X[i]@X[j] + X[i]@Y[j] -\n",
    "                       Y[i]@X[i] + Y[i]@Y[i] + Y[i]@X[j] - Y[i]@Y[j] -\n",
    "                       X[j]@X[i] + X[j]@Y[i] + X[j]@X[j] - X[j]@Y[j] +\n",
    "                       Y[j]@X[i] - Y[j]@Y[i] - Y[j]@X[j] + Y[j]@Y[j] >= 1)\n",
    "            m.addConstr(X[i]@X[i] - X[i]@Y[i] - X[i]@Y[j] + X[i]@X[j] -\n",
    "                       Y[i]@X[i] + Y[i]@Y[i] + Y[i]@Y[j] - Y[i]@X[j] -\n",
    "                       Y[j]@X[i] + Y[j]@Y[i] + Y[j]@Y[j] - Y[j]@X[j] +\n",
    "                       X[j]@X[i] - X[j]@Y[i] - X[j]@Y[j] + X[j]@X[j] >= 1)\n",
    "            \n",
    "    m.optimize()\n",
    "    \n",
    "    #This will be the list of products\n",
    "    Q = [ [] for i in range(batch_size)]\n",
    "    D = [ [] for i in range(batch_size-1)]\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        Q[i].append(X[i].X)\n",
    "        Q[i].append(Y[i].X)\n",
    "        \n",
    "    for i in range(batch_size):\n",
    "        for j in range(i+1, batch_size):\n",
    "            D[i].append(Delta[i,j].X)\n",
    "        \n",
    "    return[Q,D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "835a1ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS WILL NEED TO BE MOVED!!!\n",
    "#Example for batch_design_AO\n",
    "#mu_ao = np.array(6*[1.0])\n",
    "#Sig_ao = 1.0*np.identity(6)\n",
    "#batch_size_ao = 4\n",
    "#alpha_ao = 0.2813\n",
    "#kappa_ao = -0.1019\n",
    "#gamma_ao = 0.0577\n",
    "#print(batch_design_AO(mu_ao,Sig_ao,batch_size_ao,alpha_ao,kappa_ao,gamma_ao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9196e26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function constructs a batch design based off of average question mean, average question variance, and MAXIMUM\n",
    "#question orthogonality. For the average question orthogonality, we take the absolute value of the summands rather than\n",
    "#the square. We also normalize mu and Sig in the objective so that we do not need to keep on refitting the parameters \n",
    "#that go with question mean, question variance, and question orthogonality.\n",
    "\n",
    "def batch_design_MO(mu,Sig,batch_size,quest_mean_log_coeff,quest_var_log_coeff,quest_orth_log_coeff,t_lim = 100):\n",
    "    #mu: expectation of prior on beta\n",
    "    #Sig: Covariance matrix of prior on beta\n",
    "    #batch_size: the number of questions we want to return in our batch design. This should be less or equal to the number\n",
    "    #of attributes\n",
    "    #quest_mean_log_coeff: this is a fitting parameter that goes with the average question mean and is obtained \n",
    "    #by fitting a linear model log (D-err/Init_det) ~ AM/||l*mu|| + AV/||s*Sig|| + MO/||s*Sig|| + ||l*mu|| + ||s*Sig|| and using the fitted parameter that goes with\n",
    "    #AM/||l*mu||\n",
    "    #quest_var_log_coeff: this is a fitting parameter that goes with the average question variance and is obtained \n",
    "    #by fitting a linear model log (D-err/Init_det) ~ AM/||l*mu|| + AV/||s*Sig|| + MO/||s*Sig|| + ||l*mu|| + ||s*Sig|| and using the fitted parameter that goes with\n",
    "    #AV/||s*Sig||\n",
    "    #quest_orth_log_coeff: this is a fitting parameter that goes with the average question orthogonality and is obtained \n",
    "    #by fitting a linear model log (D-err/Init_det) ~ AM/||l*mu|| + AV/||s*Sig|| + MO/||s*Sig|| + ||l*mu|| + ||s*Sig|| and using the fitted parameter that goes with\n",
    "    #MO/||s*Sig||\n",
    "    #(l,s) are scaling parameters for mu and Sig that divide the space into different signal-to-noise ratio regions.\n",
    "    #t_lim: this is the max amount of time we want to take to construct the batch\n",
    "    \n",
    "    #Make sure that quest_orth_log_coeff is greater or equal to zero. Otherwise, we will\n",
    "    #have an unbounded optimization problem. In most situations, the fitting procedure\n",
    "    #will result in a positive value for quest_orth_log_coeff, but very rarely the fitting\n",
    "    #procedure will give a statistically non-significant but negative value for\n",
    "    #quest_orth_log_coeff that makes the optimization problem bounded. When the quest_orth_log_coeff\n",
    "    #is less than 0, we decide to set it equal to 0. This will result in a bounded optimization problem,\n",
    "    #but the quality of the solution in terms of D-error may not be sufficient because we are no\n",
    "    #longer controlling orthogonality in the objective function.\n",
    "    if quest_orth_log_coeff<0.0:\n",
    "        quest_orth_log_coeff = 0.0\n",
    "    \n",
    "    #This is the number of attributes for the products\n",
    "    n = len(Sig[0])\n",
    "    \n",
    "    m = gp.Model(\"mip1\")\n",
    "    m.setParam('Timelimit',t_lim)\n",
    "    \n",
    "    #calculate 2-norms of mu and Sigma\n",
    "    mu_2norm = np.linalg.norm(mu,2)\n",
    "    Sig_2norm = np.linalg.norm(Sig,2)\n",
    "    \n",
    "    #Set up the x_i and y_i, i = 1,...,batchsize\n",
    "    X = m.addMVar((batch_size,n),vtype = GRB.BINARY)\n",
    "    Y = m.addMVar((batch_size,n),vtype = GRB.BINARY)\n",
    "    delta = m.addVar(lb=0.0, vtype = GRB.CONTINUOUS)\n",
    "    \n",
    "    #set up the objective function\n",
    "    m.setObjective((quest_mean_log_coeff/(batch_size*mu_2norm))*sum([mu@X[i] - mu@Y[i] for i in range(batch_size)]) +\n",
    "                  (quest_var_log_coeff/(batch_size*Sig_2norm))*sum([X[i]@Sig@X[i] - X[i]@(2.0*Sig)@Y[i] + \n",
    "                   Y[i]@Sig@Y[i] for i in range(batch_size)]) + (quest_orth_log_coeff/Sig_2norm)*delta,GRB.MINIMIZE)\n",
    "    \n",
    "    #Set up the constraints that force the products in question i to be different, as well as forcing the symmetry\n",
    "    #exploitation condition.\n",
    "    for i in range(batch_size):\n",
    "        m.addConstr(X[i]@X[i] - X[i]@Y[i] - Y[i]@X[i] + Y[i]@Y[i] >= 1)\n",
    "        m.addConstr(mu@X[i] - mu@Y[i] >= 0)\n",
    "    \n",
    "    #Set up the Sigma-orthogonality constraint for all questions i and j, i not equal to j. Also add constraints\n",
    "    #to make sure that questions within a batch are different, including with respect to switching order of products in\n",
    "    #the questions.\n",
    "    for i in range(batch_size):\n",
    "        for j in range(i+1,batch_size):\n",
    "            m.addConstr(X[i]@Sig@X[j] - X[i]@Sig@Y[j] - Y[i]@Sig@X[j] + Y[i]@Sig@Y[j] - delta <= 0)\n",
    "            m.addConstr(X[i]@Sig@X[j] - X[i]@Sig@Y[j] - Y[i]@Sig@X[j] + Y[i]@Sig@Y[j] + delta >= 0)\n",
    "            m.addConstr(X[i]@X[i] - X[i]@Y[i] - X[i]@X[j] + X[i]@Y[j] -\n",
    "                       Y[i]@X[i] + Y[i]@Y[i] + Y[i]@X[j] - Y[i]@Y[j] -\n",
    "                       X[j]@X[i] + X[j]@Y[i] + X[j]@X[j] - X[j]@Y[j] +\n",
    "                       Y[j]@X[i] - Y[j]@Y[i] - Y[j]@X[j] + Y[j]@Y[j] >= 1)\n",
    "            m.addConstr(X[i]@X[i] - X[i]@Y[i] - X[i]@Y[j] + X[i]@X[j] -\n",
    "                       Y[i]@X[i] + Y[i]@Y[i] + Y[i]@Y[j] - Y[i]@X[j] -\n",
    "                       Y[j]@X[i] + Y[j]@Y[i] + Y[j]@Y[j] - Y[j]@X[j] +\n",
    "                       X[j]@X[i] - X[j]@Y[i] - X[j]@Y[j] + X[j]@X[j] >= 1)\n",
    "    \n",
    "    m.optimize()\n",
    "    \n",
    "    #This will be the list of products\n",
    "    Q = [ [] for i in range(batch_size)]\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        Q[i].append(X[i].X)\n",
    "        Q[i].append(Y[i].X)\n",
    "        \n",
    "    return[Q,delta.X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d11de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS WILL NEED TO BE MOVED!!!\n",
    "#Example for batch_design_MO\n",
    "#mu_mo = np.array(6*[1.0])\n",
    "#Sig_mo = 1.0*np.identity(6)\n",
    "#batch_size_mo = 4\n",
    "#alpha_mo = 0.2798\n",
    "#kappa_mo = -0.1000\n",
    "#gamma_mo = 0.0251\n",
    "#print(batch_design_MO(mu_mo,Sig_mo,batch_size_mo,alpha_mo,kappa_mo,gamma_mo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f303d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function constructs a batch design of size k <= (number of attributes) where we enforce mutual \n",
    "#Sigma-orthogonality between the k questions. The orthogonality condition makes it so that the D-error minimization\n",
    "#can be written as a product of g (one-step lookahead) functions. In this function, we are given a initial delta which is \n",
    "#assumed to be feasible and refine this delta to make it smaller using the function orthogonal_constraint_feas\n",
    "\n",
    "def batch_design_delta_refine(mu,Sig,batch_size,mu_log_coeff,Sig_log_coeff,start_delta,t_lim=100):\n",
    "    #mu: expectation of prior on beta\n",
    "    #Sig: Covariance matrix of prior on beta\n",
    "    #batch_size: the number of questions we want to return in our batch design. This should be less or equal to the number\n",
    "    #of attributes\n",
    "    #mu_log_coeff: the estimated coefficient c_1 that goes with m in the linear model log(g) = c_1*m + c_2*v\n",
    "    #Sig_log_coeff: the estimated coefficient c_2 that goes with v in the linear model log(g) = c_1m + c_2*v\n",
    "    #start_delta: this is the delta value that we start the orthogonality constraint with. Before the optimization procedure,\n",
    "    #we attempt to find a smaller value of delta so that the orthogonality constraint is tighter.\n",
    "    #M: this is a parameter which will be used as a constant to penalize the orthogonality constraint term delta.\n",
    "    #t_lim: a time limit on the running time of the optimization procedure. Not sure if t=100 is sufficient at the moment.\n",
    "    \n",
    "    #This is the number of attributes for the products\n",
    "    n = len(Sig[0])\n",
    "    \n",
    "    #These are terms corresponding to the linear and quadratic terms in the objective function.\n",
    "    mu_s = mu_log_coeff*mu\n",
    "    Sig_s = Sig_log_coeff*Sig\n",
    "    \n",
    "    m = gp.Model(\"mip1\")\n",
    "    m.setParam('Timelimit',t_lim)\n",
    "    #m.params.NonConvex = 2\n",
    "    \n",
    "    #Set up the x_i and y_i, i = 1,...,batchsize\n",
    "    X = m.addMVar((batch_size,n),vtype = GRB.BINARY)\n",
    "    Y = m.addMVar((batch_size,n),vtype = GRB.BINARY)\n",
    "    \n",
    "    #Find a small value of delta so that the problem is feasible. ASSUME we start with a feasible delta (so we pick delta\n",
    "    #to be large enough)\n",
    "    delta = start_delta\n",
    "    feasible = True\n",
    "    while feasible:\n",
    "        delta = delta/2.0\n",
    "        feasible = orthogonal_constraint_feas(mu,Sig,delta,batch_size,t_lim=15)\n",
    "        if not feasible:\n",
    "            delta = 2.0*delta\n",
    "        print(delta)\n",
    "        \n",
    "\n",
    "    #Set up the objective function, which is the sum of (batch_size) linearized g functions.\n",
    "    m.setObjective(sum([mu_s@X[i] - mu_s@Y[i] + X[i]@Sig_s@X[i] -X[i]@(2.0*Sig_s)@Y[i] + \n",
    "                   Y[i]@Sig_s@Y[i]  for i in range(batch_size)]),GRB.MINIMIZE)\n",
    "    \n",
    "    #Set up the constraints that force the products in question i to be different, as well as forcing the symmetry\n",
    "    #exploitation condition.\n",
    "    for i in range(batch_size):\n",
    "        m.addConstr(X[i]@X[i] - X[i]@Y[i] - Y[i]@X[i] + Y[i]@Y[i] >= 1)\n",
    "        m.addConstr(mu@X[i] - mu@Y[i] >= 0)\n",
    "    \n",
    "    #Set up the Sigma-orthogonality constraint for all questions i and j, i not equal to j.\n",
    "    for i in range(batch_size):\n",
    "        for j in range(i+1,batch_size):\n",
    "            m.addConstr(X[i]@Sig@X[j] - X[i]@Sig@Y[j] - Y[i]@Sig@X[j] + Y[i]@Sig@Y[j] - delta <= 0)\n",
    "            m.addConstr(X[i]@Sig@X[j] - X[i]@Sig@Y[j] - Y[i]@Sig@X[j] + Y[i]@Sig@Y[j] + delta >= 0)\n",
    "    \n",
    "    m.optimize()\n",
    "    \n",
    "    #This will be the list of products\n",
    "    Q = [ [] for i in range(batch_size)]\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        Q[i].append(X[i].X)\n",
    "        Q[i].append(Y[i].X)\n",
    "        \n",
    "    return[Q,delta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1404dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS WILL NEED TO BE MOVED!!!\n",
    "#An example of the batch design delta penalty algorithm.\n",
    "#rng = np.random.default_rng(10000) \n",
    "#np.random.seed(10000)\n",
    "\n",
    "#num_penalty = 6\n",
    "#mu_test_penalty = rng.uniform(low = -1.0, high = 1.0, size = num_penalty)#np.array(num_penalty*[1.0])#rng.uniform(low = -1.0, high = 1.0, size = num_penalty)\n",
    "#Sig_test_penalty = sklearn.datasets.make_spd_matrix(num_penalty)#np.identity(num_penalty)#sklearn.datasets.make_spd_matrix(num_penalty)\n",
    "#batch_size_penalty = 4\n",
    "#print('mu: ' + str(mu_test_penalty))\n",
    "#print('Sig: ' + str(Sig_test_penalty))\n",
    "#print(batch_design_delta_penalty(mu_test_penalty,Sig_test_penalty,batch_size_penalty,mu_log_coeff_6,Sig_log_coeff_6,M = 0.01))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deb7c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE MIGHT DELETE THIS FULLY!!!\n",
    "#Create a graph showcasing changing of orthogonality delta with parameter M\n",
    "#M_values = np.arange(0.01,1.01,0.01)\n",
    "#M_val_len = len(M_values)\n",
    "#delta_values = np.array(M_val_len*[0.0])\n",
    "#for i in range(M_val_len):\n",
    "    #delta_values[i] = batch_design_delta_penalty(mu_test_penalty,Sig_test_penalty,batch_size_penalty,\n",
    "                                                 #mu_log_coeff_6,Sig_log_coeff_6,M = M_values[i])[1]\n",
    "\n",
    "#print(delta_values)\n",
    "#plt.title(\"Batch Orthogonality Variation with Changing Orthogonality Parameter\") \n",
    "#plt.xlabel(\"Orthogonality Parameter\") \n",
    "#plt.ylabel(\"Batch Orthogonality Measure\") \n",
    "#plt.plot(M_values,delta_values) \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2493c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE MIGHT DELETE THIS FULLY!!!\n",
    "#M_values_01 = np.arange(0.02,1.01,0.01)\n",
    "#delta_values_01 = delta_values[1:]\n",
    "#plt.title(\"Batch Orthogonality Variation with Changing Orthogonality Parameter\") \n",
    "#plt.xlabel(\"Orthogonality Parameter\") \n",
    "#plt.ylabel(\"Batch Orthogonality Measure\") \n",
    "#plt.plot(M_values_01,delta_values_01) \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d28692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE WILL NEED TO MOVE THIS!!!\n",
    "#An example of the batch design delta refine algorithm.\n",
    "#rng = np.random.default_rng(10000) \n",
    "#np.random.seed(10000)\n",
    "\n",
    "#num_refine = 6\n",
    "#mu_test_refine = rng.uniform(low = -1.0, high = 1.0, size = num_refine)#np.array(num*[1.0])\n",
    "#Sig_test_refine = sklearn.datasets.make_spd_matrix(num_refine)#np.identity(num)\n",
    "#batch_size_refine = 4\n",
    "#delta_start_refine = 2.0\n",
    "#print(batch_design_delta_refine(mu_test_refine,Sig_test_refine,batch_size_refine,\n",
    "                                #mu_log_coeff_6,Sig_log_coeff_6,delta_start_refine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6e2a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WE WILL NEED TO MOVE THIS\n",
    "#An example of the feasibility checking algorithm\n",
    "#rng = np.random.default_rng(10000) \n",
    "#np.random.seed(10000)\n",
    "\n",
    "#feas_num = 6\n",
    "#Sig_feas_test = sklearn.datasets.make_spd_matrix(feas_num)\n",
    "#delta_feas = 0.0025\n",
    "#batch_feas = 4\n",
    "#print(orthogonal_constraint_feas(Sig_feas_test,delta_feas,batch_feas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbff65c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used for calculating the probability of a user picking x over y.\n",
    "def question_selection_prob(mu,Sig,x,y):\n",
    "    #mu is mean parameter of the prior\n",
    "    #Sig is the covariance matrix of the prior\n",
    "    #x is the \"preferred\" product ( i.e, we will calculate P(x>y) )\n",
    "    #y is the secondary product\n",
    "    integ_bound = 30.0\n",
    "    \n",
    "    mu,Sig = np.array(mu),np.array(Sig)\n",
    "    x,y = np.array(x),np.array(y)\n",
    "    \n",
    "    #Set up function to calculate the probability of choosing x over y\n",
    "    m = np.dot(mu,x-y)\n",
    "    v = np.dot(x-y,np.dot(Sig,x-y))\n",
    "    fun1 = lambda z: ((1 + math.e**(-m - math.sqrt(v)*z))**(-1))*(math.e**((-z**2)/2))/math.sqrt(2*math.pi)\n",
    "    \n",
    "    probability = scipy.integrate.quad(fun1, -integ_bound, integ_bound)[0]\n",
    "    \n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5631f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS WILL NEED TO BE MOVED!!!\n",
    "#This is to look at the question_selection_prob function\n",
    "#rng = np.random.default_rng(100) \n",
    "#np.random.seed(100)\n",
    "#num_prob = 6\n",
    "#mu_test_prob = rng.uniform(low = -1.0, high = 1.0, size = num_prob)#np.array(num*[1.0])\n",
    "#Sig_test_prob = sklearn.datasets.make_spd_matrix(num_prob)# np.identity(num_prob)\n",
    "#print(mu_test_prob)\n",
    "#print(Sig_test_prob)\n",
    "#x_test_prob = num_prob*[1]\n",
    "#y_test_prob = num_prob*[0]\n",
    "#print('prob x over y:' + str(question_selection_prob(mu_test_prob,Sig_test_prob,x_test_prob,y_test_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c366cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is to perform full enumerative rollout \n",
    "\n",
    "def rollout(mu,Sig,x,y,rollout_length,mu_log_coeff,Sig_log_coeff):\n",
    "    #mu: This is the initial mean parameter that we start with\n",
    "    #Sig: This is the initial covariance matrix we start with\n",
    "    #x,y: These are the two products (question) that we start the rollout process with\n",
    "    #rollout_length: This is how far ahead we wish to \"rollout\" the initial question (x,y) under the one\n",
    "    #step lookahead base policy\n",
    "    #mu_log_coeff: the estimated coefficient c_1 that goes with m in the linear model log(g) = c_1*m + c_2*v\n",
    "    #Sig_log_coeff: the estimated coefficient c_2 that goes with v in the linear model log(g) = c_1m + c_2*v\n",
    "    #trimming_parameter: This is the probability of success parameter we use in the bernoulli random variable that is used\n",
    "    #to determine whether we perform trimming at the kth level in the trajectory tree.\n",
    "    \n",
    "    #Calculate the probability of user picking x over y and y over x\n",
    "    prob_x = question_selection_prob(mu,Sig,x,y)\n",
    "    prob_y = 1.0 - prob_x\n",
    "    \n",
    "    #Update mu and Sig depending on if the user picks x or y.\n",
    "    mu_x,Sig_x = moment_matching_update(x,y,mu,Sig)\n",
    "    mu_y,Sig_y = moment_matching_update(y,x,mu,Sig)\n",
    "    \n",
    "    #Save updated parameters and probabilities\n",
    "    N_x = [mu_x,Sig_x,prob_x]\n",
    "    N_y = [mu_y,Sig_y,prob_y]\n",
    "    \n",
    "    N = [N_x,N_y]\n",
    "    \n",
    "    for i in range(rollout_length):\n",
    "        #Instantiate a list that will hold nodes at the (i+1)th level after N = [N_x,N_y]\n",
    "        Node_list = []\n",
    "        \n",
    "        #start_time_roll_node = time.perf_counter()\n",
    "        for node in N:\n",
    "            \n",
    "            #Extract mean, covariance matrix, and (accumulated) probability.\n",
    "            mu_n = node[0]\n",
    "            Sig_n = node[1]\n",
    "            prob_n = node[2]\n",
    "            \n",
    "            #Based off of the mean and covariance matrix, find the optimal one-step query, (x_n,y_n)\n",
    "            x_n,y_n = g_opt(mu_n,Sig_n,mu_log_coeff,Sig_log_coeff)[1:] \n",
    "            \n",
    "            #Calculate the probability of the user choosing xn or yn\n",
    "            prob_xn = question_selection_prob(mu_n,Sig_n,x_n,y_n)\n",
    "            prob_yn = 1.0 - prob_xn\n",
    "            \n",
    "            \n",
    "            #Calculate the accumulated probability up to this node\n",
    "            accumulate_prob_xn = prob_xn * prob_n\n",
    "            accumulate_prob_yn = prob_yn * prob_n\n",
    "\n",
    "            #Perform a moment matching update to get new parameters mu and Sig for both cases when the user\n",
    "            #prefers x_n and y_n.\n",
    "            mu_nx,Sig_nx = moment_matching_update(x_n,y_n,mu_n,Sig_n)\n",
    "            mu_ny,Sig_ny = moment_matching_update(y_n,x_n,mu_n,Sig_n)\n",
    "\n",
    "            #Store the parameters and accumulated probability in nodes.\n",
    "            N_xn = [mu_nx,Sig_nx,accumulate_prob_xn]\n",
    "            N_yn = [mu_ny,Sig_ny,accumulate_prob_yn]\n",
    "\n",
    "            Node_list.append(N_xn)\n",
    "            Node_list.append(N_yn)\n",
    "\n",
    "                \n",
    "        N = Node_list\n",
    "        #print(\"Rollout Layer \" + str(i) + \": \",time.perf_counter() - start_time_roll_node, \"seconds\")\n",
    "    #print('Node List:' + str(N))\n",
    "    weighted_det_sum = sum(np.sqrt(np.linalg.det(node[1]))*node[2] for node in N)\n",
    "    \n",
    "    return weighted_det_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "187e9e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is used to perform rollout using monte-carlo method\n",
    "\n",
    "def monte_carlo_rollout(mu,Sig,x,y,rollout_length,mu_log_coeff,Sig_log_coeff,sample_budget):\n",
    "    #mu: This is the initial mean parameter that we start with\n",
    "    #Sig: This is the initial covariance matrix we start with\n",
    "    #x,y: These are the two products (question) that we start the rollout process with\n",
    "    #rollout_length: This is how far ahead we wish to \"rollout\" the initial question (x,y) under the one\n",
    "    #step lookahead base policy\n",
    "    #mu_log_coeff: The estimated coefficient c_1 that goes with m in the linear model log(g) = c_1*m + c_2*v\n",
    "    #Sig_log_coeff: The estimated coefficient c_2 that goes with v in the linear model log(g) = c_1m + c_2*v\n",
    "    #sample_budget: This is the number of trajectories that we want to use.\n",
    "    \n",
    "    #Calculate the probability of user picking x over y and y over x\n",
    "    Sig_list = []\n",
    "    \n",
    "    prob_x = question_selection_prob(mu,Sig,x,y)\n",
    "    prob_y = 1.0 - prob_x\n",
    "    \n",
    "    #Look at which product is preferred\n",
    "    if prob_x >= prob_y:\n",
    "        prefer_prob = prob_x \n",
    "        prefer_product = x\n",
    "        not_prefer_product = y\n",
    "    else:\n",
    "        prefer_prob = prob_y \n",
    "        prefer_product = y\n",
    "        not_prefer_product = x\n",
    "    \n",
    "    #Sample 'sample_budget' number of trajectories.\n",
    "    for i in range(sample_budget):\n",
    "        \n",
    "        #Create a bernoulli random variable with probability parameter equal to the probability of the product having\n",
    "        #the higher probability of selection between x and y.\n",
    "        path_selector = scipy.stats.bernoulli.rvs(prefer_prob)\n",
    "        \n",
    "        #Perform moment matching according to the value of the bernoulli random variable, path_selector. If path_selector\n",
    "        #is 1.0, we will go down the branch with higher probability. If path_selector is 0.0, we will go down the branch \n",
    "        #with lower probability.\n",
    "        if path_selector == 1.0:\n",
    "            mu_n,Sig_n = moment_matching_update(prefer_product,not_prefer_product,mu,Sig)\n",
    "        else:\n",
    "            mu_n,Sig_n = moment_matching_update(not_prefer_product,prefer_product,mu,Sig)\n",
    "        \n",
    "        #We start the rollout process on initial question (x,y)\n",
    "        for j in range(rollout_length):\n",
    "            \n",
    "            #Solve the one-step lookahead problem to get the next question pair\n",
    "            x_n,y_n = g_opt(mu_n,Sig_n,mu_log_coeff,Sig_log_coeff)[1:] \n",
    "            \n",
    "            #Calculate the probability of x_n and y_n given mu_n and Sig_n\n",
    "            prob_xn = question_selection_prob(mu_n,Sig_n,x_n,y_n)\n",
    "            prob_yn = 1.0 - prob_xn\n",
    "            \n",
    "            #Check which of x_n and y_n has a higher probability. \n",
    "            if prob_xn >= prob_yn:\n",
    "                prefer_prob_n = prob_xn \n",
    "                prefer_product_n = x_n\n",
    "                not_prefer_product_n = y_n\n",
    "            else:\n",
    "                prefer_prob_n = prob_yn \n",
    "                prefer_product_n = y_n\n",
    "                not_prefer_product_n = x_n\n",
    "            \n",
    "            #Create a bernoulli random variable with parameter prefer_prob_n.\n",
    "            path_selector_n = scipy.stats.bernoulli.rvs(prefer_prob_n)\n",
    "            \n",
    "            #Perform moment matching according to the value of the bernoulli random variable, path_selector_n. \n",
    "            #If path_selector_n\n",
    "            #is 1.0, we will go down the branch with higher probability. If path_selector is 0.0, we will go down the branch \n",
    "            #with lower probability.\n",
    "            if path_selector_n == 1.0:\n",
    "                mu_n,Sig_n = moment_matching_update(prefer_product_n,not_prefer_product_n,mu_n,Sig_n)\n",
    "            else:\n",
    "                mu_n,Sig_n = moment_matching_update(not_prefer_product_n,prefer_product_n,mu_n,Sig_n)\n",
    "                \n",
    "        \n",
    "        #After we finish one trajectory, we append the resulting covariance matrix to a list.\n",
    "        Sig_list.append(Sig_n)\n",
    "        \n",
    "    \n",
    "    #Calculate an estimate for the determinant. We use the sample average of the determinants of the covariances coming from\n",
    "    #different trajectories.\n",
    "    determinant_estimate = (1/sample_budget)*sum(np.sqrt(np.linalg.det(S)) for S in Sig_list)\n",
    "    \n",
    "    return determinant_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d9b7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS WILL NEED TO BE MOVED!!!\n",
    "#Example of rollout method:\n",
    "#rng = np.random.default_rng(100) \n",
    "#np.random.seed(100)\n",
    "#num_attr = 6\n",
    "#roll_len = 8\n",
    "#mu_roll = num_attr*[1.0]#rng.uniform(low = -1.0, high = 1.0, size = num_attr)#\n",
    "#Sig_roll = np.identity(num_attr)#sklearn.datasets.make_spd_matrix(num_attr)#\n",
    "#x_roll = [1.0,1.0,1.0,0.0,0.0,0.0]#num_attr*[1.0]\n",
    "#y_roll = [0.0,0.0,0.0,1.0,1.0,1.0]#num_attr*[0.0]\n",
    "\n",
    "#start_time_roll_t1 = time.perf_counter()\n",
    "#print(rollout(mu_roll,Sig_roll,x_roll,y_roll,roll_len,mu_log_coeff_6,Sig_log_coeff_6))\n",
    "#print(\"Overall Rollout: \",time.perf_counter() - start_time_roll_t1, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c04ed8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS WILL NEED TO BE MOVED!!!\n",
    "#Example of monte_carlo_rollout method:\n",
    "#rng = np.random.default_rng(100) \n",
    "#np.random.seed(100)\n",
    "#num_attr = 12\n",
    "#roll_len = 11\n",
    "#budget = 50\n",
    "#mu_mcroll = num_attr*[1.0]#rng.uniform(low = -1.0, high = 1.0, size = num_attr)#num_attr*[0.5]\n",
    "#Sig_mcroll = np.identity(num_attr)#sklearn.datasets.make_spd_matrix(num_attr)#np.identity(num_attr)\n",
    "#x_mcroll = [1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0]#num_attr*[1.0]\n",
    "#y_mcroll = [0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0]#num_attr*[0.0]\n",
    "\n",
    "#start_time_mcroll_t1 = time.perf_counter()\n",
    "#print(monte_carlo_rollout(mu_mcroll,Sig_mcroll,x_mcroll,y_mcroll,roll_len,mu_log_coeff_12,Sig_log_coeff_12,budget))\n",
    "#print(\"Overall MC-Rollout: \",time.perf_counter() - start_time_mcroll_t1, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54951e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used for constructing a batch design and performing rollout on this batch design, returning the question\n",
    "#amongst the batch that results in the lowest average determinant value\n",
    "\n",
    "def rollout_with_batch_design_acquisition(mu,Sig,mu_log_coeff,Sig_log_coeff,batch_size,rollout_length,MC_budget,include_one_step = False,\n",
    "                                          penalty_term = 100):\n",
    "    #mu: This is the initial mean parameter that we start with\n",
    "    #Sig: This is the initial covariance matrix we start with\n",
    "    #mu_log_coeff: The estimated coefficient c_1 that goes with m in the linear model log(g) = c_1*m + c_2*v\n",
    "    #Sig_log_coeff: The estimated coefficient c_2 that goes with v in the linear model log(g) = c_1m + c_2*v\n",
    "    #batch_size: the number of questions we want to return in our batch design. This should be less or equal to the number\n",
    "    #of attributes\n",
    "    #rollout_length: This is how far ahead we wish to \"rollout\" the initial question (x,y) under the one\n",
    "    #step lookahead base policy\n",
    "    #MC_budget: This is the budget we allow for monte carlo method of rollout. At this point in time, we will use MC if\n",
    "    #rollout_length is greater than 8.\n",
    "    #include_one_step: This determines whether we want to include the one-step optimal question within our batch. This can\n",
    "    #help ensure that rollout performs at least as well as one-step look ahead. Default value is False.\n",
    "    #penalty_term: This is used to set the penalty level for orthogonality in the orthogonal batch design optimization problem. A higher penalty\n",
    "    #term will lead to a more Sigma_orthogonal design, while a lower penalty term will lead to less Sigma_orthogonality in the design\n",
    "    \n",
    "    #Construct the batch based off of mu,Sig, and batch_size\n",
    "    batch = batch_design_delta_penalty(mu,Sig,batch_size,mu_log_coeff,Sig_log_coeff,M = penalty_term)[0]\n",
    "    \n",
    "    #If desired, include the one-step look ahead optimal question within this batch to help ensure performance\n",
    "    #is at least as good as one-step look ahead\n",
    "    if include_one_step:\n",
    "        [one_step_x,one_step_y] = g_opt(mu,Sig,mu_log_coeff,Sig_log_coeff)[1:]\n",
    "        batch.append([one_step_x,one_step_y])\n",
    "    print(batch)\n",
    "    #For each question in the batch, perform rollout of length rollout_length and save the average of the determinant\n",
    "    #values for each question. If rollout_length is greater than or equal to 8, use MC method instead, \n",
    "    #as it seems enumeration becomes slow after this point.\n",
    "    cov_avg_det_values = []\n",
    "    if rollout_length >= 8:\n",
    "        for question in batch:\n",
    "            x = question[0]\n",
    "            y = question[1]\n",
    "            avg_det_value = monte_carlo_rollout(mu,Sig,x,y,rollout_length,mu_log_coeff,Sig_log_coeff,MC_budget)\n",
    "            cov_avg_det_values.append(avg_det_value)\n",
    "    else:\n",
    "        for question in batch:\n",
    "            x = question[0]\n",
    "            y = question[1]\n",
    "            avg_det_value = rollout(mu,Sig,x,y,rollout_length,mu_log_coeff,Sig_log_coeff)\n",
    "            cov_avg_det_values.append(avg_det_value)\n",
    "    \n",
    "    \n",
    "    #Pick the question with the lowest average determinant value. Call it opt_question\n",
    "    min_index = np.argmin(np.array(cov_avg_det_values))\n",
    "    opt_question = batch[min_index]\n",
    "    \n",
    "    return opt_question\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d5f6b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS WILL NEED TO BE MOVED OR DELETED!!!\n",
    "#An example of rollout_with_batch_design_acquisition, we also look at the one-step lookahead case:\n",
    "\n",
    "#rng = np.random.default_rng(100) \n",
    "#np.random.seed(100)\n",
    "\n",
    "#rollacq_num_attr = 6\n",
    "#rollacq_roll_len = 2\n",
    "#rollacq_MC_budget = 50\n",
    "#rollacq_batch_size = 4\n",
    "#mu_naught = np.array([0.0,0.0,-2.0,3.0,8.0,0.0])#rng.uniform(low = -1.0, high = 1.0, size = rollacq_num_attr)\n",
    "#Sig_naught = np.identity(rollacq_num_attr)#sklearn.datasets.make_spd_matrix(rollacq_num_attr)#\n",
    "\n",
    "#Sig_naught = np.diag([4.0,4.0,0.25,0.25,0.25,4.0])\n",
    "#rho = 0.1\n",
    "#for i in range(rollacq_num_attr):\n",
    "    #if i==0:\n",
    "        #Sig_naught[i,0] = 1.0\n",
    "        #Sig_naught[i,1] = rho\n",
    "    #if i == rollacq_num_attr-1:\n",
    "        #Sig_naught[i,rollacq_num_attr-1] = 1.0\n",
    "        #Sig_naught[i,rollacq_num_attr-2] = rho \n",
    "    #if i>0 and i<(rollacq_num_attr-1):\n",
    "        #for j in range(i-1,i+2):\n",
    "            #Sig_naught[i,j] = rho**abs(i-j)\n",
    "\n",
    "#Sig_naught = np.zeros([rollacq_num_attr,rollacq_num_attr])\n",
    "#for i in range(rollacq_num_attr):\n",
    "    #for j in range(rollacq_num_attr):\n",
    "        #Sig_naught[i,j] = rho**abs(i-j)\n",
    "\n",
    "#print(mu_naught)\n",
    "#print(Sig_naught)\n",
    "#rollout_opt = rollout_with_batch_design_acquisition(mu_naught,Sig_naught,mu_log_coeff_6,Sig_log_coeff_6,rollacq_batch_size,\n",
    "                                           #rollacq_roll_len,rollacq_MC_budget,include_one_step = True,penalty_term = 0.1)\n",
    "#onestep_opt = g_opt(mu_naught,Sig_naught,mu_log_coeff_6,Sig_log_coeff_6)[1:]\n",
    "\n",
    "#print('rollout_opt: ' + str(rollout_opt))\n",
    "#print('onestep_opt: ' + str(onestep_opt))\n",
    "#print('rollout_value of rollout solution: ' + str(rollout(mu_naught,\n",
    "                                                         #Sig_naught,\n",
    "                                                         #rollout_opt[0],\n",
    "                                                         #rollout_opt[1],\n",
    "                                                         #rollacq_roll_len,\n",
    "                                                         #mu_log_coeff_6,\n",
    "                                                         #Sig_log_coeff_6)))\n",
    "#print('rollout_value of onestep solution: ' + str(rollout(mu_naught,\n",
    "                                                         #Sig_naught,\n",
    "                                                         #onestep_opt[0],\n",
    "                                                         #onestep_opt[1],\n",
    "                                                         #rollacq_roll_len,\n",
    "                                                         #mu_log_coeff_6,\n",
    "                                                         #Sig_log_coeff_6)))\n",
    "\n",
    "#[mu_update_roll,Sig_update_roll] = moment_matching_update(rollout_opt[0],rollout_opt[1],mu_naught,Sig_naught)\n",
    "#[mu_update_onestep,Sig_update_onestep] = moment_matching_update(onestep_opt[0],onestep_opt[1],mu_naught,Sig_naught)\n",
    "\n",
    "#print('Determinant of Sig_update_roll: ' + str(np.linalg.det(Sig_update_roll)))\n",
    "#print('Determinant of Sig_update_onestep: ' + str(np.linalg.det(Sig_update_onestep)))\n",
    "\n",
    "#print('Sig_update_roll: ' + str(Sig_update_roll))\n",
    "#print('Sig_update_onestep: ' + str(Sig_update_onestep))\n",
    "#print('mu_update_roll: ' + str(mu_update_roll))\n",
    "#print('mu_update_onestep: ' + str(mu_update_onestep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adba7e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS MAY JUST BE DELETED!!!\n",
    "#Second Rollout iteration\n",
    "#rng = np.random.default_rng(100) \n",
    "#np.random.seed(100)\n",
    "\n",
    "#rollacq_num_attr = 6\n",
    "#rollacq_roll_len_1 = 2\n",
    "#rollacq_MC_budget = 50 #NOT NEEDED since we are only doing 4 lookahead\n",
    "#rollacq_batch_size = 4\n",
    "#mu_roll_1 = mu_update_roll#rng.uniform(low = -1.0, high = 1.0, size = rollacq_num_attr)\n",
    "#Sig_roll_1 = Sig_update_roll#sklearn.datasets.make_spd_matrix(rollacq_num_attr)#\n",
    "\n",
    "#rollout_opt_1 = rollout_with_batch_design_acquisition(mu_roll_1,Sig_roll_1,mu_log_coeff_6,Sig_log_coeff_6,rollacq_batch_size,\n",
    "                                           #rollacq_roll_len_1,rollacq_MC_budget,include_one_step = True)\n",
    "\n",
    "#print('rollout_opt_1: ' + str(rollout_opt_1))\n",
    "\n",
    "#[mu_roll_2,Sig_roll_2] = moment_matching_update(rollout_opt_1[0],rollout_opt_1[1],mu_roll_1,Sig_roll_1)\n",
    "\n",
    "#print('Determinant of Sig_roll_2: ' + str(np.linalg.det(Sig_roll_2)))\n",
    "\n",
    "#print('Sig_roll_2: ' + str(Sig_roll_2))\n",
    "#print('mu_roll_2: ' + str(mu_roll_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c64f3c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS MAY NEED TO BE DELETED!!!\n",
    "#Second onestep iteration\n",
    "#rng = np.random.default_rng(100) \n",
    "#np.random.seed(100)\n",
    "\n",
    "\n",
    "#mu_onestep_1 = mu_update_onestep#rng.uniform(low = -1.0, high = 1.0, size = rollacq_num_attr)\n",
    "#Sig_onestep_1 = Sig_update_onestep#sklearn.datasets.make_spd_matrix(rollacq_num_attr)#\n",
    "\n",
    "#onestep_opt_1 = g_opt(mu_onestep_1,Sig_onestep_1,mu_log_coeff_6,Sig_log_coeff_6)[1:]\n",
    "\n",
    "\n",
    "#print('onestep_opt_1: ' + str(onestep_opt_1))\n",
    "\n",
    "#[mu_onestep_2,Sig_onestep_2] = moment_matching_update(onestep_opt_1[0],onestep_opt_1[1],mu_onestep_1,Sig_onestep_1)\n",
    "\n",
    "#print('Determinant of Sig_onestep_2: ' + str(np.linalg.det(Sig_onestep_2)))\n",
    "\n",
    "#print('Sig_onestep_2: ' + str(Sig_onestep_2))\n",
    "#print('mu_onestep_2: ' + str(mu_onestep_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef9067ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinate_exchange_acq(mu,Sig,mu_log_coeff,Sig_log_coeff,batch_size,rollout_length,MC_budget,rel_gap_threshold,\n",
    "                           include_batch = False, include_one_step = True):\n",
    "    #mu: This is the initial mean parameter that we start with\n",
    "    #Sig: This is the initial covariance matrix we start with\n",
    "    #mu_log_coeff: The estimated coefficient c_1 that goes with m in the linear model log(g) = c_1*m + c_2*v\n",
    "    #Sig_log_coeff: The estimated coefficient c_2 that goes with v in the linear model log(g) = c_1m + c_2*v\n",
    "    #batch_size: the number of questions we want to return in our batch design. This should be less or equal to the number\n",
    "    #of attributes\n",
    "    #rollout_length: This is how far ahead we wish to \"rollout\" the initial question (x,y) under the one\n",
    "    #step lookahead base policy\n",
    "    #MC_budget: This is the budget we allow for monte carlo method of rollout. At this point in time, we will use MC if\n",
    "    #rollout_length is greater than 8.\n",
    "    #rel_gap_threshold: This is used to see if the perturbed question outperforms the current question\n",
    "    #include_batch: This determines whether we also iterate over the batch questions.\n",
    "    #include_one_step: This determines whether we want to include the one-step optimal question within our batch. This can\n",
    "    #help ensure that rollout performs at least as well as one-step look ahead.\n",
    "    \n",
    "    #question_component tells us how many components are in (x,y)\n",
    "    attr = len(mu)\n",
    "    question_component = 2*attr\n",
    "    \n",
    "    #Used to store the initial set of questions coming from batch and one-step method\n",
    "    init_set_of_questions = []\n",
    "    \n",
    "    #Used to store the set of questions after performing coordinate exchange on the initial batch\n",
    "    final_set_of_questions = []\n",
    "    \n",
    "    #This will store the rollout values of the final set of questions\n",
    "    final_det_values = []\n",
    "    \n",
    "    #Determine if the initial set of questions includes the batch design\n",
    "    if include_batch:\n",
    "        init_set_of_questions = batch_design_delta_penalty(mu,Sig,batch_size,mu_log_coeff,Sig_log_coeff)[0]\n",
    "    \n",
    "    #Determine if the initial set of questions includes the one-step optimal solution\n",
    "    if include_one_step:\n",
    "        [one_step_x,one_step_y] = g_opt(mu,Sig,mu_log_coeff,Sig_log_coeff)[1:]\n",
    "        init_set_of_questions.append([one_step_x,one_step_y])\n",
    "    \n",
    "    #Need to use monte_carlo if rollout_length is greater than 8\n",
    "    if rollout_length>=8:\n",
    "        #iterate over all the questions\n",
    "        for question in init_set_of_questions:\n",
    "            current_question = [q[:] for q in question]#question[:]\n",
    "            x = current_question[0]\n",
    "            y = current_question[1]\n",
    "            #perform monte carlo rollout on the current question. Store its value\n",
    "            current_roll_value = monte_carlo_rollout(mu,Sig,x,y,rollout_length,mu_log_coeff,Sig_log_coeff,MC_budget)\n",
    "            #This counter is used to determine when the coordinate exchange process stops for this question.\n",
    "            print('first roll value: ' + str(current_roll_value))\n",
    "            print('first question: ' + str(current_question))\n",
    "            counter = 0\n",
    "            #Begin the coordinate exchange process for the current question\n",
    "            while counter < question_component:\n",
    "                #Initiate a variable called perturb question. This question will start as the same as the current question,\n",
    "                #but later on we will change a single attribute in one of the products and see if that improves the rollout\n",
    "                #value.\n",
    "                perturb_question = [cq[:] for cq in current_question]\n",
    "                #If the counter is less than the number of product attributes, we will change one of the entries in 'x'\n",
    "                if counter < attr:\n",
    "                    #Changing an entry in 'x'\n",
    "                    perturb_question[0][counter] = abs(1.0-current_question[0][counter])\n",
    "                    x_perturb = perturb_question[0]\n",
    "                    y_perturb = perturb_question[1]\n",
    "                    #Make sure the perturbed 'x' and 'y' are not equal. If so, check its rollout value.\n",
    "                    if np.dot(np.array(x_perturb)-np.array(y_perturb),np.array(x_perturb)-np.array(y_perturb))>0:\n",
    "                        perturb_roll_value = monte_carlo_rollout(mu,Sig,x_perturb,y_perturb,rollout_length,mu_log_coeff,\n",
    "                                                                 Sig_log_coeff,MC_budget)\n",
    "                #If counter is greater than number of product attributes, we will change one of the entries in 'y'.\n",
    "                else:\n",
    "                    perturb_question[1][counter-attr] = abs(1.0 - current_question[1][counter-attr])\n",
    "                    x_perturb = perturb_question[0]\n",
    "                    y_perturb = perturb_question[1]\n",
    "                    if np.dot(np.array(x_perturb)-np.array(y_perturb),np.array(x_perturb)-np.array(y_perturb))>0:\n",
    "                        perturb_roll_value = monte_carlo_rollout(mu,Sig,x_perturb,y_perturb,rollout_length,mu_log_coeff,\n",
    "                                                                 Sig_log_coeff,MC_budget)\n",
    "                \n",
    "                #If the perturbed question's rollout value outperforms the current question's rollout value by some\n",
    "                #relative threshold, then we will replace the current question with the perturbed question\n",
    "                if (current_roll_value - perturb_roll_value)/current_roll_value >= rel_gap_threshold:\n",
    "                    current_question = [q[:] for q in perturb_question]#perturb_question\n",
    "                    current_roll_value = perturb_roll_value\n",
    "                    counter = 0\n",
    "                    print('current_question: ' + str(current_question))\n",
    "                    print('current_roll_value: ' + str(current_roll_value))\n",
    "                else:\n",
    "                    counter = counter + 1\n",
    "            \n",
    "            #After the coordinate exchange process, we place the resulting question and its rollout value in a list.\n",
    "            final_set_of_questions.append(current_question)\n",
    "            final_det_values.append(current_roll_value)\n",
    "    \n",
    "    #Use regular rollout if rollout length is less than 8. Same coordinate exchange process as in the \n",
    "    #monte carlo rollout method    \n",
    "    else:\n",
    "        for question in init_set_of_questions:\n",
    "            current_question = [q[:] for q in question]\n",
    "            x = current_question[0]\n",
    "            y = current_question[1]\n",
    "            current_roll_value = rollout(mu,Sig,x,y,rollout_length,mu_log_coeff,Sig_log_coeff)\n",
    "            print('first roll value: ' + str(current_roll_value))\n",
    "            print('first question: ' + str(current_question))\n",
    "            counter = 0\n",
    "            while counter < question_component:\n",
    "                perturb_question = [cq[:] for cq in current_question]\n",
    "                if counter < attr:\n",
    "                    perturb_question[0][counter] = abs(1.0-current_question[0][counter])\n",
    "                    x_perturb = perturb_question[0]\n",
    "                    y_perturb = perturb_question[1]\n",
    "                    if np.dot(np.array(x_perturb)-np.array(y_perturb),np.array(x_perturb)-np.array(y_perturb))>0:\n",
    "                        perturb_roll_value = rollout(mu,Sig,x_perturb,y_perturb,rollout_length,mu_log_coeff,\n",
    "                                                                 Sig_log_coeff)\n",
    "                else:\n",
    "                    perturb_question[1][counter-attr] = abs(1.0 - current_question[1][counter-attr])\n",
    "                    x_perturb = perturb_question[0]\n",
    "                    y_perturb = perturb_question[1]\n",
    "                    if np.dot(np.array(x_perturb)-np.array(y_perturb),np.array(x_perturb)-np.array(y_perturb))>0:\n",
    "                        perturb_roll_value = rollout(mu,Sig,x_perturb,y_perturb,rollout_length,mu_log_coeff,\n",
    "                                                                 Sig_log_coeff)\n",
    "                    \n",
    "                if (current_roll_value - perturb_roll_value)/current_roll_value >= rel_gap_threshold:\n",
    "                    current_question = [q[:] for q in perturb_question]\n",
    "                    current_roll_value = perturb_roll_value\n",
    "                    counter = 0\n",
    "                    print('current_question: ' + str(current_question))\n",
    "                    print('current_roll_value: ' + str(current_roll_value))\n",
    "                else:\n",
    "                    counter = counter + 1\n",
    "                \n",
    "            final_set_of_questions.append(current_question)\n",
    "            final_det_values.append(current_roll_value)\n",
    "    \n",
    "    #Find the minimimum rollout value among all the questions that have went through coordinate exchange. Pick the one with\n",
    "    #the smallest rollout value.\n",
    "    min_index = np.argmin(np.array(final_det_values))\n",
    "    rollout_coordinate_opt_question = final_set_of_questions[min_index]\n",
    "    \n",
    "    return rollout_coordinate_opt_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d2c59cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS WILL NEED TO BE MOVED!!!\n",
    "#Example for coordinate_exchange\n",
    "#rng = np.random.default_rng(100) \n",
    "#np.random.seed(100)\n",
    "\n",
    "#coord_mu = np.array(12*[1.0])#rng.uniform(low = -1.0, high = 1.0, size = 12)#np.array(6*[1.0])#np.array([1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])#np.array([-0.25,0.5,-0.75,1.0,-1.25,1.5]) \n",
    "#coord_Sig = np.identity(12)#sklearn.datasets.make_spd_matrix(12)#np.identity(6)##np.identity(12)#1.25*np.array([[1.0,-0.5,0.25,-0.125,0.0625,-0.03125],\n",
    "                      #[-0.5,1.0,-0.5,0.25,-0.125,0.0625],\n",
    "                     #[0.25,-0.5,1.0,-0.5,0.25,-0.125],\n",
    "                     #[-0.125,0.25,-0.5,1.0,-0.5,0.25],\n",
    "                     #[0.0625,-0.125,0.25,-0.5,1.0,-0.5],\n",
    "                     #[-0.03125,0.0625,-0.125,0.25,-0.5,1.0]])       #np.diag([2.0,0.5,1.0,1.0,1.0,1.0])\n",
    "                    #np.diag([1.25,0.8,1.5,0.3333,2,0.5])\n",
    "#print(coord_mu,coord_Sig)\n",
    "#coord_batch_size = 0\n",
    "#coord_roll_len = 3\n",
    "#coord_MC_budget = 0#50\n",
    "#coord_rel_gap = 0.0001\n",
    "#start_time = time.perf_counter()\n",
    "#print(coordinate_exchange_acq(coord_mu,coord_Sig,mu_log_coeff_12,Sig_log_coeff_12,coord_batch_size,coord_roll_len,\n",
    "                             #coord_MC_budget,coord_rel_gap,include_batch = False))\n",
    "#print(time.perf_counter() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "068b1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS WILL NEED TO BE MOVED OR DELETED!!!\n",
    "#Example for batch\n",
    "#rng = np.random.default_rng(99) \n",
    "#np.random.seed(99)\n",
    "\n",
    "#batch_mu = np.array([1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])#np.array([-0.25,0.5,-0.75,1.0,-1.25,1.5])#np.array([1.0,1.0,1.0,1.0,1.0,1.0])# #rng.uniform(low = -1.0, high = 1.0, size = 6)\n",
    "#batch_Sig = np.identity(12)#1.25*np.array([[1.0,-0.5,0.25,-0.125,0.0625,-0.03125],\n",
    "                        #[-0.5,1.0,-0.5,0.25,-0.125,0.0625],\n",
    "                     #[0.25,-0.5,1.0,-0.5,0.25,-0.125],\n",
    "                     #[-0.125,0.25,-0.5,1.0,-0.5,0.25],\n",
    "                     #[0.0625,-0.125,0.25,-0.5,1.0,-0.5],\n",
    "                     #[-0.03125,0.0625,-0.125,0.25,-0.5,1.0]])  \n",
    "                    #np.identity(6)#  #sklearn.datasets.make_spd_matrix(6)#np.diag([2.0,0.5,1.0,1.0,1.0,1.0])\n",
    "                    #np.diag([1.25,0.8,1.5,0.3333,2,0.5])\n",
    "#print(batch_mu,batch_Sig)\n",
    "\n",
    "#roll_batch_size = 4\n",
    "\n",
    "#batch_roll_len = 3\n",
    "\n",
    "#batch_roll_MC_budget = 0#50\n",
    "\n",
    "#start_time_batch = time.perf_counter()\n",
    "#print(rollout_with_batch_design_acquisition(batch_mu,batch_Sig,mu_log_coeff_12,Sig_log_coeff_12,roll_batch_size,\n",
    "                                           #batch_roll_len,batch_roll_MC_budget,include_one_step = True,penalty_term = 10))\n",
    "#print(time.perf_counter() - start_time_batch, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
