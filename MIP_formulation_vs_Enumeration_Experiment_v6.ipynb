{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "import scipy.integrate\n",
    "import math\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "\n",
    "############\n",
    "from Baseline_Functions_Definitions import z_expectation_variance\n",
    "from Experiment_Framework import product_diff_list,question_extractor,norm_AO_MO_data_generation\n",
    "from Questionnaire_Procedure import moment_matching_update\n",
    "from Batch_Design_and_Rollout import batch_design_AO, batch_design_MO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a9314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to generate an nxn matrix M(r) such that M_ij = r^|i-j| for -1<r<1. This matrix is called a \n",
    "#Kac-Murdock-Szego matrix.\n",
    "def KMS_Matrix(n,r):\n",
    "    #n: this is the number of rows and columns of the matrix\n",
    "    #r: this is the coefficient given above that determines the value of the matrice's entries \n",
    "    \n",
    "    \n",
    "    M = np.zeros([n,n])\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            M[i,j] = r**abs(i-j)\n",
    "        \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105ad21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to create a set of batch designs and evaluate their D-error (in a sequential manner). \n",
    "#We save the D-error of each batch in a list.\n",
    "\n",
    "def random_batch_D_error(init_mu,init_Sig,batch_size,num_random_batches,true_partworths, gumbel_error_terms):\n",
    "    #init_mu: This is the initial expectation of the partworths.\n",
    "    #init_Sig: This is the initial covariance matrix of the partworths.\n",
    "    #batch_size: This is the number of questions in each batch.\n",
    "    #num_random_batches: This is the number of random batches that we will generate.\n",
    "    #true_partworths: This is the true/baseline partworths we will use to evaluate the d-error of a design.\n",
    "    #gumbel_error_terms: This is a list of gumbel errors terms used in evaluating the d-error of a design. This \n",
    "    #list should have dimension (true_partworths x batch_size), where each entry is a list with two randomly generated\n",
    "    #gumbel terms. We use the same true partworths and error terms for evaluating the d-error of each randomly generated \n",
    "    #design.\n",
    "    \n",
    "    attr_num = len(init_mu)\n",
    "    \n",
    "    average_d_error = []\n",
    "    \n",
    "    #Create a list of all products.\n",
    "    prod_list = product_diff_list(attr_num)\n",
    "    \n",
    "    #Construct the set of batch designs\n",
    "    batch_set = [[] for i in range(num_random_batches)]\n",
    "    for i in range(num_random_batches):\n",
    "        random_question_matrix = random.sample(prod_list,batch_size)\n",
    "        for m in range(batch_size):\n",
    "            #random_question_vec = random.sample(prod_list,1)[0]\n",
    "            #[x,y] = question_extractor(random_question_vec)\n",
    "            [x,y] = question_extractor(random_question_matrix[m])\n",
    "            batch_set[i].append([x,y])\n",
    "        \n",
    "            \n",
    "    #Evaluate the d-error\n",
    "    #true_partworths = []\n",
    "    #for t in range(num_true_partworths):\n",
    "                #true_partworths.append(rng.multivariate_normal(init_mu,init_Sig))\n",
    "    num_true_partworths = len(true_partworths)\n",
    "    \n",
    "    for i in range(num_random_batches):\n",
    "                #Create a list for the batch that will store the final determinant value for each simulation\n",
    "                #corresponding to each baseline partworth.\n",
    "                batch_simulate_d_values = []\n",
    "                #print('random_batch_number: ' + str(i))\n",
    "                #Simulate d-efficiency over baseline partworths\n",
    "                for j in range(num_true_partworths):\n",
    "                #Each time we start with a new partworth, we must use the initial prior parameters.\n",
    "                    mu = init_mu\n",
    "                    Sig = init_Sig\n",
    "                    \n",
    "                    #Each simulation goes through the questions in the random batch.\n",
    "                    for k in range(batch_size):\n",
    "                    #Set x and y\n",
    "                        x = batch_set[i][k][0]\n",
    "                        y = batch_set[i][k][1]\n",
    "                \n",
    "                        #These temp variables will be used in the choice model below in case the user prefers y over x.\n",
    "                        x_temp = x\n",
    "                        y_temp = y\n",
    "                        \n",
    "                        #See preference between two products.\n",
    "                        gum_x = gumbel_error_terms[j][k][0]#np.random.gumbel(0,1)\n",
    "                        gum_y = gumbel_error_terms[j][k][1]#np.random.gumbel(0,1)\n",
    "                        if (np.dot(true_partworths[j],np.array(y)) + gum_y) >= (np.dot(true_partworths[j],np.array(x)) + gum_x):\n",
    "                            x = y_temp\n",
    "                            y = x_temp\n",
    "                            \n",
    "                        #Perform moment matching after choice is made.\n",
    "                        [mu, Sig] = moment_matching_update(x,y,mu,Sig)\n",
    "                        \n",
    "                    #After the questionnaire for a baseline partworth is complete, we append the square root of the determinant\n",
    "                    #of the final covariance matrix.\n",
    "                    batch_simulate_d_values.append(np.sqrt(np.linalg.det(Sig)))\n",
    "                    \n",
    "                #We average the d-values from the simulation for a batch and store it in a list.\n",
    "                average_d_error.append(np.mean(batch_simulate_d_values))\n",
    "                \n",
    "    return average_d_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5187bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the models batch_AO and batch_MO.\n",
    "rng = np.random.default_rng(100) \n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "\n",
    "#signal to noise ratio. \n",
    "#1 - LOW: multiply expectation by 0.25 and covariance by 4.0\n",
    "#2 - REG: multiply expectation by 1.0 and covariance by 1.0\n",
    "#3 - HIGH: multiply expectation by 4.0 and covariance by 0.25\n",
    "snr = int(sys.argv[1])\n",
    "\n",
    "\n",
    "#Prior type\n",
    "#1 - homogeneous expectation and identity covariance matrix\n",
    "#2 - heterogeneous expectation and KMS covariance matrix\n",
    "prior_type = int(sys.argv[2])\n",
    "\n",
    "if snr == 1:\n",
    "    if prior_type == 1:\n",
    "        init_mu_fit = 0.25*np.array(6*[1.0])\n",
    "        init_Sig_fit = 4.0*np.identity(6)\n",
    "    if prior_type == 2:\n",
    "        init_mu_fit = 0.25*np.array([-0.25,0.5,-0.75,1.0,-1.25,1.5])\n",
    "        init_Sig_fit = 4.0*(1.25*KMS_Matrix(6,-0.5))\n",
    "if snr == 2:\n",
    "    if prior_type == 1:\n",
    "        init_mu_fit = 1.0*np.array(6*[1.0])\n",
    "        init_Sig_fit = 1.0*np.identity(6)\n",
    "    if prior_type == 2:\n",
    "        init_mu_fit = 1.0*np.array([-0.25,0.5,-0.75,1.0,-1.25,1.5])\n",
    "        init_Sig_fit = 1.0*(1.25*KMS_Matrix(6,-0.5))\n",
    "if snr == 3:\n",
    "    if prior_type == 1:\n",
    "        init_mu_fit = 4.0*np.array(6*[1.0])\n",
    "        init_Sig_fit = 0.25*np.identity(6)\n",
    "    if prior_type == 2:\n",
    "        init_mu_fit = 4.0*np.array([-0.25,0.5,-0.75,1.0,-1.25,1.5])\n",
    "        init_Sig_fit = 0.25*(1.25*KMS_Matrix(6,-0.5))\n",
    "    \n",
    "batch_size_fit = 4\n",
    "    \n",
    "L_fit = [1.0]\n",
    "S_fit = [1.0]\n",
    "\n",
    "num_random_batches_fit = 1000\n",
    "num_true_partworths_fit = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c13e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the data in order to estimate the parameters of the AO and MO models\n",
    "average_orthogonality_fit, maximum_orthogonality_fit, average_question_mean_fit, average_question_variance_fit, L_mu_fit, S_Sig_fit, init_sqrt_determinant_fit, average_d_error_fit = norm_AO_MO_data_generation(init_mu_fit, init_Sig_fit, batch_size_fit, L_fit, S_fit, num_random_batches_fit, num_true_partworths_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe of the generated data for fitting the parameters of the AO and MO models\n",
    "df_fit = pd.DataFrame(list(zip(average_orthogonality_fit, maximum_orthogonality_fit, average_question_mean_fit, average_question_variance_fit, L_mu_fit, S_Sig_fit, init_sqrt_determinant_fit, average_d_error_fit)),\n",
    "                  columns =['Avg_Orth', 'Max_Orth', 'Avg_Quest_Mean', 'Avg_Quest_Var', 'L_mu_norm', 'S_Sig_norm', 'Init_Sqrt_Det', 'D_err'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca86ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add some new columns to the dataset. We mean-center the independent variables to attempt to reduce VIF. This will not affect the value of\n",
    "#of the coefficients, except for the intercept.\n",
    "df_fit['log_norm_derr'] = np.log(np.divide(np.array(df_fit['D_err']),np.array(df_fit['Init_Sqrt_Det'])))\n",
    "df_fit['cent_norm_AM'] = np.divide(np.array(df_fit['Avg_Quest_Mean']),np.array(df_fit['L_mu_norm'])) - np.mean(np.divide(np.array(df_fit['Avg_Quest_Mean']),np.array(df_fit['L_mu_norm'])))\n",
    "df_fit['cent_norm_AV'] = np.divide(np.array(df_fit['Avg_Quest_Var']),np.array(df_fit['S_Sig_norm'])) - np.mean(np.divide(np.array(df_fit['Avg_Quest_Var']),np.array(df_fit['S_Sig_norm'])))\n",
    "df_fit['cent_norm_AO'] = np.divide(np.array(df_fit['Avg_Orth']),np.array(df_fit['S_Sig_norm'])) - np.mean(np.divide(np.array(df_fit['Avg_Orth']),np.array(df_fit['S_Sig_norm'])))\n",
    "df_fit['cent_norm_MO'] = np.divide(np.array(df_fit['Max_Orth']),np.array(df_fit['S_Sig_norm'])) - np.mean(np.divide(np.array(df_fit['Max_Orth']),np.array(df_fit['S_Sig_norm'])))\n",
    "\n",
    "df_fit['cent_L_mu_norm'] = df_fit['L_mu_norm'] - np.mean(np.array(df_fit['L_mu_norm']))\n",
    "df_fit['cent_S_Sig_norm'] = df_fit['S_Sig_norm'] - np.mean(np.array(df_fit['S_Sig_norm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806792f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save resulting file as a CSV.\n",
    "if snr == 1:\n",
    "    if prior_type == 1:\n",
    "        df_fit.to_csv('MIPvEnum_Normalized_AO_MO_Model_Data_mu025_Sig4Ident_batchsize4_L_1_S_1_nrb_1000_ntp_100_v6.csv')\n",
    "    if prior_type == 2:\n",
    "        df_fit.to_csv('MIPvEnum_Normalized_AO_MO_Model_Data_lowsnr_muhet_SigKMS_batchsize4_L_1_S_1_nrb_1000_ntp_100_v6.csv')\n",
    "if snr == 2:\n",
    "    if prior_type == 1:\n",
    "        df_fit.to_csv('MIPvEnum_Normalized_AO_MO_Model_Data_mu1_Sig1Ident_batchsize4_L_1_S__1_nrb_1000_ntp_100_v6.csv')\n",
    "    if prior_type == 2:\n",
    "        df_fit.to_csv('MIPvEnum_Normalized_AO_MO_Model_Data_medsnr_muhet_SigKMS_batchsize4_L_1_S_1_nrb_1000_ntp_100_v6.csv')\n",
    "if snr == 3:\n",
    "    if prior_type == 1:\n",
    "        df_fit.to_csv('MIPvEnum_Normalized_AO_MO_Model_Data_mu4_Sig025Ident_batchsize4_L_1_S_1_nrb_1000_ntp_100_v6.csv')\n",
    "    if prior_type == 2:\n",
    "        df_fit.to_csv('MIPvEnum_Normalized_AO_MO_Model_Data_highsnr_muhet_SigKMS_batchsize4_L_1_S_1_nrb_1000_ntp_100_v6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7700d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model with AO\n",
    "#Since we use L=S=[1.0], we do not need the regression terms L_mu_norm and S_Sig_norm\n",
    "model_AO = sm.formula.ols(formula = \"log_norm_derr ~  cent_norm_AM + cent_norm_AV + cent_norm_AO\", data = df_fit).fit()\n",
    "parameter_est_AO = model_AO.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d3668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model with MO\n",
    "#Since we use L=S=[1.0], we do not need the regression terms L_mu_norm and S_Sig_norm\n",
    "model_MO = sm.formula.ols(formula = \"log_norm_derr ~  cent_norm_AM + cent_norm_AV + cent_norm_MO\", data = df_fit).fit()\n",
    "parameter_est_MO = model_MO.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266b50fd-1193-4c34-bf50-66886b64c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model ouput as a text file\n",
    "if snr == 1:\n",
    "    if prior_type == 1:\n",
    "        with open('summary_low_homo_AO_v6.txt', 'w') as fh:\n",
    "            fh.write(model_AO.summary().as_text())\n",
    "        with open('summary_low_homo_MO_v6.txt', 'w') as fh:\n",
    "            fh.write(model_MO.summary().as_text())\n",
    "    if prior_type == 2:\n",
    "        with open('summary_low_het_AO_v6.txt', 'w') as fh:\n",
    "            fh.write(model_AO.summary().as_text())\n",
    "        with open('summary_low_het_MO_v6.txt', 'w') as fh:\n",
    "            fh.write(model_MO.summary().as_text())\n",
    "if snr == 2:\n",
    "    if prior_type == 1:\n",
    "        with open('summary_med_homo_AO_v6.txt', 'w') as fh:\n",
    "            fh.write(model_AO.summary().as_text())\n",
    "        with open('summary_med_homo_MO_v6.txt', 'w') as fh:\n",
    "            fh.write(model_MO.summary().as_text())\n",
    "    if prior_type == 2:\n",
    "        with open('summary_med_het_AO_v6.txt', 'w') as fh:\n",
    "            fh.write(model_AO.summary().as_text())\n",
    "        with open('summary_med_het_MO_v6.txt', 'w') as fh:\n",
    "            fh.write(model_MO.summary().as_text())\n",
    "if snr == 3:\n",
    "    if prior_type == 1:\n",
    "        with open('summary_high_homo_AO_v6.txt', 'w') as fh:\n",
    "            fh.write(model_AO.summary().as_text())\n",
    "        with open('summary_high_homo_MO_v6.txt', 'w') as fh:\n",
    "            fh.write(model_MO.summary().as_text())\n",
    "    if prior_type == 2:\n",
    "        with open('summary_high_het_AO_v6.txt', 'w') as fh:\n",
    "            fh.write(model_AO.summary().as_text())\n",
    "        with open('summary_high_het_MO_v6.txt', 'w') as fh:\n",
    "            fh.write(model_MO.summary().as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc55ba26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model parameters in txt file\n",
    "if snr == 1:\n",
    "    params_est = np.array([parameter_est_AO[1],parameter_est_AO[2],parameter_est_AO[3],parameter_est_MO[1],parameter_est_MO[2],parameter_est_MO[3]])\n",
    "    if prior_type == 1:\n",
    "        np.savetxt('MIPvEnum_modelparams_lowsnr_v6.txt',params_est)\n",
    "    if prior_type == 2:\n",
    "        np.savetxt('MIPvEnum_modelparams_lowsnr_muhet_SigKMS_v6.txt', params_est)\n",
    "if snr == 2:\n",
    "    params_est = np.array([parameter_est_AO[1],parameter_est_AO[2],parameter_est_AO[3],parameter_est_MO[1],parameter_est_MO[2],parameter_est_MO[3]])\n",
    "    if prior_type == 1:\n",
    "        np.savetxt('MIPvEnum_modelparams_medsnr_v6.txt',params_est)\n",
    "    if prior_type == 2:\n",
    "        np.savetxt('MIPvEnum_modelparams_medsnr_muhet_SigKMS_v6.txt', params_est)\n",
    "if snr == 3:\n",
    "    params_est = np.array([parameter_est_AO[1],parameter_est_AO[2],parameter_est_AO[3],parameter_est_MO[1],parameter_est_MO[2],parameter_est_MO[3]])\n",
    "    if prior_type == 1:\n",
    "        np.savetxt('MIPvEnum_modelparams_highsnr_v6.txt',params_est)\n",
    "    if prior_type == 2:\n",
    "        np.savetxt('MIPvEnum_modelparams_highsnr_muhet_SigKMS_v6.txt', params_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44cd96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment settings:\n",
    "#Settings for experiment\n",
    "rng = np.random.default_rng(100)\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "\n",
    "    \n",
    "if snr == 1:\n",
    "    if prior_type == 1:\n",
    "        mu_exp = 0.25*np.array(6*[1.0])\n",
    "        Sig_exp = 4.0*np.identity(6)\n",
    "    if prior_type == 2:\n",
    "        mu_exp = 0.25*np.array([-0.25,0.5,-0.75,1.0,-1.25,1.5])\n",
    "        Sig_exp = 4.0*(1.25*KMS_Matrix(6,-0.5))\n",
    "if snr == 2:\n",
    "    if prior_type == 1:\n",
    "        mu_exp = 1.0*np.array(6*[1.0])\n",
    "        Sig_exp = 1.0*np.identity(6)\n",
    "    if prior_type == 2:\n",
    "        mu_exp = 1.0*np.array([-0.25,0.5,-0.75,1.0,-1.25,1.5])\n",
    "        Sig_exp = 1.0*(1.25*KMS_Matrix(6,-0.5))\n",
    "if snr == 3:\n",
    "    if prior_type == 1:\n",
    "        mu_exp = 4.0*np.array(6*[1.0])\n",
    "        Sig_exp = 0.25*np.identity(6)\n",
    "    if prior_type == 2:\n",
    "        mu_exp = 4.0*np.array([-0.25,0.5,-0.75,1.0,-1.25,1.5])\n",
    "        Sig_exp = 0.25*(1.25*KMS_Matrix(6,-0.5))\n",
    "\n",
    "batch_size_exp = 4\n",
    "num_random_batches_exp = 100000       \n",
    "\n",
    "true_partworth_exp = []\n",
    "\n",
    "num_true_partworths_exp = 100\n",
    "#There will be 100 true partworths\n",
    "for t in range(num_true_partworths_exp):\n",
    "    true_partworth_exp.append(rng.multivariate_normal(mu_exp,Sig_exp))\n",
    "    \n",
    "#Create list of gumbel error terms\n",
    "gumbel_error_terms_exp = [[[np.random.gumbel(0,1) for k in range(2)] for j in range(batch_size_exp)] for i in range(num_true_partworths_exp)]\n",
    "print(gumbel_error_terms_exp[0])   \n",
    "\n",
    "AO_alpha_exp = parameter_est_AO[1]\n",
    "AO_kappa_exp = parameter_est_AO[2]\n",
    "AO_gamma_exp = parameter_est_AO[3]\n",
    "\n",
    "MO_alpha_exp = parameter_est_MO[1]\n",
    "MO_kappa_exp = parameter_est_MO[2]\n",
    "MO_gamma_exp = parameter_est_MO[3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0209db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of d-error of random batch designs\n",
    "tic = time.perf_counter()\n",
    "d_err_list = random_batch_D_error(mu_exp,Sig_exp,batch_size_exp,num_random_batches_exp,true_partworth_exp,gumbel_error_terms_exp)\n",
    "toc = time.perf_counter()\n",
    "time_meas = toc - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b08463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Batch_AO design and evaluate its D-error\n",
    "[AO_batch,AO_Ortho] = batch_design_AO(mu_exp,Sig_exp,batch_size_exp,AO_alpha_exp,AO_kappa_exp,AO_gamma_exp,t_lim = 100,logfile = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acea520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Batch_MO design and evaluate its D-error\n",
    "[MO_batch, MO_Ortho] = batch_design_MO(mu_exp,Sig_exp,batch_size_exp,MO_alpha_exp,MO_kappa_exp,MO_gamma_exp,t_lim = 100,logfile = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632c231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the d-error of the Batch_AO design\n",
    "\n",
    "#Create a list for the batch that will store the final determinant value for each simulation\n",
    "#corresponding to each baseline partworth.\\\n",
    "\n",
    "batch_AO_d_values = []\n",
    "                \n",
    "#Simulate d-efficiency over baseline partworths\n",
    "for j in range(len(true_partworth_exp)):\n",
    "    #Each time we start with a new partworth, we must use the initial prior parameters.\n",
    "    mu_AO = mu_exp\n",
    "    Sig_AO = Sig_exp\n",
    "                    \n",
    "    #Each simulation goes through the questions in the random batch.\n",
    "    for k in range(batch_size_exp):\n",
    "        #Set x and y\n",
    "        x_AO = AO_batch[k][0]\n",
    "        y_AO = AO_batch[k][1]\n",
    "                \n",
    "        #These temp variables will be used in the choice model below in case the user prefers y over x.\n",
    "        x_temp_AO = x_AO\n",
    "        y_temp_AO = y_AO\n",
    "        \n",
    "        gum_x_AO = gumbel_error_terms_exp[j][k][0]\n",
    "        gum_y_AO = gumbel_error_terms_exp[j][k][1]\n",
    "        #See preference between two products.\n",
    "        if (np.dot(true_partworth_exp[j],np.array(y_AO)) + gum_y_AO) >= (np.dot(true_partworth_exp[j],np.array(x_AO)) + gum_x_AO):\n",
    "            x_AO = y_temp_AO\n",
    "            y_AO = x_temp_AO\n",
    "                            \n",
    "        #Perform moment matching after choice is made.\n",
    "        [mu_AO, Sig_AO] = moment_matching_update(x_AO,y_AO,mu_AO,Sig_AO)\n",
    "                        \n",
    "    #After the questionnaire for a baseline partworth is complete, we append the square root of the determinant\n",
    "    #of the final covariance matrix.\n",
    "    batch_AO_d_values.append(np.sqrt(np.linalg.det(Sig_AO)))\n",
    "                    \n",
    "#We average the d-values from the simulation for the AO batch and save it as a variable.\n",
    "batch_AO_d_error = np.mean(batch_AO_d_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4206101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the d-error of the Batch_MO design\n",
    "\n",
    "#Create a list for the batch that will store the final determinant value for each simulation\n",
    "#corresponding to each baseline partworth.\n",
    "batch_MO_d_values = []\n",
    "                \n",
    "#Simulate d-efficiency over baseline partworths\n",
    "for j in range(len(true_partworth_exp)):\n",
    "    #Each time we start with a new partworth, we must use the initial prior parameters.\n",
    "    mu_MO = mu_exp\n",
    "    Sig_MO = Sig_exp\n",
    "                    \n",
    "    #Each simulation goes through the questions in the random batch.\n",
    "    for k in range(batch_size_exp):\n",
    "        #Set x and y\n",
    "        x_MO = MO_batch[k][0]\n",
    "        y_MO = MO_batch[k][1]\n",
    "                \n",
    "        #These temp variables will be used in the choice model below in case the user prefers y over x.\n",
    "        x_temp_MO = x_MO\n",
    "        y_temp_MO = y_MO\n",
    "        \n",
    "        gum_x_MO = gumbel_error_terms_exp[j][k][0]\n",
    "        gum_y_MO = gumbel_error_terms_exp[j][k][1]\n",
    "        #See preference between two products. \n",
    "        if (np.dot(true_partworth_exp[j],np.array(y_MO)) + gum_y_MO) >= (np.dot(true_partworth_exp[j],np.array(x_MO)) + gum_x_MO):\n",
    "            x_MO = y_temp_MO\n",
    "            y_MO = x_temp_MO\n",
    "                            \n",
    "        #Perform moment matching after choice is made.\n",
    "        [mu_MO, Sig_MO] = moment_matching_update(x_MO,y_MO,mu_MO,Sig_MO)\n",
    "                        \n",
    "    #After the questionnaire for a baseline partworth is complete, we append the square root of the determinant\n",
    "    #of the final covariance matrix.\n",
    "    batch_MO_d_values.append(np.sqrt(np.linalg.det(Sig_MO)))\n",
    "                    \n",
    "#We average the d-values from the simulation for the AO batch and save it as a variable.\n",
    "batch_MO_d_error = np.mean(batch_MO_d_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded4f08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_AO_success = [1 if batch_AO_d_error < rand_batch_d_error else 0 for rand_batch_d_error in d_err_list]\n",
    "batch_MO_success = [1 if batch_MO_d_error < rand_batch_d_error else 0 for rand_batch_d_error in d_err_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9449a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save d-error information and success information in a csv\n",
    "batch_information_list = np.array([d_err_list,batch_AO_success,batch_MO_success]).T\n",
    "batch_information_list_df = pd.DataFrame(batch_information_list, columns = ['D-errors', 'Batch AO < D-error', 'Batch MO < D-error'])\n",
    "\n",
    "if snr == 1:\n",
    "    if prior_type == 1:\n",
    "        batch_information_list_df.to_csv('MIPvsEnum_lowsnr_d_error_batch_comparison_list_v6.csv')\n",
    "    if prior_type == 2:\n",
    "        batch_information_list_df.to_csv('MIPvsEnum_lowsnr_d_error_batch_comparison_list_muhet_SigKMS_v6.csv')\n",
    "if snr == 2:\n",
    "    if prior_type == 1:\n",
    "        batch_information_list_df.to_csv('MIPvsEnum_mediumsnr_d_error_batch_comparison_list_v6.csv')\n",
    "    if prior_type == 2:\n",
    "        batch_information_list_df.to_csv('MIPvsEnum_mediumsnr_d_error_batch_comparison_list_muhet_SigKMS_v6.csv')\n",
    "if snr == 3:\n",
    "    if prior_type == 1:\n",
    "        batch_information_list_df.to_csv('MIPvsEnum_highsnr_d_error_batch_comparison_list_v6.csv')\n",
    "    if prior_type == 2:\n",
    "        batch_information_list_df.to_csv('MIPvsEnum_highsnr_d_error_batch_comparison_list_muhet_SigKMS_v6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc80f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct estimates and confidence interval\n",
    "AO_prop_est = np.mean(batch_AO_success)\n",
    "MO_prop_est = np.mean(batch_MO_success)\n",
    "\n",
    "AO_CI_upper = AO_prop_est + 1.96*np.sqrt(AO_prop_est*(1-AO_prop_est)/len(batch_AO_success))\n",
    "AO_CI_lower = AO_prop_est - 1.96*np.sqrt(AO_prop_est*(1-AO_prop_est)/len(batch_AO_success))\n",
    "\n",
    "MO_CI_upper = MO_prop_est + 1.96*np.sqrt(MO_prop_est*(1-MO_prop_est)/len(batch_MO_success))\n",
    "MO_CI_lower = MO_prop_est - 1.96*np.sqrt(MO_prop_est*(1-MO_prop_est)/len(batch_MO_success))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16183f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save confidence interval information, time for iterating over random batches, and d-error of batches\n",
    "if snr == 1:\n",
    "    CI_information = np.array(['batch_AO_d_error: ' + str(batch_AO_d_error),'AO_prop_est: ' +str(AO_prop_est),'AO_CI_lower: ' + str(AO_CI_lower),'AO_CI_upper: ' + str(AO_CI_upper),'batch_MO_d_error: ' + str(batch_MO_d_error),'MO_prop_est: ' + str(MO_prop_est),'MO_CI_lower:' + str(MO_CI_lower),'MO_CI_upper: ' + str(MO_CI_upper),'time for enumeration: ' + str(time_meas)])\n",
    "    if prior_type == 1:\n",
    "        np.savetxt('MIPvEnum_CIinfo_lowsnr_v6.txt',CI_information,fmt='%s')\n",
    "    if prior_type == 2:\n",
    "        np.savetxt('MIPvEnum_CIinfo_lowsnr_muhet_SigKMS_v6.txt',CI_information,fmt='%s')\n",
    "if snr == 2:\n",
    "    CI_information = np.array(['batch_AO_d_error: ' + str(batch_AO_d_error),'AO_prop_est: ' +str(AO_prop_est),'AO_CI_lower: ' + str(AO_CI_lower),'AO_CI_upper: ' + str(AO_CI_upper),'batch_MO_d_error: ' + str(batch_MO_d_error),'MO_prop_est: ' + str(MO_prop_est),'MO_CI_lower:' + str(MO_CI_lower),'MO_CI_upper: ' + str(MO_CI_upper),'time for enumeration: ' + str(time_meas)])\n",
    "    if prior_type == 1:\n",
    "        np.savetxt('MIPvEnum_CIinfo_mediumsnr_v6.txt',CI_information,fmt='%s')\n",
    "    if prior_type == 2:\n",
    "        np.savetxt('MIPvEnum_CIinfo_mediumsnr_muhet_SigKMS_v6.txt',CI_information,fmt='%s')\n",
    "if snr == 3:\n",
    "    CI_information = np.array(['batch_AO_d_error: ' + str(batch_AO_d_error),'AO_prop_est: ' +str(AO_prop_est),'AO_CI_lower: ' + str(AO_CI_lower),'AO_CI_upper: ' + str(AO_CI_upper),'batch_MO_d_error: ' + str(batch_MO_d_error),'MO_prop_est: ' + str(MO_prop_est),'MO_CI_lower:' + str(MO_CI_lower),'MO_CI_upper: ' + str(MO_CI_upper),'time for enumeration: ' + str(time_meas)])\n",
    "    if prior_type == 1:\n",
    "        np.savetxt('MIPvEnum_CIinfo_highsnr_v6.txt',CI_information,fmt='%s')\n",
    "    if prior_type == 2:\n",
    "        np.savetxt('MIPvEnum_CIinfo_highsnr_muhet_SigKMS_v6.txt',CI_information,fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save information regarding the batch design.\n",
    "if snr == 1:\n",
    "    batch_info = np.array(['AO_batch: '+str(AO_batch),'AO_Orth: '+str(AO_Ortho),'MO_batch: '+str(MO_batch),'MO_Orth: '+str(MO_Ortho)])\n",
    "    if prior_type == 1:\n",
    "        np.savetxt('MIPvEnum_batchinfo_lowsnr_v6.txt',batch_info,fmt='%s')\n",
    "    if prior_type == 2:\n",
    "        np.savetxt('MIPvEnum_batchinfo_lowsnr_muhet_SigKMS_v6.txt',batch_info,fmt='%s')\n",
    "if snr == 2:\n",
    "    batch_info = np.array(['AO_batch: '+str(AO_batch),'AO_Orth: '+str(AO_Ortho),'MO_batch: '+str(MO_batch),'MO_Orth: '+str(MO_Ortho)])\n",
    "    if prior_type == 1:\n",
    "        np.savetxt('MIPvEnum_batchinfo_mediumsnr_v6.txt',batch_info,fmt='%s')\n",
    "    if prior_type == 2:\n",
    "        np.savetxt('MIPvEnum_batchinfo_mediumsnr_muhet_SigKMS_v6.txt',batch_info,fmt='%s')\n",
    "if snr == 3:\n",
    "    batch_info = np.array(['AO_batch: '+str(AO_batch),'AO_Orth: '+str(AO_Ortho),'MO_batch: '+str(MO_batch),'MO_Orth: '+str(MO_Ortho)])\n",
    "    if prior_type == 1:\n",
    "        np.savetxt('MIPvEnum_batchinfo_highsnr_v6.txt',batch_info,fmt='%s')\n",
    "    if prior_type == 2:\n",
    "        np.savetxt('MIPvEnum_batchinfo_highsnr_muhet_SigKMS_v6.txt',batch_info,fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
